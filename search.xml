<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[solr的应用---taotao项目搜索功能实现]]></title>
    <url>%2F2018%2F10%2F13%2Fsolr%E7%9A%84%E5%BA%94%E7%94%A8---taotao%E9%A1%B9%E7%9B%AE%E6%90%9C%E7%B4%A2%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[前方泥土太多 走出才能洒脱 是时候写一篇质量很高的博客了呢 为啥我一背井离乡那个坑逼就回来了呢，兄弟团聚这么难啊 家乡现在通暖气了吧 霜冻真的冷 想家，想爸妈，想兄弟，想她 好吧 开始写吧 序 可以看出搜索是个大的项目块，与数据库并无关联，由portal直接调用SearchService，再乡下由项目调用solr服务，联系到solr自带的索引库 从首页的jsp中 找到1&lt;script type=&quot;text/javascript&quot; src=&quot;/js/base-v1.js&quot; charset=&quot;utf-8&quot;&gt; 1&lt;input type=&quot;button&quot; value=&quot;搜索&quot; class=&quot;button&quot; onclick=&quot;search(&apos;key&apos;);return false;&quot; clstag=&quot;homepage|keycount|home2013|03a&quot;&gt; 这两段 得出从basev1.js中找search的片段1234function search(a) &#123; var b = &quot;http://localhost:8082/search.html?q=&quot; + encodeURIComponent(document.getElementById(a).value); return window.location.href = b;&#125; 这里得到了将来portal的controller的响应条件 请求url：http://localhost:8082/search.html?q=查询条件 导入数据搭建solr服务器的过程不再赘述需要jdk tomcat 比较繁琐 关键是配置 这里定义数据格式 才能根据这个完成导入和取出数据 solr 通过你导入的长篇大论分析出各种词汇 然后根据你输入词汇返回查询的对象这里重点介绍java代码调用solr的服务 首先需要把数据库的数据取出 传输到solr库 12345678910111213&lt;select id=&quot;getItemList&quot; resultType=&quot;com.taotao.search.pojo.Item&quot;&gt; SELECT a.id, a.title, a.sell_point, a.price, a.image, b. NAME category_name FROM tb_item a LEFT JOIN tb_item_cat b ON a.cid = b.id &lt;/select&gt;&lt;/mapper&gt; List&lt;com.taotao.search.pojo.Item&gt; getItemList(); 这里从数据库中取出数据然后 123456789101112131415161718192021222324252627282930public TaotaoResult importAllItem() &#123; // TODO Auto-generated method stub try &#123; List&lt;Item&gt; list=itemMapper.getItemList(); for (Item item : list) &#123; SolrInputDocument document = new SolrInputDocument(); document.setField(&quot;id&quot;, item.getId()); document.setField(&quot;item_title&quot;, item.getTitle()); document.setField(&quot;item_sell_point&quot;, item.getSell_point()); document.setField(&quot;item_price&quot;, item.getId()); document.setField(&quot;item_image&quot;, item.getId()); document.setField(&quot;item_category_name&quot;, item.getCategory_name()); document.setField(&quot;item_desc&quot;, item.getItem_desc()); solrserver.add(document); &#125; solrserver.commit(); &#125; catch (Exception e) &#123; // TODO: handle exception e.printStackTrace(); return TaotaoResult.build(500, ExceptionUtil.getStackTrace(e)); &#125; return TaotaoResult.ok(); &#125;&#125; 写一个循环的方法 把取出来的整个list挨个写入solr库 @RequestMapping(“/manager”)public class ItemController { @Autowired ItemService itemService; //导入所有商品数据 @RequestMapping(&quot;/importall&quot;) @ResponseBody public TaotaoResult importAllItem(){ TaotaoResult result=itemService.importAllItem(); return result; } 浏览器输入这个url 数据量大的话浏览器加载时间会长，不过只执行一次的模块。 去solr库看 成功导入数据库取出数据 编写服务然后就能用java代码取出这些数据操作 (dao层)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Repositorypublic class SearchDaoImpl implements SearchDao &#123; @Autowired private SolrServer solrServer; @Override public SearchResult searchDao(SolrQuery solrQuery) throws SolrServerException &#123; SearchResult searchResult = new SearchResult(); // 根据查询结果查询索引库 QueryResponse queryResponse = solrServer.query(solrQuery); SolrDocumentList solrDocumentList = queryResponse.getResults(); // Map&lt;String, Map&lt;String, List&lt;String&gt;&gt;&gt; highlighting = queryResponse.getHighlighting(); long numFound = solrDocumentList.getNumFound(); searchResult.setRecordCount(numFound); List&lt;Item&gt; list = new ArrayList&lt;&gt;(); for (SolrDocument solrDocument : solrDocumentList) &#123; Item item = new Item(); item.setId((String) solrDocument.get(&quot;id&quot;)); List&lt;String&gt; list2 = highlighting.get(solrDocument.get(&quot;id&quot;)).get(&quot;item_title&quot;); String str = &quot;&quot;; if (list2 != null &amp;&amp; list2.size() &gt; 0) &#123; str = list2.get(0); &#125; else &#123; str = (String) solrDocument.get(&quot;item_category_name&quot;); &#125; item.setCategory_name((String) solrDocument.get(&quot;item_category_name&quot;)); item.setPrice((long) solrDocument.get(&quot;item_price&quot;)); item.setTitle((String) solrDocument.get(&quot;item_title&quot;)); item.setImage((String) solrDocument.get(&quot;item_image&quot;)); item.setSell_point((String) solrDocument.get(&quot;item_sell_point&quot;)); list.add(item); &#125; searchResult.setList(list); return searchResult; &#125; 这里通过传入的查询词汇的参数，把从solr中取出的数据包装成一个个item对象（list） public class SearchResult { private List list; private long pageCount; private long curPage; private long recordCount;searchresult长这样 service层调用dao层 12345678910111213141516171819202122232425262728293031323334353637public class SearchServiceImpl implements SearchService &#123; @Autowired SearchDao searchDao; @Override public SearchResult search(String queryString, int page, int rows) throws SolrServerException &#123; SolrQuery query = new SolrQuery(); query.setQuery(queryString); query.setStart((page-1)*rows); query.set(&quot;df&quot;, &quot;item_keywords&quot;); query.setHighlight(true); query.addHighlightField(&quot;item_title&quot;); query.setHighlightSimplePre(&quot;&lt;em style=\&quot;color:red\&quot;&gt;&quot;); query.setHighlightSimplePost(&quot;&lt;/em&gt;&quot;); SearchResult searchResult = searchDao.searchDao(query); long recordCount =searchResult.getRecordCount(); long pageCount = recordCount / rows; if (recordCount %rows&gt;0) &#123; pageCount++; &#125; searchResult.setPageCount(pageCount); searchResult.setCurPage(page); return searchResult; &#125; 传的参数String query 的具体的值是不会变的 关键的逻辑query.setStart((page-1)*rows);定义了分页展示 controller层 通过浏览器就可以取出数据 @Controllerpublic class SearchController { @Autowired private SearchService service; @RequestMapping(value = &quot;/query&quot;, method = RequestMethod.GET) @ResponseBody private TaotaoResult search(@RequestParam(defaultValue = &quot;1&quot;) Integer page, @RequestParam(defaultValue = &quot;60&quot;) Integer rows, @RequestParam(&quot;q&quot;) String queryString) { if (StringUtils.isBlank(queryString)) { return TaotaoResult.build(400, &quot;查询条件不能为空&quot;); } SearchResult result = null; try { queryString = new String(queryString.getBytes(&quot;iso8859-1&quot;), &quot;utf-8&quot;); result = service.search(queryString, page, rows); } catch (Exception e) { e.printStackTrace(); } return TaotaoResult.ok(result); } }这句话很关键queryString = new String(queryString.getBytes(“iso8859-1”), “utf-8” 解决了传输到浏览器的乱码问题 输入url取出的taotaoresult型数据 调用服务portal 层调用写好的服务12345678910111213141516171819202122232425262728293031@Servicepublic class SearchServiceImpl implements SearchService &#123; @Value(&quot;$&#123;SOLR_BASE_URL&#125;&quot;) public String SOLR_BASE_URL; @Override public SearchResult getSearchResult(String query, int page) &#123; Map&lt;String, String&gt; param= new HashMap&lt;&gt;(); param.put(&quot;q&quot;, query); param.put(&quot;page&quot;, page+&quot;&quot;); // String json = HttpClientUtil.doGet(SOLR_BASE_URL,param); TaotaoResult tresult = TaotaoResult.formatToPojo(json, SearchResult.class); SearchResult sresult = (SearchResult) tresult.getData(); return sresult; &#125;&#125; 这里HttpClientUtil.doGet 有带参数的url的方法 参数是map类型 page+“”是将page强制转换成string类型 取出刚刚截图的taotaoresult 的String类型消息 先格式化成searchresult的pojo再转换成taotaoresult型对象 再取出后面的data 强制转换成SearchResult 这里需要taotaoresult经手是为了方便查看异常 和关键的formatToPojo方法 controller 层12345678910111213141516171819202122232425262728293031@Controllerpublic class SearchController &#123; @Autowired SearchService searchService; @RequestMapping(&quot;/search&quot;) public String showSearch(@RequestParam(&quot;q&quot;) String query, @RequestParam(defaultValue = &quot;1&quot;) Integer page, Model model) &#123; if (query!=null) &#123; try &#123; query = new String(query.getBytes(&quot;iso8859-1&quot;), &quot;utf-8&quot;); &#125; catch (UnsupportedEncodingException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; SearchResult result = searchService.getSearchResult(query, page); model.addAttribute(&quot;query&quot;, query); model.addAttribute(&quot;totalPages&quot;, result.getPageCount()); model.addAttribute(&quot;page&quot;, page); model.addAttribute(&quot;itemList&quot;, result.getList()); return &quot;search&quot;; &#125;&#125; 用到了springmvc 响应前端的 这里可能会出一个空指针异常 来自 @RequestParam(defaultValue = “1”) Integer page 这个地方 如果 page没有定义默认参数 而且传入了一个null 将会让逐个下一层的int page 都传入一个null的参数 导致产生了空引用 ${query} - 商品搜索 - 淘淘 &lt;div class=&quot;crumb&quot;&gt;全部结果&amp;nbsp;&amp;gt;&amp;nbsp;&lt;strong&gt;&quot;${query}&quot;&lt;/strong&gt;&lt;/div&gt; 下一页 &nbsp;&nbsp;共${totalPages}页&nbsp;&nbsp;&nbsp;&nbsp;到第 c:forEach items=”${itemList}” var=”item”&gt; ${item.title} 去响应jsp定义好的回显功能]]></content>
      <categories>
        <category>项目实战</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[taotao的redis集群缓存池]]></title>
    <url>%2F2018%2F10%2F08%2Ftaotao%E7%9A%84redis%E9%9B%86%E7%BE%A4%E7%BC%93%E5%AD%98%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[mmp现在就开始做集群是不是太早了，，既然用到了那就开始学吧刚刚发小给发了个喝酒的视频 瞬间笑喷 真羡慕他们 能和故交知己坐一起痛饮该是世界上最大快事吧 服务器已配置好单机的redis 为啥用redis项目中使用redis，主要是从两个角度去考虑:性能和并发 我们在碰到需要执行耗时特别久，且结果不频繁变动的SQL，就特别适合将运行结果放入缓存 后面的请求就去缓存中读取，使得请求能够迅速响应。 redis的数据类型，以及每种数据类型的使用场景String 这个其实没啥好说的，最常规的set/get操作，value可以是String也可以是数字。一般做一些复杂的计数功能的缓存。 hash 这里value存放的是结构化的对象，比较方便的就是操作其中的某个字段。博主在做单点登录的时候，就是用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果。 list 使用List的数据结构，可以做简单的消息队列的功能。另外还有一个就是，可以利用lrange命令，做基于redis的分页功能，性能极佳，用户体验好。本人还用一个场景，很合适—取行情信息。就也是个生产者和消费者的场景。LIST可以很好的完成排队，先进先出的原则。 set 因为set堆放的是一堆不重复值的集合。所以可以做全局去重的功能。为什么不用JVM自带的Set进行去重？因为我们的系统一般都是集群部署，使用JVM自带的Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了。 另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。 sorted set sorted set多了一个权重参数score,集合中的元素能够按score进行排列。可以做排行榜应用，取TOP N操作。 以上是redis相关概念 接下来说集群 redis-cluster把所有的物理节点映射到[0-16383]slot上,cluster 负责维护nodeslotvalueRedis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点 Key:a计算a的hash值，例如值为100，100这个槽在server1上，所以a应该放到server1. Key:helloHash值：10032，此槽在server2上。Hell可以应该存在server2. (1)领着投票过程是集群中所有master参与,如果半数以上master节点与master节点通信超过(cluster-node-timeout),认为当前master节点挂掉.(2):什么时候整个集群不可用(cluster_state:fail)? a:如果集群任意master挂掉,且当前master没有slave.集群进入fail状态,也可以理解成集群的slot映射[0-16383]不完成时进入fail状态. ps : redis-3.0.0.rc1加入cluster-require-full-coverage参数,默认关闭,打开集群兼容部分失败. b:如果集群超过半数以上master挂掉，无论是否有slave集群进入fail状态. ps:当集群不可用时,所有对集群的操作做都不可用，收到((error) CLUSTERDOWN The cluster is down)错误 心头一颤 看样子需要3个节点 才能完成一个最小的集群 然后就是一主一备 6个虚拟机。。心疼一波我的老伙计 需要使用一个官方提供额ruby脚本呢]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[捋一下门户首页大广告实现方案]]></title>
    <url>%2F2018%2F10%2F08%2F%E6%8D%8B%E4%B8%80%E4%B8%8B%E9%97%A8%E6%88%B7%E9%A6%96%E9%A1%B5%E5%A4%A7%E5%B9%BF%E5%91%8A%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[最近没有涉及到新的技术，项目做的一帆风顺吧，好吧 我又来捋一捋了 分析首先从jsp开始 发现首页大广告位置的 取出那条json格式化之后发现 jsp的大广告这部分接受这样格式的json数据和之前不同的是，portal层没有dao层，不能从数据库中取出数据然后转换json，需要调用rest层的服务rest层可以从数据库取出数据然后转换成json，（因为httpclient传递的是json数据）然后由portal的service层取出字符串 剥丝抽茧 把数据data取出来转化成list对象，然后遍历，对照上一条json把该加的内容加进去 使用modelAndView对象把json字符串传递给jsp。 1var data = $&#123;ad1&#125;; ↓↓↓↓↓↓↓↓↓↓↓↓↓1model.addAttribute(&quot;ad1&quot;,adJSON); restful层其实rest相当于给portal的dao层，只是这样方便后期扩展的门户继续调用这个restful形式 123456789101112131415public class ContentServiceimpl implements ContentService &#123; @Autowired private TbContentMapper contentMapper; @Override public List&lt;TbContent&gt; getContentList(long contentCid) &#123; // 查询商品列表 TbContentExample example = new TbContentExample(); Criteria criteria = example.createCriteria(); criteria.andCategoryIdEqualTo(contentCid); List&lt;TbContent&gt; list =contentMapper.selectByExample(example); return list; &#125;&#125; 根据分类contentid把content内容信息全取出来 123456789101112131415161718@RequestMapping(&quot;/content&quot;)public class ContentController &#123; @Autowired private ContentService contentService; @RequestMapping(&quot;/list/&#123;contentCategoryId&#125;&quot;) @ResponseBody public TaotaoResult getContentList(@PathVariable Long contentCategoryId) &#123; try &#123; List&lt;TbContent&gt; list = contentService.getContentList(contentCategoryId); return TaotaoResult.ok(list); &#125; catch (Exception e) &#123; e.printStackTrace(); return TaotaoResult.build(500, com.taotao.common.utils.ExceptionUtil.getStackTrace(e)); &#125; &#125; 写好控制层在浏览器输入对应url便可以将json数据取出来，但此时json数据并不符合jsp所要展示的相应格式对比 portal 层需要使用httpclient调用taotao-rest的服务。根据内容分类id查询分类的内容列表，需要使用httpclient调用taotao-rest的服务。得到一个json字符串。需要把字符串转换成java对象taotaoResult对象。从taotaoResult对象中取data属性，得到内容列表。把内容列表转换成jsp页面要求的json格式。返回一个json字符串。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Servicepublic class ContentServiceImpl implements ContentService &#123; @Value(&quot;$&#123;REST_BASE_URL&#125;&quot;) public String REST_BASE_URL; @Value(&quot;$&#123;REST_INDEX_AD_URL&#125;&quot;) public String REST_INDEX_AD_URL; //这里的属性在一个配置文件 @Override public String getContentList() &#123; String result = HttpClientUtil.doGet(REST_BASE_URL + REST_INDEX_AD_URL); //访问的REST_BASE_URL = http://localhost:8081/rest/ 而 REST_INDEX_AD_URL = /content/list/89 try &#123; //类型转换 把字符串转换成TaotaoResult TaotaoResult formatToList = TaotaoResult.formatToList(result, TbContent.class); //取出data List&lt;TbContent&gt; list = (List&lt;TbContent&gt;) formatToList.getData(); List&lt;Map&gt; resultList = new ArrayList&lt;&gt;(); //创建一个jsp页码要求的pojo列表 for (TbContent tbContent : list) &#123; Map map =new HashMap&lt;&gt;(); map.put(&quot;src&quot;, tbContent.getPic()); map.put(&quot;height&quot;, 240); map.put(&quot;width&quot;, 670); map.put(&quot;srcB&quot;, tbContent.getPic2()); map.put(&quot;widthB&quot;, 550); map.put(&quot;heightB&quot;, 240); map.put(&quot;href&quot;, tbContent.getUrl()); map.put(&quot;alt&quot;, tbContent.getSubTitle()); resultList.add(map); &#125; return JsonUtils.objectToJson(resultList); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; controller1234567@RequestMapping(&quot;/index&quot;) public String showIndex(Model model) &#123; String adJson = contentService.getContentList(); model.addAttribute(&quot;ad1&quot;, adJson); return &quot;index&quot;; &#125; 总结到这里信息交流的变化过程就是 taotaoresultlist对象 → taotaoresult json → string字符串 → taotaoresultlist对象 → tbcontent对象 → 详细的tbcontentlist的对象 → 可以响应的json]]></content>
      <categories>
        <category>项目实战</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[屡一下taotao前台系统商品分类展示]]></title>
    <url>%2F2018%2F10%2F07%2F%E5%B1%A1%E4%B8%80%E4%B8%8Btaotao%E5%89%8D%E5%8F%B0%E7%B3%BB%E7%BB%9F%E5%95%86%E5%93%81%E5%88%86%E7%B1%BB%E5%B1%95%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[大晚上的不想睡，，一天不写博客感觉浑身难受 先从前台开始捋把 首页商品类目展示流程 数据传输过程 这是前台jsp映射的url callback 应该是传到后台方法的参数 rest的controller层功能是将从service层取出的字符串转换成json再拼接成前台所适应的字符串形式 callback + “(“ + json + “)12345678910111213141516171819@Controllerpublic class ItemCatController &#123; @Autowired ItemCatService itemCatService; @RequestMapping(value=&quot;/itemcat/list&quot;, produces=MediaType.APPLICATION_JSON_VALUE+&quot;;charset=UTF-8&quot;) @ResponseBody public String getItemcatList(String callback) &#123; CatResult catResult = itemCatService.getItemCatList(); // 把pojo转换成字符串 String json = JsonUtils.objectToJson(catResult); String result = callback + &quot;(&quot; + json + &quot;);&quot;; return result; &#125;&#125; getItemCatList 这个方法实现在service层1234567public CatResult getItemCatList() &#123; CatResult catResult = new CatResult(); // 查询分类列表 catResult.setData(getCatList(0)); return catResult; &#125; 关键来了 这个getCatList() 1234567891011121314151617181920212223242526272829303132private List&lt;?&gt; getCatList(long parentId) &#123; // 创建查询条件 TbItemCatExample example = new TbItemCatExample(); com.taotao.pojo.TbItemCatExample.Criteria criteria = example.createCriteria(); criteria.andParentIdEqualTo(parentId); List&lt;TbItemCat&gt; list = itemCatMapper.selectByExample(example); List resultList = new ArrayList&lt;&gt;(); for (TbItemCat itemCat : list) &#123; // 判断是否是fu结点 if (itemCat.getIsParent()) &#123; CatNode catNode = new CatNode(); if (parentId == 0) &#123; catNode.setName(&quot;&lt;a href=&apos;/products/&quot; + itemCat.getId() + &quot;.html&apos;&gt;&quot; + itemCat.getName() + &quot;&lt;/a&gt;&quot;); &#125; else &#123; catNode.setName(itemCat.getName()); &#125; catNode.setUrl(&quot;/products/&quot; + itemCat.getId() + &quot;.html&quot;); catNode.setItem(getCatList(itemCat.getId())); resultList.add(catNode); &#125; else &#123; resultList.add(&quot;/products/&quot; + itemCat.getId() + &quot;.html|&quot; + itemCat.getName()); &#125; &#125; return resultList; &#125;&#125; 通过是否是父节点将从数据库取出的杂乱的数据循环遍历按一定顺序拼装成jsp可以理解的json格式数据 装进list里 以上就是数据库数据展示到jsp 的过程 跨域问题使用json数据测试。如果ajax请求的是同一个工程中taotao-portal的json数据没有问题，可以直接显示出来。如果请求的是taotao-rest工程中json数据，会发生错误。 跨域问题：浏览器一个安全的限制，不允许js跨域请求资源， www.taotao.com manage.taotao.com 跨域 www.taotao.com www.taotao.com 非跨域 www.taotao.com www.taotao.com:8081 跨域 如何解决跨域问题：使用jsonp来解决跨域问题。 jsonp的原理：浏览器在js请求中，是允许通过script标签的src跨域请求，可以在请求的结果中添加回调方法名，在请求页面中定义方法，既可获取到跨域请求的数据。]]></content>
      <categories>
        <category>项目实战</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[设计模式介绍及Java描述---单例模式]]></title>
    <url>%2F2018%2F10%2F04%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%BB%8B%E7%BB%8D%E5%8F%8AJava%E6%8F%8F%E8%BF%B0---%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[时间在你的眼角写下几丝愁 概述设计模式是针对某一类问题的最优解决方案，是从许多优秀的软件系统中总结出的。 Java中设计模式（java design patterns）通常有23种。 模式可以分成3类：创建型、行为型和结构型。 创建型模式创建型模式涉及对象的实例化，特点是不让用户代码依赖于对象的创建或排列方式，避免用户直接使用new创建对象。 创建型模式有以下5个： 1工厂方法模式、抽象工厂方法模式、生成器模式、原型模式和单例模式。 ##行为型模式 行为型模式涉及怎样合理的设计对象之间的交互通信，以及怎样合理为对象分配职责，让设计富有弹性，易维护，易复用。行为型模式有以下11个： 1责任链模式、命令模式、解释器模式、迭代器模式、中介者模式、备忘录模式、观察者模式、状态模式、策略模式、模板方法模式和访问者模式。 结构型模式结构型模式涉及如何组合类和对象以形成更大的结构，和类有关的结构型模式涉及如何合理使用继承机制；和对象有关的结构型模式涉及如何合理的使用对象组合机制。结构型模式有以下7个：1适配器模式、组合模式、代理模式、享元模式、外观模式、桥接模式和装饰模式。 模式中涉及的重要角色，会在描述中（加粗字体）介绍出来。下面就逐一介绍。 1、单例模式（Singleton Pattern）Ensure a class only has one instance,and provide a global point of access to it. 保证一个类仅有一个实例，并提供一个访问它的全局访问点。 何时使用 当系统需要某个类只有一个实例的时候 优点 单例模式的类唯一实例由其本身控制，可以很好的控制用户何时访问它。 单例模式概念很简单，而且也比较常用。 在使用这个模式的时候，我们要考虑是否会在多线程中使用，如果不会应用于多线程，那写法就足够简单： 12345678public class SimpleSingleton &#123; private static SimpleSingleton instance; private SimpleSingleton()&#123;&#125; public static SimpleSingleton getIntance()&#123; if(instance == null) instance = new SimpleSingleton(); return instance; &#125;&#125; 上例就是一个简单的单例模式实现，使用了懒加载模式。但是多线程中可能会创建多个实例。下面就介绍多线程中的使用。 如果直接将上面例子应用到多线程中，可以直接把getInstance()设置为同步的(synchronized)，但是并不高效，任一之后，只能有一个线程可以调用这个方法，其余的会排队等待。 所以整个方法做同步不是优解，那就只同步代码块就好了。这就引出了双重检验锁，即在同步块外检查一次null，然后再在同步块内检查一次。但是最终这种方式也是会有问题的，使用静态内部类是一种比较好的方式。 动机对于系统中的某些类来说，只有一个实例很重要，例如，一个系统中可以存在多个打印任务，但是只能有一个正在工作的任务；一个系统只能有一个窗口管理器或文件系统；一个系统只能有一个计时工具或ID(序号)生成器。如在Windows中就只能打开一个任务管理器。如果不使用机制对窗口对象进行唯一化，将弹出多个窗口，如果这些窗口显示的内容完全一致，则是重复对象，浪费内存资源；如果这些窗口显示的内容不一致，则意味着在某一瞬间系统有多个状态，与实际不符，也会给用户带来误解，不知道哪一个才是真实的状态。因此有时确保系统中某个对象的唯一性即一个类只能有一个实例非常重要 要点显然单例模式的要点有三个；一是某个类只能有一个实例；二是它必须自行创建这个实例；三是它必须自行向整个系统提供这个实例。 当一个类的实例可以有且只可以一个的时候就需要用到了。为什么只需要有一个呢？有人说是为了节约内存，但这只是单例模式带来的一个好处。只有一个实例确实减少内存占用，可是我认为这不是使用单例模式的理由。我认为使用单例模式的时机是当实例存在多个会引起程序逻辑错误的时候。比如类似有序的号码生成器这样的东西，怎么可以允许一个应用上存在多个呢？Singleton模式主要作用是保证在Java应用程序中，一个类Class只有一个实例存在。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F09%2F28%2Fjava%E4%B8%ADHashMap%E8%AF%A6%E8%A7%A3%EF%BC%88%E5%AE%9E%E4%BE%8B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[title: java中HashMap详解（实例）categories: JAVA a HashMap 和 HashSet 是 Java Collection Framework 的两个重要成员，其中 HashMap 是 Map 接口的常用实现类，HashSet 是 Set 接口的常用实现类。虽然 HashMap 和 HashSet 实现的接口规范不同，但它们底层的 Hash 存储机制完全一样，甚至 HashSet 本身就采用 HashMap 来实现的。 通过 HashMap、HashSet 的源代码分析其 Hash 存储机制实际上，HashSet 和 HashMap 之间有很多相似之处，对于 HashSet 而言，系统采用 Hash 算法决定集合元素的存储位置，这样可以保证能快速存、取集合元素；对于 HashMap 而言，系统 key-value 当成一个整体进行处理，系统总是根据 Hash 算法来计算 key-value 的存储位置，这样可以保证能快速存、取 Map 的 key-value 对。在介绍集合存储之前需要指出一点：虽然集合号称存储的是 Java 对象，但实际上并不会真正将 Java 对象放入 Set 集合中，只是在 Set 集合中保留这些对象的引用而言。也就是说：Java 集合实际上是多个引用变量所组成的集合，这些引用变量指向实际的 Java 对象。集合和引用 就像引用类型的数组一样，当我们把 Java 对象放入数组之时，并不是真正的把 Java 对象放入数组中，只是把对象的引用放入数组中，每个数组元素都是一个引用变量。 HashMap 的存储实现 当程序试图将多个 key-value 放入 HashMap 中时，以如下代码片段为例： HashMap&lt;String , Double&gt; map = new HashMap&lt;String , Double&gt;(); map.put(&quot;语文&quot; , 80.0); map.put(&quot;数学&quot; , 89.0); map.put(&quot;英语&quot; , 78.2); HashMap 采用一种所谓的“Hash 算法”来决定每个元素的存储位置。当程序执行 map.put(“语文” , 80.0); 时，系统将调用”语文”的 hashCode() 方法得到其 hashCode 值——每个 Java 对象都有 hashCode() 方法，都可通过该方法获得它的 hashCode 值。得到这个对象的 hashCode 值之后，系统会根据该 hashCode 值来决定该元素的存储位置。我们可以看 HashMap 类的 put(K key , V value) 方法的源代码： public V put(K key, V value) { // 如果 key 为 null，调用 putForNullKey 方法进行处理 if (key == null) return putForNullKey(value); // 根据 key 的 keyCode 计算 Hash 值 int hash = hash(key.hashCode()); // 搜索指定 hash 值在对应 table 中的索引 int i = indexFor(hash, table.length); // 如果 i 索引处的 Entry 不为 null，通过循环不断遍历 e 元素的下一个元素 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { Object k; // 找到指定 key 与需要放入的 key 相等（hash 值相同 // 通过 equals 比较放回 true） if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } // 如果 i 索引处的 Entry 为 null，表明此处还没有 Entry modCount++; // 将 key、value 添加到 i 索引处 addEntry(hash, key, value, i); return null; } 上面程序中用到了一个重要的内部接口：Map.Entry，每个 Map.Entry 其实就是一个 key-value 对。从上面程序中可以看出：当系统决定存储 HashMap 中的 key-value 对时，完全没有考虑 Entry 中的 value，仅仅只是根据 key 来计算并决定每个 Entry 的存储位置。这也说明了前面的结论：我们完全可以把 Map 集合中的 value 当成 key 的附属，当系统决定了 key 的存储位置之后，value 随之保存在那里即可。上面方法提供了一个根据 hashCode() 返回值来计算 Hash 码的方法：hash()，这个方法是一个纯粹的数学计算，其方法如下： static int hash(int h) { h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); } 对于任意给定的对象，只要它的 hashCode() 返回值相同，那么程序调用 hash(int h) 方法所计算得到的 Hash 码值总是相同的。接下来程序会调用 indexFor(int h, int length) 方法来计算该对象应该保存在 table 数组的哪个索引处。indexFor(int h, int length) 方法的代码如下： static int indexFor(int h, int length) { return h &amp; (length-1); } 这个方法非常巧妙，它总是通过 h &amp;(table.length -1) 来得到该对象的保存位置——而 HashMap 底层数组的长度总是 2 的 n 次方，这一点可参看后面关于 HashMap 构造器的介绍。当 length 总是 2 的倍数时，h &amp; (length-1) 将是一个非常巧妙的设计：假设 h=5,length=16, 那么 h &amp; length - 1 将得到 5；如果 h=6,length=16, 那么 h &amp; length - 1 将得到 6 ……如果 h=15,length=16, 那么 h &amp; length - 1 将得到 15；但是当 h=16 时 , length=16 时，那么 h &amp; length - 1 将得到 0 了；当 h=17 时 , length=16 时，那么 h &amp; length - 1 将得到 1 了……这样保证计算得到的索引值总是位于 table 数组的索引之内。根据上面 put 方法的源代码可以看出，当程序试图将一个 key-value 对放入 HashMap 中时，程序首先根据该 key 的 hashCode() 返回值决定该 Entry 的存储位置：如果两个 Entry 的 key 的 hashCode() 返回值相同，那它们的存储位置相同。如果这两个 Entry 的 key 通过 equals 比较返回 true，新添加 Entry 的 value 将覆盖集合中原有 Entry 的 value，但 key 不会覆盖。如果这两个 Entry 的 key 通过 equals 比较返回 false，新添加的 Entry 将与集合中原有 Entry 形成 Entry 链，而且新添加的 Entry 位于 Entry 链的头部——具体说明继续看 addEntry() 方法的说明。当向 HashMap 中添加 key-value 对，由其 key 的 hashCode() 返回值决定该 key-value 对（就是 Entry 对象）的存储位置。当两个 Entry 对象的 key 的 hashCode() 返回值相同时，将由 key 通过 eqauls() 比较值决定是采用覆盖行为（返回 true），还是产生 Entry 链（返回 false）。上面程序中还调用了 addEntry(hash, key, value, i); 代码，其中 addEntry 是 HashMap 提供的一个包访问权限的方法，该方法仅用于添加一个 key-value 对。下面是该方法的代码： void addEntry(int hash, K key, V value, int bucketIndex) { // 获取指定 bucketIndex 索引处的 Entry Entry&lt;K,V&gt; e = table[bucketIndex]; // ① // 将新创建的 Entry 放入 bucketIndex 索引处，并让新的 Entry 指向原来的 Entry table[bucketIndex] = new Entry&lt;K,V&gt;(hash, key, value, e); // 如果 Map 中的 key-value 对的数量超过了极限 if (size++ &gt;= threshold) // 把 table 对象的长度扩充到 2 倍。 resize(2 * table.length); // ② } 上面方法的代码很简单，但其中包含了一个非常优雅的设计：系统总是将新添加的 Entry 对象放入 table 数组的 bucketIndex 索引处——如果 bucketIndex 索引处已经有了一个 Entry 对象，那新添加的 Entry 对象指向原有的 Entry 对象（产生一个 Entry 链），如果 bucketIndex 索引处没有 Entry 对象，也就是上面程序①号代码的 e 变量是 null，也就是新放入的 Entry 对象指向 null，也就是没有产生 Entry 链。 /** * The table, resized as necessary. Length MUST Always be a power of two. */ transient Entry[] table; static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final K key; V value; Entry&lt;K,V&gt; next; final int hash; …… } 可以看出，Entry就是数组中的元素，每个 Map.Entry 其实就是一个key-value对，它持有一个指向下一个元素的引用，这就构成了链表。 JDK 源码在 JDK 安装目录下可以找到一个 src.zip 压缩文件，该文件里包含了 Java 基础类库的所有源文件。只要读者有学习兴趣，随时可以打开这份压缩文件来阅读 Java 类库的源代码，这对提高读者的编程能力是非常有帮助的。需要指出的是：src.zip 中包含的源代码并没有包含像上文中的中文注释，这些注释是笔者自己添加进去的。Hash 算法的性能选项根据上面代码可以看出，在同一个 bucket 存储 Entry 链的情况下，新放入的 Entry 总是位于 bucket 中，而最早放入该 bucket 中的 Entry 则位于这个 Entry 链的最末端。上面程序中还有这样两个变量： * size：该变量保存了该 HashMap 中所包含的 key-value 对的数量。 * threshold：该变量包含了 HashMap 能容纳的 key-value 对的极限，它的值等于 HashMap 的容量乘以负载因子（load factor）。 从上面程序中②号代码可以看出，当 size++ &gt;= threshold 时，HashMap 会自动调用 resize 方法扩充 HashMap 的容量。每扩充一次，HashMap 的容量就增大一倍。上面程序中使用的 table 其实就是一个普通数组，每个数组都有一个固定的长度，这个数组的长度就是 HashMap 的容量。HashMap 包含如下几个构造器： * HashMap()：构建一个初始容量为 16，负载因子为 0.75 的 HashMap。 * HashMap(int initialCapacity)：构建一个初始容量为 initialCapacity，负载因子为 0.75 的 HashMap。 * HashMap(int initialCapacity, float loadFactor)：以指定初始容量、指定的负载因子创建一个 HashMap。 当创建一个 HashMap 时，系统会自动创建一个 table 数组来保存 HashMap 中的 Entry，下面是 HashMap 中一个构造器的代码： // 以指定初始化容量、负载因子创建 HashMap public HashMap(int initialCapacity, float loadFactor) { // 初始容量不能为负数 if (initialCapacity &lt; 0) throw new IllegalArgumentException( &quot;Illegal initial capacity: &quot; + initialCapacity); // 如果初始容量大于最大容量，让出示容量 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // 负载因子必须大于 0 的数值 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException( loadFactor); // 计算出大于 initialCapacity 的最小的 2 的 n 次方值。 int capacity = 1; while (capacity &lt; initialCapacity) capacity &lt;&lt;= 1; this.loadFactor = loadFactor; // 设置容量极限等于容量 * 负载因子 threshold = (int)(capacity * loadFactor); // 初始化 table 数组 table = new Entry[capacity]; // ① init(); } 上面代码中粗体字代码包含了一个简洁的代码实现：找出大于 initialCapacity 的、最小的 2 的 n 次方值，并将其作为 HashMap 的实际容量（由 capacity 变量保存）。例如给定 initialCapacity 为 10，那么该 HashMap 的实际容量就是 16。程序①号代码处可以看到：table 的实质就是一个数组，一个长度为 capacity 的数组。对于 HashMap 及其子类而言，它们采用 Hash 算法来决定集合中元素的存储位置。当系统开始初始化 HashMap 时，系统会创建一个长度为 capacity 的 Entry 数组，这个数组里可以存储元素的位置被称为“桶（bucket）”，每个 bucket 都有其指定索引，系统可以根据其索引快速访问该 bucket 里存储的元素。无论何时，HashMap 的每个“桶”只存储一个元素（也就是一个 Entry），由于 Entry 对象可以包含一个引用变量（就是 Entry 构造器的的最后一个参数）用于指向下一个 Entry，因此可能出现的情况是：HashMap 的 bucket 中只有一个 Entry，但这个 Entry 指向另一个 Entry ——这就形成了一个 Entry 链。如图 1 所示： 图 1. HashMap 的存储示意HashMap 的读取实现当 HashMap 的每个 bucket 里存储的 Entry 只是单个 Entry ——也就是没有通过指针产生 Entry 链时，此时的 HashMap 具有最好的性能：当程序通过 key 取出对应 value 时，系统只要先计算出该 key 的 hashCode() 返回值，在根据该 hashCode 返回值找出该 key 在 table 数组中的索引，然后取出该索引处的 Entry，最后返回该 key 对应的 value 即可。看 HashMap 类的 get(K key) 方法代码： public V get(Object key) { // 如果 key 是 null，调用 getForNullKey 取出对应的 value if (key == null) return getForNullKey(); // 根据该 key 的 hashCode 值计算它的 hash 码 int hash = hash(key.hashCode()); // 直接取出 table 数组中指定索引处的值， for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; // 搜索该 Entry 链的下一个 Entr e = e.next) // ① { Object k; // 如果该 Entry 的 key 与被搜索 key 相同 if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) return e.value; } return null; } 从上面代码中可以看出，如果 HashMap 的每个 bucket 里只有一个 Entry 时，HashMap 可以根据索引、快速地取出该 bucket 里的 Entry；在发生“Hash 冲突”的情况下，单个 bucket 里存储的不是一个 Entry，而是一个 Entry 链，系统只能必须按顺序遍历每个 Entry，直到找到想搜索的 Entry 为止——如果恰好要搜索的 Entry 位于该 Entry 链的最末端（该 Entry 是最早放入该 bucket 中），那系统必须循环到最后才能找到该元素。 归纳起来简单地说，HashMap 在底层将 key-value 当成一个整体进行处理，这个整体就是一个 Entry 对象。HashMap 底层采用一个 Entry[] 数组来保存所有的 key-value 对，当需要存储一个 Entry 对象时，会根据 Hash 算法来决定其存储位置；当需要取出一个 Entry 时，也会根据 Hash 算法找到其存储位置，直接取出该 Entry。由此可见：HashMap 之所以能快速存、取它所包含的 Entry，完全类似于现实生活中母亲从小教我们的：不同的东西要放在不同的位置，需要时才能快速找到它。 当创建 HashMap 时，有一个默认的负载因子（load factor），其默认值为 0.75，这是时间和空间成本上一种折衷：增大负载因子可以减少 Hash 表（就是那个 Entry 数组）所占用的内存空间，但会增加查询数据的时间开销，而查询是最频繁的的操作（HashMap 的 get() 与 put() 方法都要用到查询）；减小负载因子会提高数据查询的性能，但会增加 Hash 表所占用的内存空间。 掌握了上面知识之后，我们可以在创建 HashMap 时根据实际需要适当地调整 load factor 的值；如果程序比较关心空间开销、内存比较紧张，可以适当地增加负载因子；如果程序比较关心时间开销，内存比较宽裕则可以适当的减少负载因子。通常情况下，程序员无需改变负载因子的值。如果开始就知道 HashMap 会保存多个 key-value 对，可以在创建时就使用较大的初始化容量，如果 HashMap 中 Entry 的数量一直不会超过极限容量（capacity * load factor），HashMap 就无需调用 resize() 方法重新分配 table 数组，从而保证较好的性能。当然，开始就将初始容量设置太高可能会浪费空间（系统需要创建一个长度为 capacity 的 Entry 数组），因此创建 HashMap 时初始化容量设置也需要小心对待。 总结：HashMap的实现原理： 利用key的hashCode重新hash计算出当前对象的元素在数组中的下标 存储时，如果出现hash值相同的key，此时有两种情况。(1)如果key相同，则覆盖原始值；(2)如果key不同（出现冲突），则将当前的key-value放入链表中 获取时，直接找到hash值对应的下标，在进一步判断key是否相同，从而找到对应值。 理解了以上过程就不难明白HashMap是如何解决hash冲突的问题，核心就是使用了数组的存储方式，然后将冲突的key的对象放入链表中，一旦发现冲突就在链表中做进一步的对比。]]></content>
  </entry>
  <entry>
    <title><![CDATA[利用Http协议和Ftp协议搭载一个远程的图片服务器]]></title>
    <url>%2F2018%2F09%2F27%2F%E5%88%A9%E7%94%A8Http%E5%8D%8F%E8%AE%AE%E5%92%8CFtp%E5%8D%8F%E8%AE%AE%E6%90%AD%E8%BD%BD%E4%B8%80%E4%B8%AA%E8%BF%9C%E7%A8%8B%E7%9A%84%E5%9B%BE%E7%89%87%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[我想换个Markdown的编辑器 前言初次尝试，收货颇丰，本篇文章写给初入服务器搭建的新手以及加深一下自己对整个过程的理解，希望对正在阅读的陌生人以及将来的自己一点帮助。 工具准备linux系统的虚拟机，本人使用centos 6.4nginx的压缩包 可以打开虚拟机上的网页下载或者本机使用xshell传过去(建议下载一个XSHELL 因为很多命令需要复制，需要把文档传过去) 服务器环境搭建ftp ftp服务需要vsftpd软件，可以直接在linux终端安装 添加一个ftp用户useradd ftpuser1yum -y install vsftpd 这样一个用户建完，可以用这个登录，记得用普通登录不要用匿名了。登录后默认的路径为 /home/ftpuser. 添加密码 passwd ftpuser输入两次密码后修改密码。 因为ftp默认的端口为21，而centos默认是没有开启的，所以要修改iptables文件[root@bogon ~]# vim /etc/sysconfig/iptables在行上面有22 -j ACCEPT 下面另起一行输入跟那行差不多的，只是把22换成21，然后：wq保存。 还要运行下,重启iptables[root@bogon ~]# service iptables restart 当然 如果你觉得你的服务器防火墙不重要可以全面关闭 service IPtables stop 外网是可以访问上去了，可是发现没法返回目录（使用ftp的主动模式，被动模式还是无法访问），也上传不了，因为selinux作怪了。修改selinux：执行以下命令查看状态：[root@bogon ~]# getsebool -a | grep ftpallow_ftpd_anon_write –&gt; offallow_ftpd_full_access –&gt; offallow_ftpd_use_cifs –&gt; offallow_ftpd_use_nfs –&gt; offftp_home_dir –&gt; offftpd_connect_db –&gt; offftpd_use_passive_mode –&gt; offhttpd_enable_ftp_server –&gt; offtftp_anon_write –&gt; off[root@bogon ~]#执行上面命令，再返回的结果看到两行都是off，代表，没有开启外网的访问[root@bogon ~]# setsebool -P allow_ftpd_full_access on[root@bogon ~]# setsebool -P ftp_home_dir on 设置开机启动vsftpd ftp服务[root@bogon ~]# chkconfig vsftpd on 现在可以尝试着使用ftp服务给服务器上传文件了 在编写java程序之前最好先使用一个软件测试一下ftp连接是否好使 FileZilla Client 下载 一路安装 需要填写的依次是 ip地址 用户名 密码 端口号 21 如果ftp好使的话右边就出现了文件目录 nginx nginx 是提供http服务访问的一个软件，需要配置好才能从本机通过url访问到linux上的文件。 nginx是C语言开发安装nginx需要先将官网下载的源码进行编译，编译依赖gcc环境，如果没有gcc环境，需要安装gcc： 1yum install gcc-c++ PCRE(Perl Compatible Regular Expressions)是一个Perl库，包括 perl 兼容的正则表达式库。nginx的http模块使用pcre来解析正则表达式，所以需要在linux上安装pcre库。 1yum install -y pcre pcre-devel 注：pcre-devel是使用pcre开发的一个二次开发库。nginx也需要此库。zlib zlib库提供了很多种压缩和解压缩的方式，nginx使用zlib对http包的内容进行gzip，所以需要在linux上安装zlib库。 1yum install -y zlib zlib-devel opensslOpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。nginx不仅支持http协议，还支持https（即在ssl协议上传输http），所以需要在linux安装openssl库。y1um install -y openssl openssl-devel 在linux上输入ll命令需要看到这个包。当前文件夹 打开终端 使用 tar -zvxf nginx-1.8.0.tar.gz 命令 tab可以自动补全 cd nginx-1.8.0 解压出来可以看到nginx里有一个configure配置文件 ./configure \–prefix=/usr/local/nginx \–pid-path=/var/run/nginx/nginx.pid \–lock-path=/var/lock/nginx.lock \–error-log-path=/var/log/nginx/error.log \–http-log-path=/var/log/nginx/access.log \–with-http_gzip_static_module \–http-client-body-temp-path=/var/temp/nginx/client \–http-proxy-temp-path=/var/temp/nginx/proxy \–http-fastcgi-temp-path=/var/temp/nginx/fastcgi \–http-uwsgi-temp-path=/var/temp/nginx/uwsgi \–http-scgi-temp-path=/var/temp/nginx/scgi 将这段代码复制进终端，完成安装配置再ll就发现多了一个Makefile文件，这就是可以执行的安装文件 接下来依次输入 12make make install 编译和安装 如果不知道安装到哪里可以输入whereis niginx 接下来可以执行nginx了 123cd /usr/local/nginx/sbin/./nginx 也可以手动进去这个文件目录开启 这时候可以查看nginx的状态了 输入虚拟机的ip地址可以直接看到nginx的欢迎界面如果要访问服务器需要关闭防火墙 1service IPtables stop 理论上输入在服务器上的url就可以访问文件了 ，但还需要进一步配置才能完成图片服务器 进入nginx的目录conf文件夹，输入vim nginx.conf 会出现编辑内容 前提是在root模式下 按i 开始编辑往下拉一点点 在server 标签下更改如下信息 1234location /images/ &#123; root /home/ftpuser/www/; autoindex on;&#125; 加这句话的目的是更改上传的图片位置，创建相应的文件夹 在nginx目录下html文件夹创建一个images的文件夹 1makdir images 需要重启 nginx 重新读取配置文件内容1./nginx -s reload 这时候按如下格式输入url就可以访问到你在linux服务器上的文件（图片了） 接下来 让我们看看项目是如何导通这两个服务的 1234567891011121314151617181920212223242526272829import java.io.File;import java.io.FileInputStream;import org.apache.commons.net.ftp.FTP;import org.apache.commons.net.ftp.FTPClient;import org.junit.Test;public class FTPTest &#123; @Test public void testftpClient() throws Exception&#123; //创建一个ftpclient对象 FTPClient ftpClient = new FTPClient(); //创建ftp链接 ftpClient.connect(&quot;192.168.19.131&quot;, 21); //登录ftp服务器,使用用户名和密码 ftpClient.login(&quot;ftpuser&quot;,&quot;1234&quot;); //上传文件 //设置上传的路径 ftpClient.changeWorkingDirectory(&quot;/home/ftpuser/www/images&quot;); //读取本地文件 ftpClient.setFileType(FTP.BINARY_FILE_TYPE); FileInputStream fileInputStream = new FileInputStream(new File(&quot;C:\\Users\\ky\\Desktop\\123.JPG&quot;)); ftpClient.storeFile(&quot;hello.jpg&quot;, fileInputStream);//第一个参数是服务器端文件名 //第二个参数是inputstream //关闭连接 ftpClient.logout(); &#125;&#125; 我先写了一个测试类 测试结果完美上传到指定路径 这个测试类就是传输的基本原理原理就是这么简单 但还是太过繁琐，完全可以设计一个封装类去简化操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118public class FtpUtil &#123; /** * Description: 向FTP服务器上传文件 * @param host FTP服务器hostname * @param port FTP服务器端口 * @param username FTP登录账号 * @param password FTP登录密码 * @param basePath FTP服务器基础目录 * @param filePath FTP服务器文件存放路径。例如分日期存放：/2015/01/01。文件的路径为basePath+filePath * @param filename 上传到FTP服务器上的文件名 * @param input 输入流 * @return 成功返回true，否则返回false */ public static boolean uploadFile(String host, int port, String username, String password, String basePath, String filePath, String filename, InputStream input) &#123; boolean result = false; FTPClient ftp = new FTPClient(); try &#123; int reply; ftp.connect(host, port);// 连接FTP服务器 // 如果采用默认端口，可以使用ftp.connect(host)的方式直接连接FTP服务器 ftp.login(username, password);// 登录 reply = ftp.getReplyCode(); if (!FTPReply.isPositiveCompletion(reply)) &#123; ftp.disconnect(); return result; &#125; //切换到上传目录 if (!ftp.changeWorkingDirectory(basePath+filePath)) &#123; //如果目录不存在创建目录 String[] dirs = filePath.split(&quot;/&quot;); String tempPath = basePath; for (String dir : dirs) &#123; if (null == dir || &quot;&quot;.equals(dir)) continue; tempPath += &quot;/&quot; + dir; if (!ftp.changeWorkingDirectory(tempPath)) &#123; if (!ftp.makeDirectory(tempPath)) &#123; return result; &#125; else &#123; ftp.changeWorkingDirectory(tempPath); &#125; &#125; &#125; &#125; //设置上传文件的类型为二进制类型 ftp.setFileType(FTP.BINARY_FILE_TYPE); //上传文件 if (!ftp.storeFile(filename, input)) &#123; return result; &#125; input.close(); ftp.logout(); result = true; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (ftp.isConnected()) &#123; try &#123; ftp.disconnect(); &#125; catch (IOException ioe) &#123; &#125; &#125; &#125; return result; &#125; /** * Description: 从FTP服务器下载文件 * @param host FTP服务器hostname * @param port FTP服务器端口 * @param username FTP登录账号 * @param password FTP登录密码 * @param remotePath FTP服务器上的相对路径 * @param fileName 要下载的文件名 * @param localPath 下载后保存到本地的路径 * @return */ public static boolean downloadFile(String host, int port, String username, String password, String remotePath, String fileName, String localPath) &#123; boolean result = false; FTPClient ftp = new FTPClient(); try &#123; int reply; ftp.connect(host, port); // 如果采用默认端口，可以使用ftp.connect(host)的方式直接连接FTP服务器 ftp.login(username, password);// 登录 reply = ftp.getReplyCode(); if (!FTPReply.isPositiveCompletion(reply)) &#123; ftp.disconnect(); return result; &#125; ftp.changeWorkingDirectory(remotePath);// 转移到FTP服务器目录 FTPFile[] fs = ftp.listFiles(); for (FTPFile ff : fs) &#123; if (ff.getName().equals(fileName)) &#123; File localFile = new File(localPath + &quot;/&quot; + ff.getName()); OutputStream is = new FileOutputStream(localFile); ftp.retrieveFile(ff.getName(), is); is.close(); &#125; &#125; ftp.logout(); result = true; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (ftp.isConnected()) &#123; try &#123; ftp.disconnect(); &#125; catch (IOException ioe) &#123; &#125; &#125; &#125; return result; &#125; 编写一个main方法测试可以使用12345678910 public static void main(String[] args) &#123; try &#123; FileInputStream in=new FileInputStream(new File(&quot;D:\\temp\\imagestest\\webapps\\images\\pictest.jpg&quot;)); boolean flag = uploadFile(&quot;192.168.19.131&quot;, 21, &quot;ftpuser&quot;, &quot;1234&quot;, &quot;/home/ftpuser/www/images&quot;,&quot;/2015/01/21&quot;, &quot;pictest.jpg&quot;, in); System.out.println(flag); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 接下来我们就要用这个ftputl工具类去开发 需要一个去满足jsp传入对象的形式的返回值,用来回显图片(使用http的服务返回一个路径)12345678910111213141516171819202122232425262728293031323334353637383940414243public class PictureResult &#123; /** * 上传图片返回值，成功：0 失败：1 */ private Integer error; /** * 回显图片使用的url */ private String url; /** * 错误时的错误消息 */ private String message; public PictureResult(Integer state, String url) &#123; this.url = url; this.error = state; &#125; public PictureResult(Integer state, String url, String errorMessage) &#123; this.url = url; this.error = state; this.message = errorMessage; &#125; public Integer getError() &#123; return error; &#125; public void setError(Integer error) &#123; this.error = error; &#125; public String getUrl() &#123; return url; &#125; public void setUrl(String url) &#123; this.url = url; &#125; public String getMessage() &#123; return message; &#125; public void setMessage(String message) &#123; this.message = message; &#125; &#125; service层先定义一个接口还有一个接口实现类1234public interface PictureService &#123; PictureResult uploadPicture(MultipartFile uploadfile) ;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Servicepublic class PictureServiceImpl implements PictureService &#123; @Value(&quot;$&#123;IMAGE_BASE_URL&#125;&quot;) private String IMAGE_BASE_URL; @Value(&quot;$&#123;FILI_UPLOAD_PATH&#125;&quot;) private String FILI_UPLOAD_PATH; @Value(&quot;$&#123;FTP_SERVER_IP&#125;&quot;) private String FTP_SERVER_IP; @Value(&quot;$&#123;FTP_PORT&#125;&quot;) private Integer FTP_PORT; @Value(&quot;$&#123;FTP_USERNAME&#125;&quot;) private String FTP_USERNAME; @Value(&quot;$&#123;FTP_PASSWORD&#125;&quot;) private String FTP_PASSWORD; @Override public PictureResult uploadPicture(MultipartFile uploadFile) &#123; // 上传文件功能实现 String path = savePicture(uploadFile); // 回显 PictureResult result = new PictureResult(0, IMAGE_BASE_URL + path); return result; &#125; private String savePicture(MultipartFile uploadFile) &#123; String result = null; try &#123; // 上传文件功能实现 // 判断文件是否为空 if (uploadFile.isEmpty()) return null; // 上传文件以日期为单位分开存放，可以提高图片的查询速度 String filePath = &quot;/&quot; + new SimpleDateFormat(&quot;yyyy&quot;).format(new Date()) + &quot;/&quot; + new SimpleDateFormat(&quot;MM&quot;).format(new Date()) + &quot;/&quot; + new SimpleDateFormat(&quot;dd&quot;).format(new Date()); // 取原始文件名 String originalFilename = uploadFile.getOriginalFilename(); // 新文件名 String newFileName = IDUtils.genImageName() + originalFilename.substring(originalFilename.lastIndexOf(&quot;.&quot;)); // 转存文件，上传到ftp服务器 FtpUtil.uploadFile(FTP_SERVER_IP, FTP_PORT, FTP_USERNAME, FTP_PASSWORD, FILI_UPLOAD_PATH, filePath, newFileName, uploadFile.getInputStream()); result = filePath + &quot;/&quot; + newFileName; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return result; &#125; controller层12345678910111213141516@Controller@RequestMapping(&quot;/pic&quot;)public class PictureController &#123; @Autowired private PictureService pictureService; @RequestMapping(&quot;/upload&quot;) @ResponseBody public PictureResult uploda(MultipartFile uploadFile) throws Exception &#123; //调用service上传图片 PictureResult pictureResult = pictureService.uploadPicture(uploadFile); //返回上传结果 return pictureResult; &#125; 需要定义功能映射路径和注入到service层 返回上传结果，如果能看到图片显示说明http服务成功搭建}]]></content>
      <categories>
        <category>经验总结</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java中修饰符的作用域及可见性]]></title>
    <url>%2F2018%2F09%2F27%2FJava%E4%B8%AD%E4%BF%AE%E9%A5%B0%E7%AC%A6%E7%9A%84%E4%BD%9C%E7%94%A8%E5%9F%9F%E5%8F%8A%E5%8F%AF%E8%A7%81%E6%80%A7%2F</url>
    <content type="text"><![CDATA[java中，针对不同的修饰词，类及其类中的方法、域都有不同的可见性。以下为针对java中可见性的几点总结。 publicpublic 修饰的成员可以在任何范围内直接访问，只是一种最宽松的访问控制等级。需要注意的，所谓的直接访问仍需要先创建或获得一个相应类的对象然后才可以使用”对象名.成员“的方式访问其属性或调用其方法，但是出于信息封装和隐藏的需要一般不提倡把成员声明为public的，而构造方法和需要外界直接调用的普通方法则适合声明为public. protectedprotected修饰的成员可以在其所在类中、同一包中及子类中（无论子类在不在同一个包）被直接访问，但不能在位于不同包中的非子类中被直接访问，这里需要特别声明：1在位于不同包的子类中必须是子类的对象才能直接访问其父类的protected成员，而父类自身的对象反而不能访问其所在类中声明的protected成员。 下面我就一个例子说明它: 12345678910111213141516171819202122232425262728源代码：A.javapackage p1;public class A&#123; public int m = 5; protected int n = 6;&#125;12345源程序：B.javapackage p2;import p1;public class B extends A&#123; public void mb()&#123; m = m + 1; n = n * 2; &#125; public static void main(String[] args)&#123; B b = new B(); b.m = 7; //合法 b.n = 8; //合法 A a = new A(); a.m = 9; //合法 a.n = 10; //不合法 &#125;&#125; 可以想象如果想让Java类中的成员在所在包中可以直接访问，且在其子类中也能访问（子类有可能和父类不再在一个包中），但不愿意在更大更范围内公开时，就可以声明为 protected. default缺省访问修饰符的成员只能在其所在类中或包中直接访问，在不同包中即使是不同包的子类也不能直接访问。 privateprivate成员只能在所在类中被直接访问，是4种访问等级最高的一个。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[JAVA 集合类 list map queue set 实用场景梳理]]></title>
    <url>%2F2018%2F09%2F26%2FJAVA%20%E9%9B%86%E5%90%88%E7%B1%BB%20list%20map%20queue%20set%20%E5%AE%9E%E7%94%A8%E5%9C%BA%E6%99%AF%E6%A2%B3%E7%90%86%2F</url>
    <content type="text"><![CDATA[Java集合类基本概念在编程中，常常需要集中存放多个数据。从传统意义上讲，数组是我们的一个很好的选择，前提是我们事先已经明确知道我们将要保存的对象的数量。一旦在数组初始化时指定了这个数组长度，这个数组长度就是不可变的，如果我们需要保存一个可以动态增长的数据(在编译时无法确定具体的数量)，java的集合类就是一个很好的设计方案了。 集合类主要负责保存、盛装其他数据，因此集合类也被称为容器类。所以的集合类都位于java.util包下，后来为了处理多线程环境下的并发安全问题，java5还在java.util.concurrent包下提供了一些多线程支持的集合类。 在学习Java中的集合类的API、编程原理的时候，我们一定要明白，”集合”是一个很古老的数学概念，它远远早于Java的出现。从数学概念的角度来理解集合能帮助我们更好的理解编程中什么时候该使用什么类型的集合类。 Java容器类类库的用途是”保存对象”，并将其划分为两个不同的概念：12345671) Collection一组&quot;对立&quot;的元素，通常这些元素都服从某种规则 1.1) List必须保持元素特定的顺序 1.2) Set不能有重复元素 1.3) Queue保持一个队列(先进先出)的顺序2) Map一组成对的&quot;键值对&quot;对象 Collection和Map的区别在于容器中每个位置保存的元素个数:121) Collection 每个位置只能保存一个元素(对象)2) Map保存的是&quot;键值对&quot;，就像一个小型数据库。我们可以通过&quot;键&quot;找到该键对应的&quot;值&quot; Java集合类架构层次关系1. Interface Iterable迭代器接口，这是Collection类的父接口。实现这个Iterable接口的对象允许使用foreach进行遍历，也就是说，所有的Collection集合对象都具有”foreach可遍历性”。这个Iterable接口只有一个方法:iterator()。它返回一个代表当前集合对象的泛型迭代器，用于之后的遍历操作. 1.1 CollectionCollection是最基本的集合接口，一个Collection代表一组Object的集合，这些Object被称作Collection的元素。Collection是一个接口，用以提供规范定义，不能被实例化使用 1) SetSet集合类似于一个罐子，”丢进”Set集合里的多个对象之间没有明显的顺序。Set继承自Collection接口，不能包含有重复元素(记住，这是整个Set类层次的共有属性)。 Set判断两个对象相同不是使用”==”运算符，而是根据equals方法。也就是说，我们在加入一个新元素的时候，如果这个新元素对象和Set中已有对象进行注意equals比较都返回false，则Set就会接受这个新元素对象，否则拒绝。 因为Set的这个制约，在使用Set集合的时候，应该注意两点：1) 为Set集合里的元素的实现类实现一个有效的equals(Object)方法、2) 对Set的构造函数，传入的Collection参数不能包含重复的元素 1.1) HashSetHashSet是Set接口的典型实现，HashSet使用HASH算法来存储集合中的元素，因此具有良好的存取和查找性能。当向HashSet集合中存入一个元素时，HashSet会调用该对象的hashCode()方法来得到该对象的hashCode值，然后根据该HashCode值决定该对象在HashSet中的存储位置。 值得主要的是，HashSet集合判断两个元素相等的标准是两个对象通过equals()方法比较相等，并且两个对象的hashCode()方法的返回值相等 1.1.1) LinkedHashSetLinkedHashSet集合也是根据元素的hashCode值来决定元素的存储位置，但和HashSet不同的是，它同时使用链表维护元素的次序，这样使得元素看起来是以插入的顺序保存的。 当遍历LinkedHashSet集合里的元素时，LinkedHashSet将会按元素的添加顺序来访问集合里的元素。 LinkedHashSet需要维护元素的插入顺序，因此性能略低于HashSet的性能，但在迭代访问Set里的全部元素时(遍历)将有很好的性能(链表很适合进行遍历) 1.2) SortedSet 此接口主要用于排序操作，即实现此接口的子类都属于排序的子类 1.2.1) TreeSetTreeSet是SortedSet接口的实现类，TreeSet可以确保集合元素处于排序状态 1.3) EnumSetEnumSet是一个专门为枚举类设计的集合类，EnumSet中所有元素都必须是指定枚举类型的枚举值，该枚举类型在创建EnumSet时显式、或隐式地指定。EnumSet的集合元素也是有序的，它们以枚举值在Enum类内的定义顺序来决定集合元素的顺序 2) ListList集合代表一个元素有序、可重复的集合，集合中每个元素都有其对应的顺序索引。List集合允许加入重复元素，因为它可以通过索引来访问指定位置的集合元素。List集合默认按元素的添加顺序设置元素的索引. 2.1) ArrayListArrayList是基于数组实现的List类，它封装了一个动态的增长的、允许再分配的Object[]数组。 2.2) VectorVector和ArrayList在用法上几乎完全相同，但由于Vector是一个古老的集合，所以Vector提供了一些方法名很长的方法，但随着JDK1.2以后，java提供了系统的集合框架，就将Vector改为实现List接口，统一归入集合框架体系中 2.2.1) StackStack是Vector提供的一个子类，用于模拟”栈”这种数据结构(LIFO后进先出) 2.3) LinkedListimplements List,Deque。实现List接口，能对它进行队列操作，即可以根据索引来随机访问集合中的元素。同时它还实现Deque接口，即能将LinkedList当作双端队列使用。自然也可以被当作”栈来使用” 3) QueueQueue用于模拟”队列”这种数据结构(先进先出 FIFO)。队列的头部保存着队列中存放时间最长的元素，队列的尾部保存着队列中存放时间最短的元素。新元素插入(offer)到队列的尾部，访问元素(poll)操作会返回队列头部的元素，队列不允许随机访问队列中的元素。结合生活中常见的排队就会很好理解这个概念 3.1) PriorityQueuePriorityQueue并不是一个比较标准的队列实现，PriorityQueue保存队列元素的顺序并不是按照加入队列的顺序，而是按照队列元素的大小进行重新排序，这点从它的类名也可以看出来 3.2) DequeDeque接口代表一个”双端队列”，双端队列可以同时从两端来添加、删除元素，因此Deque的实现类既可以当成队列使用、也可以当成栈使用 3.2.1) ArrayDeque是一个基于数组的双端队列，和ArrayList类似，它们的底层都采用一个动态的、可重分配的Object[]数组来存储集合元素，当集合元素超出该数组的容量时，系统会在底层重新分配一个Object[]数组来存储集合元素 3.2.2) LinkedList1.2 MapMap用于保存具有”映射关系”的数据，因此Map集合里保存着两组值，一组值用于保存Map里的key，另外一组值用于保存Map里的value。key和value都可以是任何引用类型的数据。Map的key不允许重复，即同一个Map对象的任何两个key通过equals方法比较结果总是返回false。 关于Map，我们要从代码复用的角度去理解，java是先实现了Map，然后通过包装了一个所有value都为null的Map就实现了Set集合Map的这些实现类和子接口中key集的存储形式和Set集合完全相同(即key不能重复)Map的这些实现类和子接口中value集的存储形式和List非常类似(即value可以重复、根据索引来查找) 1) HashMap和HashSet集合不能保证元素的顺序一样，HashMap也不能保证key-value对的顺序。并且类似于HashSet判断两个key是否相等的标准也是: 两个key通过equals()方法比较返回true、同时两个key的hashCode值也必须相等 1.1) LinkedHashMapLinkedHashMap也使用双向链表来维护key-value对的次序，该链表负责维护Map的迭代顺序，与key-value对的插入顺序一致(注意和TreeMap对所有的key-value进行排序进行区分) 2) Hashtable 是一个古老的Map实现类 2.1) PropertiesProperties对象在处理属性文件时特别方便(windows平台上的.ini文件)，Properties类可以把Map对象和属性文件关联起来，从而可以把Map对象中的key-value对写入到属性文件中，也可以把属性文件中的”属性名-属性值”加载到Map对象中 3) SortedMap正如Set接口派生出SortedSet子接口，SortedSet接口有一个TreeSet实现类一样，Map接口也派生出一个SortedMap子接口，SortedMap接口也有一个TreeMap实现类 3.1) TreeMapTreeMap就是一个红黑树数据结构，每个key-value对即作为红黑树的一个节点。TreeMap存储key-value对(节点)时，需要根据key对节点进行排序。TreeMap可以保证所有的key-value对处于有序状态。同样，TreeMap也有两种排序方式: 自然排序、定制排序 4) WeakHashMapWeakHashMap与HashMap的用法基本相似。区别在于，HashMap的key保留了对实际对象的”强引用”，这意味着只要该HashMap对象不被销毁，该HashMap所引用的对象就不会被垃圾回收。 但WeakHashMap的key只保留了对实际对象的弱引用，这意味着如果WeakHashMap对象的key所引用的对象没有被其他强引用变量所引用，则这些key所引用的对象可能被垃圾回收，当垃圾回收了该key所对应的实际对象之后，WeakHashMap也可能自动删除这些key所对应的key-value对 5) IdentityHashMapIdentityHashMap的实现机制与HashMap基本相似，在IdentityHashMap中，当且仅当两个key严格相等(key1==key2)时，IdentityHashMap才认为两个key相等 6) EnumMapEnumMap是一个与枚举类一起使用的Map实现，EnumMap中的所有key都必须是单个枚举类的枚举值。创建EnumMap时必须显式或隐式指定它对应的枚举类。EnumMap根据key的自然顺序 (即枚举值在枚举类中的定义顺序) Java集合类的应用场景代码HashSet12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import java.util.*; //类A的equals方法总是返回true,但没有重写其hashCode()方法。不能保证当前对象是HashSet中的唯一对象class A&#123; public boolean equals(Object obj) &#123; return true; &#125;&#125;//类B的hashCode()方法总是返回1,但没有重写其equals()方法。不能保证当前对象是HashSet中的唯一对象class B&#123; public int hashCode() &#123; return 1; &#125;&#125;//类C的hashCode()方法总是返回2,且有重写其equals()方法class C&#123; public int hashCode() &#123; return 2; &#125; public boolean equals(Object obj) &#123; return true; &#125;&#125;public class HashSetTest&#123; public static void main(String[] args) &#123; HashSet books = new HashSet(); //分别向books集合中添加两个A对象，两个B对象，两个C对象 books.add(new A()); books.add(new A()); books.add(new B()); books.add(new B()); books.add(new C()); books.add(new C()); System.out.println(books); &#125;&#125; result: [B@1, B@1, C@2, A@3bc257, A@785d65] 可以看到，如果两个对象通过equals()方法比较返回true，但这两个对象的hashCode()方法返回不同的hashCode值时，这将导致HashSet会把这两个对象保存在Hash表的不同位置，从而使对象可以添加成功，这就与Set集合的规则有些出入了。所以，我们要明确的是: equals()决定是否可以加入HashSet、而hashCode()决定存放的位置，它们两者必须同时满足才能允许一个新元素加入HashSet但是要注意的是: 如果两个对象的hashCode相同，但是它们的equlas返回值不同，HashSet会在这个位置用链式结构来保存多个对象。而HashSet访问集合元素时也是根据元素的HashCode值来快速定位的，这种链式结构会导致性能下降。 所以如果需要把某个类的对象保存到HashSet集合中，我们在重写这个类的equlas()方法和hashCode()方法时，应该尽量保证两个对象通过equals()方法比较返回true时，它们的hashCode()方法返回值也相等 LinkedHashSet123456789101112131415161718import java.util.*; public class LinkedHashSetTest&#123; public static void main(String[] args) &#123; LinkedHashSet books = new LinkedHashSet(); books.add(&quot;Java&quot;); books.add(&quot;LittleHann&quot;); System.out.println(books); //删除 Java books.remove(&quot;Java&quot;); //重新添加 Java books.add(&quot;Java&quot;); System.out.println(books); &#125;&#125; 与HashSet集合采用hash算法来决定元素的存储位置不同，TreeSet采用红黑树的数据结构来存储集合元素。TreeSet支持两种排序方式: 自然排序、定制排序 1. 自然排序:TreeSet会调用集合元素的compareTo(Object obj)方法来比较元素之间的大小关系，然后将集合元素按升序排序，即自然排序。如果试图把一个对象添加到TreeSet时，则该对象的类必须实现Comparable接口，否则程序会抛出异常。 当把一个对象加入TreeSet集合中时，TreeSet会调用该对象的compareTo(Object obj)方法与容器中的其他对象比较大小，然后根据红黑树结构找到它的存储位置。如果两个对象通过compareTo(Object obj)方法比较相等，新对象将无法添加到TreeSet集合中(牢记Set是不允许重复的概念)。 注意: 当需要把一个对象放入TreeSet中，重写该对象对应类的equals()方法时，应该保证该方法与compareTo(Object obj)方法有一致的结果，即如果两个对象通过equals()方法比较返回true时，这两个对象通过compareTo(Object obj)方法比较结果应该也为0(即相等) 看到这里，我们应该明白： 121) 对与Set来说，它定义了equals()为唯一性判断的标准，而对于到了具体的实现，HashSet、TreeSet来说，它们又会有自己特有的唯一性判断标准，只有同时满足了才能判定为唯一性2) 我们在操作这些集合类的时候，对和唯一性判断有关的函数重写要重点关注 2. 定制排序TreeSet的自然排序是根据集合元素的大小，TreeSet将它们以升序排序。如果我们需要实现定制排序，则可以通过Comparator接口的帮助(类似PHP中的array_map回调处理函数的思想)。该接口里包含一个int compare(T o1， T o2)方法，该方法用于比较大小 123456789101112131415161718192021222324252627282930313233343536import java.util.*;class M&#123; int age; public M(int age) &#123; this.age = age; &#125; public String toString() &#123; return &quot;M[age:&quot; + age + &quot;]&quot;; &#125;&#125;public class TreeSetTest4&#123; public static void main(String[] args) &#123; TreeSet ts = new TreeSet(new Comparator() &#123; //根据M对象的age属性来决定大小 public int compare(Object o1, Object o2) &#123; M m1 = (M)o1; M m2 = (M)o2; return m1.age &gt; m2.age ? -1 : m1.age &lt; m2.age ? 1 : 0; &#125; &#125;); ts.add(new M(5)); ts.add(new M(-3)); ts.add(new M(9)); System.out.println(ts); &#125;&#125; 看到这里，我们需要梳理一下关于排序的概念 1231) equals、compareTo决定的是怎么比的问题，即用什么field进行大小比较2) 自然排序、定制排序、Comparator决定的是谁大的问题，即按什么顺序(升序、降序)进行排序它们的关注点是不同的，一定要注意区分 EnumSet1234567891011121314151617181920212223242526272829303132333435363738394041import java.util.*;enum Season&#123; SPRING,SUMMER,FALL,WINTER&#125;public class EnumSetTest&#123; public static void main(String[] args) &#123; //创建一个EnumSet集合，集合元素就是Season枚举类的全部枚举值 EnumSet es1 = EnumSet.allOf(Season.class); //输出[SPRING,SUMMER,FALL,WINTER] System.out.println(es1); //创建一个EnumSet空集合，指定其集合元素是Season类的枚举值。 EnumSet es2 = EnumSet.noneOf(Season.class); //输出[] System.out.println(es2); //手动添加两个元素 es2.add(Season.WINTER); es2.add(Season.SPRING); //输出[SPRING,WINTER] System.out.println(es2); //以指定枚举值创建EnumSet集合 EnumSet es3 = EnumSet.of(Season.SUMMER , Season.WINTER); //输出[SUMMER,WINTER] System.out.println(es3); EnumSet es4 = EnumSet.range(Season.SUMMER , Season.WINTER); //输出[SUMMER,FALL,WINTER] System.out.println(es4); //新创建的EnumSet集合的元素和es4集合的元素有相同类型， //es5的集合元素 + es4集合元素 = Season枚举类的全部枚举值 EnumSet es5 = EnumSet.complementOf(es4); //输出[SPRING] System.out.println(es5); &#125;&#125; 以上就是Set集合类的编程应用场景。那么应该怎样选择何时使用这些集合类呢？ 123451) HashSet的性能总是比TreeSet好(特别是最常用的添加、查询元素等操作)，因为TreeSet需要额外的红黑树算法来维护集合元素的次序。只有当需要一个保持排序的Set时，才应该使用TreeSet，否则都应该使用HashSet2) 对于普通的插入、删除操作，LinkedHashSet比HashSet要略慢一点，这是由维护链表所带来的开销造成的。不过，因为有了链表的存在，遍历LinkedHashSet会更快3) EnumSet是所有Set实现类中性能最好的，但它只能保存同一个枚举类的枚举值作为集合元素4) HashSet、TreeSet、EnumSet都是&quot;线程不安全&quot;的，通常可以通过Collections工具类的synchronizedSortedSet方法来&quot;包装&quot;该Set集合。SortedSet s = Collections.synchronizedSortedSet(new TreeSet(...)); ArrayList如果一开始就知道ArrayList集合需要保存多少元素，则可以在创建它们时就指定initialCapacity大小，这样可以减少重新分配的次数，提供性能，ArrayList还提供了如下方法来重新分配Object[]数组 121) ensureCapacity(int minCapacity): 将ArrayList集合的Object[]数组长度增加minCapacity2) trimToSize(): 调整ArrayList集合的Object[]数组长度为当前元素的个数。程序可以通过此方法来减少ArrayList集合对象占用的内存空间 12345678910111213141516171819202122232425262728293031323334import java.util.*;public class ListTest&#123; public static void main(String[] args) &#123; List books = new ArrayList(); //向books集合中添加三个元素 books.add(new String(&quot;轻量级Java EE企业应用实战&quot;)); books.add(new String(&quot;疯狂Java讲义&quot;)); books.add(new String(&quot;疯狂Android讲义&quot;)); System.out.println(books); //将新字符串对象插入在第二个位置 books.add(1 , new String(&quot;疯狂Ajax讲义&quot;)); for (int i = 0 ; i &lt; books.size() ; i++ ) &#123; System.out.println(books.get(i)); &#125; //删除第三个元素 books.remove(2); System.out.println(books); //判断指定元素在List集合中位置：输出1，表明位于第二位 System.out.println(books.indexOf(new String(&quot;疯狂Ajax讲义&quot;))); //① //将第二个元素替换成新的字符串对象 books.set(1, new String(&quot;LittleHann&quot;)); System.out.println(books); //将books集合的第二个元素（包括） //到第三个元素（不包括）截取成子集合 System.out.println(books.subList(1 , 2)); &#125; Stack注意Stack的后进先出的特点 12345678910111213141516171819202122232425262728import java.util.*;public class VectorTest&#123; public static void main(String[] args) &#123; Stack v = new Stack(); //依次将三个元素push入&quot;栈&quot; v.push(&quot;疯狂Java讲义&quot;); v.push(&quot;轻量级Java EE企业应用实战&quot;); v.push(&quot;疯狂Android讲义&quot;); //输出：[疯狂Java讲义, 轻量级Java EE企业应用实战 , 疯狂Android讲义] System.out.println(v); //访问第一个元素，但并不将其pop出&quot;栈&quot;，输出：疯狂Android讲义 System.out.println(v.peek()); //依然输出：[疯狂Java讲义, 轻量级Java EE企业应用实战 , 疯狂Android讲义] System.out.println(v); //pop出第一个元素，输出：疯狂Android讲义 System.out.println(v.pop()); //输出：[疯狂Java讲义, 轻量级Java EE企业应用实战] System.out.println(v); &#125;&#125; LinkedList 复制代码import java.util.*; public class LinkedListTest{ public static void main(String[] args) { LinkedList books = new LinkedList(); //将字符串元素加入队列的尾部(双端队列) books.offer(&quot;疯狂Java讲义&quot;); //将一个字符串元素加入栈的顶部(双端队列) books.push(&quot;轻量级Java EE企业应用实战&quot;); //将字符串元素添加到队列的头(相当于栈的顶部) books.offerFirst(&quot;疯狂Android讲义&quot;); for (int i = 0; i &lt; books.size() ; i++ ) { System.out.println(books.get(i)); } //访问、并不删除栈顶的元素 System.out.println(books.peekFirst()); //访问、并不删除队列的最后一个元素 System.out.println(books.peekLast()); //将栈顶的元素弹出&quot;栈&quot; System.out.println(books.pop()); //下面输出将看到队列中第一个元素被删除 System.out.println(books); //访问、并删除队列的最后一个元素 System.out.println(books.pollLast()); //下面输出将看到队列中只剩下中间一个元素： //轻量级Java EE企业应用实战 System.out.println(books); } }复制代码从代码中我们可以看到，LinkedList同时表现出了双端队列、栈的用法。功能非常强大 0x3: Queue PriorityQueue 复制代码import java.util.*; public class PriorityQueueTest{ public static void main(String[] args) { PriorityQueue pq = new PriorityQueue(); //下面代码依次向pq中加入四个元素 pq.offer(6); pq.offer(-3); pq.offer(9); pq.offer(0); //输出pq队列，并不是按元素的加入顺序排列， //而是按元素的大小顺序排列，输出[-3, 0, 9, 6] System.out.println(pq); //访问队列第一个元素，其实就是队列中最小的元素：-3 System.out.println(pq.poll()); } }复制代码PriorityQueue不允许插入null元素，它还需要对队列元素进行排序，PriorityQueue的元素有两种排序方式 1) 自然排序:采用自然顺序的PriorityQueue集合中的元素对象都必须实现了Comparable接口，而且应该是同一个类的多个实例，否则可能导致ClassCastException异常2) 定制排序创建PriorityQueue队列时，传入一个Comparator对象，该对象负责对队列中的所有元素进行排序关于自然排序、定制排序的原理和之前说的TreeSet类似 ArrayDeque 复制代码import java.util.*; public class ArrayDequeTest{ public static void main(String[] args) { ArrayDeque stack = new ArrayDeque(); //依次将三个元素push入”栈” stack.push(“疯狂Java讲义”); stack.push(“轻量级Java EE企业应用实战”); stack.push(“疯狂Android讲义”); //输出：[疯狂Java讲义, 轻量级Java EE企业应用实战 , 疯狂Android讲义] System.out.println(stack); //访问第一个元素，但并不将其pop出&quot;栈&quot;，输出：疯狂Android讲义 System.out.println(stack.peek()); //依然输出：[疯狂Java讲义, 轻量级Java EE企业应用实战 , 疯狂Android讲义] System.out.println(stack); //pop出第一个元素，输出：疯狂Android讲义 System.out.println(stack.pop()); //输出：[疯狂Java讲义, 轻量级Java EE企业应用实战] System.out.println(stack); } }复制代码以上就是List集合类的编程应用场景。我们来梳理一下思路 1234561. java提供的List就是一个&quot;线性表接口&quot;，ArrayList(基于数组的线性表)、LinkedList(基于链的线性表)是线性表的两种典型实现2. Queue代表了队列，Deque代表了双端队列(既可以作为队列使用、也可以作为栈使用)3. 因为数组以一块连续内存来保存所有的数组元素，所以数组在随机访问时性能最好。所以的内部以数组作为底层实现的集合在随机访问时性能最好。4. 内部以链表作为底层实现的集合在执行插入、删除操作时有很好的性能5. 进行迭代操作时，以链表作为底层实现的集合比以数组作为底层实现的集合性能好我们之前说过，Collection接口继承了Iterable接口，也就是说，我们以上学习到的所有的Collection集合类都具有&quot;可遍历性&quot; Iterable接口也是java集合框架的成员，它隐藏了各种Collection实现类的底层细节，向应用程序提供了遍历Collection集合元素的统一编程接口: 1231) boolean hasNext(): 是否还有下一个未遍历过的元素2) Object next(): 返回集合里的下一个元素3) void remove(): 删除集合里上一次next方法返回的元素 iterator实现遍历: 复制代码 1234567891011121314151617181920212223242526272829303132import java.util.*;public class IteratorTest&#123; public static void main(String[] args) &#123; //创建一个集合 Collection books = new HashSet(); books.add(&quot;轻量级Java EE企业应用实战&quot;); books.add(&quot;疯狂Java讲义&quot;); books.add(&quot;疯狂Android讲义&quot;); //获取books集合对应的迭代器 Iterator it = books.iterator(); while(it.hasNext()) &#123; //it.next()方法返回的数据类型是Object类型， //需要强制类型转换 String book = (String)it.next(); System.out.println(book); if (book.equals(&quot;疯狂Java讲义&quot;)) &#123; //从集合中删除上一次next方法返回的元素 it.remove(); &#125; //对book变量赋值，不会改变集合元素本身 book = &quot;测试字符串&quot;; &#125; System.out.println(books); &#125;&#125; 从代码可以看出，iterator必须依附于Collection对象，若有一个iterator对象，必然有一个与之关联的Collection对象。 除了可以使用iterator接口迭代访问Collection集合里的元素之外，使用java5提供的foreach循环迭代访问集合元素更加便捷 foreach实现遍历:1234567891011121314151617181920212223242526import java.util.*;public class ForeachTest&#123; public static void main(String[] args) &#123; //创建一个集合 Collection books = new HashSet(); books.add(new String(&quot;轻量级Java EE企业应用实战&quot;)); books.add(new String(&quot;疯狂Java讲义&quot;)); books.add(new String(&quot;疯狂Android讲义&quot;)); for (Object obj : books) &#123; //此处的book变量也不是集合元素本身 String book = (String)obj; System.out.println(book); if (book.equals(&quot;疯狂Android讲义&quot;)) &#123; //下面代码会引发ConcurrentModificationException异常 //books.remove(book); &#125; &#125; System.out.println(books); &#125;&#125; 除了Collection固有的iterator()方法，List还额外提供了一个listIterator()方法，该方法返回一个ListIterator对象，ListIterator接口继承了Iterator接口，提供了专门操作List的方法。ListIterator接口在Iterator接口的继承上增加了如下方法: 1) boolean hasPrevious(): 返回该迭代器关联的集合是否还有上一个元素2) Object previous(): 返回该迭代器的上一个元素(向前迭代)3) void add(): 在指定位置插入一个元素ListIterator实现遍历: 复制代码import java.util.*; public class ListIteratorTest{ public static void main(String[] args) { String[] books = { “疯狂Java讲义”, “轻量级Java EE企业应用实战” }; List bookList = new ArrayList(); for (int i = 0; i &lt; books.length ; i++ ) { bookList.add(books[i]); } ListIterator lit = bookList.listIterator(); while (lit.hasNext()) { System.out.println(lit.next()); lit.add(“——-分隔符——-“); } System.out.println(“=======下面开始反向迭代=======”); while(lit.hasPrevious()) { System.out.println(lit.previous()); } }}复制代码 0x4: Map HashMap、Hashtable 复制代码import java.util.*; class A{ int count; public A(int count) { this.count = count; } //根据count的值来判断两个对象是否相等。 public boolean equals(Object obj) { if (obj == this) return true; if (obj!=null &amp;&amp; obj.getClass()==A.class) { A a = (A)obj; return this.count == a.count; } return false; } //根据count来计算hashCode值。 public int hashCode() { return this.count; }}class B{ //重写equals()方法，B对象与任何对象通过equals()方法比较都相等 public boolean equals(Object obj) { return true; }}public class HashtableTest{ public static void main(String[] args) { Hashtable ht = new Hashtable(); ht.put(new A(60000) , “疯狂Java讲义”); ht.put(new A(87563) , “轻量级Java EE企业应用实战”); ht.put(new A(1232) , new B()); System.out.println(ht); //只要两个对象通过equals比较返回true， //Hashtable就认为它们是相等的value。 //由于Hashtable中有一个B对象， //它与任何对象通过equals比较都相等，所以下面输出true。 System.out.println(ht.containsValue(&quot;测试字符串&quot;)); //① //只要两个A对象的count相等，它们通过equals比较返回true，且hashCode相等 //Hashtable即认为它们是相同的key，所以下面输出true。 System.out.println(ht.containsKey(new A(87563))); //② //下面语句可以删除最后一个key-value对 ht.remove(new A(1232)); //③ //通过返回Hashtable的所有key组成的Set集合， //从而遍历Hashtable每个key-value对 for (Object key : ht.keySet()) { System.out.print(key + &quot;----&gt;&quot;); System.out.print(ht.get(key) + &quot;\n&quot;); } } }复制代码当使用自定义类作为HashMap、Hashtable的key时，如果重写该类的equals(Object obj)和hashCode()方法，则应该保证两个方法的判断标准一致–当两个key通过equals()方法比较返回true时，两个key的hashCode()的返回值也应该相同 LinkedHashMap 复制代码import java.util.*; public class LinkedHashMapTest{ public static void main(String[] args) { LinkedHashMap scores = new LinkedHashMap(); scores.put(“语文” , 80); scores.put(“英文” , 82); scores.put(“数学” , 76); //遍历scores里的所有的key-value对 for (Object key : scores.keySet()) { System.out.println(key + “——&gt;” + scores.get(key)); } }}复制代码Properties 复制代码import java.util.;import java.io.; public class PropertiesTest{ public static void main(String[] args) throws Exception { Properties props = new Properties(); //向Properties中增加属性 props.setProperty(“username” , “yeeku”); props.setProperty(“password” , “123456”); //将Properties中的key-value对保存到a.ini文件中 props.store(new FileOutputStream(&quot;a.ini&quot;), &quot;comment line&quot;); //① //新建一个Properties对象 Properties props2 = new Properties(); //向Properties中增加属性 props2.setProperty(&quot;gender&quot; , &quot;male&quot;); //将a.ini文件中的key-value对追加到props2中 props2.load(new FileInputStream(&quot;a.ini&quot;) ); //② System.out.println(props2); } }复制代码Properties还可以把key-value对以XML文件的形式保存起来，也可以从XML文件中加载key-value对 TreeMap 复制代码import java.util.*; class R implements Comparable{ int count; public R(int count) { this.count = count; } public String toString() { return “R[count:” + count + “]”; } //根据count来判断两个对象是否相等。 public boolean equals(Object obj) { if (this == obj) return true; if (obj!=null &amp;&amp; obj.getClass()==R.class) { R r = (R)obj; return r.count == this.count; } return false; } //根据count属性值来判断两个对象的大小。 public int compareTo(Object obj) { R r = (R)obj; return count &gt; r.count ? 1 : count &lt; r.count ? -1 : 0; }}public class TreeMapTest{ public static void main(String[] args) { TreeMap tm = new TreeMap(); tm.put(new R(3) , “轻量级Java EE企业应用实战”); tm.put(new R(-5) , “疯狂Java讲义”); tm.put(new R(9) , “疯狂Android讲义”); System.out.println(tm); //返回该TreeMap的第一个Entry对象 System.out.println(tm.firstEntry()); //返回该TreeMap的最后一个key值 System.out.println(tm.lastKey()); //返回该TreeMap的比new R(2)大的最小key值。 System.out.println(tm.higherKey(new R(2))); //返回该TreeMap的比new R(2)小的最大的key-value对。 System.out.println(tm.lowerEntry(new R(2))); //返回该TreeMap的子TreeMap System.out.println(tm.subMap(new R(-1) , new R(4))); } }复制代码从代码中可以看出，类似于TreeSet中判断两个元素是否相等的标准，TreeMap中判断两个key相等的标准是: 1) 两个key通过compareTo()方法返回02) equals()放回true我们在重写这两个方法的时候一定要保证它们的逻辑关系一致。 再次强调一下: Set和Map的关系十分密切，java源码就是先实现了HashMap、TreeMap等集合，然后通过包装一个所有的value都为null的Map集合实现了Set集合类WeakHashMap 复制代码import java.util.*; public class WeakHashMapTest{ public static void main(String[] args) { WeakHashMap whm = new WeakHashMap(); //将WeakHashMap中添加三个key-value对， //三个key都是匿名字符串对象（没有其他引用） whm.put(new String(“语文”) , new String(“良好”)); whm.put(new String(“数学”) , new String(“及格”)); whm.put(new String(“英文”) , new String(“中等”)); //将WeakHashMap中添加一个key-value对， //该key是一个系统缓存的字符串对象。&quot;java&quot;是一个常量字符串强引用 whm.put(&quot;java&quot; , new String(&quot;中等&quot;)); //输出whm对象，将看到4个key-value对。 System.out.println(whm); //通知系统立即进行垃圾回收 System.gc(); System.runFinalization(); //通常情况下，将只看到一个key-value对。 System.out.println(whm); } }复制代码如果需要使用WeakHashMap的key来保留对象的弱引用，则不要让key所引用的对象具有任何强引用，否则将失去使用WeakHashMap的意义 IdentityHashMap 复制代码import java.util.*; public class IdentityHashMapTest{ public static void main(String[] args) { IdentityHashMap ihm = new IdentityHashMap(); //下面两行代码将会向IdentityHashMap对象中添加两个key-value对 ihm.put(new String(“语文”) , 89); ihm.put(new String(“语文”) , 78); //下面两行代码只会向IdentityHashMap对象中添加一个key-value对 ihm.put(&quot;java&quot; , 93); ihm.put(&quot;java&quot; , 98); System.out.println(ihm); } }复制代码EnumMap 复制代码import java.util.*; enum Season{ SPRING,SUMMER,FALL,WINTER}public class EnumMapTest{ public static void main(String[] args) { //创建一个EnumMap对象，该EnumMap的所有key //必须是Season枚举类的枚举值 EnumMap enumMap = new EnumMap(Season.class); enumMap.put(Season.SUMMER , “夏日炎炎”); enumMap.put(Season.SPRING , “春暖花开”); System.out.println(enumMap); }}复制代码与创建普通Map有所区别的是，创建EnumMap是必须指定一个枚举类，从而将该EnumMap和指定枚举类关联起来 以上就是Map集合类的编程应用场景。我们来梳理一下思路 1) HashMap和Hashtable的效率大致相同，因为它们的实现机制几乎完全一样。但HashMap通常比Hashtable要快一点，因为Hashtable需要额外的线程同步控制2) TreeMap通常比HashMap、Hashtable要慢(尤其是在插入、删除key-value对时更慢)，因为TreeMap底层采用红黑树来管理key-value对3) 使用TreeMap的一个好处就是： TreeMap中的key-value对总是处于有序状态，无须专门进行排序操作]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[TreeSet详细介绍(源码解析)和使用示例]]></title>
    <url>%2F2018%2F09%2F26%2Ftreeset%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D(%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90)%E5%92%8C%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[有志不在年高 TreeSet介绍简介 TreeSet 是一个有序的集合，它的作用是提供有序的Set集合。 它继承于AbstractSet抽象类，实现了NavigableSet, Cloneable, java.io.Serializable接口。 TreeSet 继承于AbstractSet，所以它是一个Set集合，具有Set的属性和方法。 TreeSet 实现了NavigableSet接口，意味着它支持一系列的导航方法。比如查找与指定目标最匹配项。 TreeSet 实现了Cloneable接口，意味着它能被克隆。 TreeSet 实现了java.io.Serializable接口，意味着它支持序列化。 TreeSet是基于TreeMap实现的。TreeSet中的元素支持2种排序方式：自然排序 或者 根据创建TreeSet 时提供的 Comparator 进行排序。这取决于使用的构造方法。 TreeSet为基本操作（add、remove 和 contains）提供受保证的 log(n) 时间开销。另外，TreeSet是非同步的。 它的iterator 方法返回的迭代器是fail-fast的。 构造函数1234567891011// 默认构造函数。使用该构造函数，TreeSet中的元素按照自然排序进行排列。TreeSet()// 创建的TreeSet包含collectionTreeSet(Collection&lt;? extends E&gt; collection)// 指定TreeSet的比较器TreeSet(Comparator&lt;? super E&gt; comparator)// 创建的TreeSet包含setTreeSet(SortedSet&lt;E&gt; set) (01) TreeSet实际上是TreeMap实现的。当我们构造TreeSet时；若使用不带参数的构造函数，则TreeSet的使用自然比较器；若用户需要使用自定义的比较器，则需要使用带比较器的参数。(02) TreeSet是非线程安全的。(03) TreeSet实现java.io.Serializable的方式。当写入到输出流时，依次写入“比较器、容量、全部元素”；当读出输入流时，再依次读取。 TreeSet遍历方式1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.util.*;public class TreeSetIteratorTest &#123; public static void main(String[] args) &#123; TreeSet set = new TreeSet(); set.add(&quot;aaa&quot;); set.add(&quot;aaa&quot;); set.add(&quot;bbb&quot;); set.add(&quot;eee&quot;); set.add(&quot;ddd&quot;); set.add(&quot;ccc&quot;); // 顺序遍历TreeSet ascIteratorThroughIterator(set) ; // 逆序遍历TreeSet descIteratorThroughIterator(set); // 通过for-each遍历TreeSet。不推荐！此方法需要先将Set转换为数组 foreachTreeSet(set); &#125; // 顺序遍历TreeSet public static void ascIteratorThroughIterator(TreeSet set) &#123; System.out.print(&quot;\n ---- Ascend Iterator ----\n&quot;); for(Iterator iter = set.iterator(); iter.hasNext(); ) &#123; System.out.printf(&quot;asc : %s\n&quot;, iter.next()); &#125; &#125; // 逆序遍历TreeSet public static void descIteratorThroughIterator(TreeSet set) &#123; System.out.printf(&quot;\n ---- Descend Iterator ----\n&quot;); for(Iterator iter = set.descendingIterator(); iter.hasNext(); ) System.out.printf(&quot;desc : %s\n&quot;, (String)iter.next()); &#125; // 通过for-each遍历TreeSet。不推荐！此方法需要先将Set转换为数组 private static void foreachTreeSet(TreeSet set) &#123; System.out.printf(&quot;\n ---- For-each ----\n&quot;); String[] arr = (String[])set.toArray(new String[0]); for (String str:arr) System.out.printf(&quot;for each : %s\n&quot;, str); &#125;&#125; 结果 —- Ascend Iterator —-asc : aaaasc : bbbasc : cccasc : dddasc : eee —- Descend Iterator —-desc : eeedesc : ddddesc : cccdesc : bbbdesc : aaa —- For-each —-for each : aaafor each : bbbfor each : cccfor each : dddfor each : eee Set中不允许重复元素下面是支持 TreeSet 类的构造函数。序号 | 构造函数的说明—|—1 | TreeSet （) 此构造函数构造空树集，将在根据其元素的自然顺序按升序排序。 2 | TreeSet (集合c)此构造函数生成树的集合，它包含素的集合 c。 3 | TreeSet (比较器 comp)此构造函数构造一个空树集，将根据给定的比较器进行排序。 4 | TreeSet (SortedSet ss)此构造函数生成包含给定 SortedSet 的元素 TreeSet TreeSet的方法总结： 修饰符和类型 方法和描述 boolean add(E e)将指定的元素添加到这套，如果它已不存在。 boolean addAll(Collection&lt;? extends E&gt; c)在加入这一组指定的集合中添加的所有元素。 E ceiling(E e)返回最小的元素在这一组大于或等于给定的元素，则null如果没有这样的元素。 void clear()从这一组中移除所有元素。 Object clone()返回此TreeSet实例浅表副本。 Comparator&lt;? super E&gt; comparator()返回用于排序在这集，或空元素，如果这套使用自然排序其元素的比较。 boolean contains(Object o)如果此集合包含指定的元素，则返回true 。 Iterator descendingIterator()返回迭代器中这套降序排序的元素。 NavigableSet descendingSet()返回逆序视图中包含的元素这一套。 E first()返回第一个 （最低） 元素当前在这一套。 E floor(E e)返回的最大元素在这一组小于或等于null如果没有这样的元素。 SortedSet headSet(E toElement)返回其元素是严格小于toElement这套的部分视图.NavigableSet headSet(E toElement, boolean inclusive)返回一个视图的这部分设置的元素都小于 （或等于，如果inclusive是真的） toElement.E higher(E e)返回最小的元素在这套严格大于给定的元素，则null如果没有这样的元素。boolean isEmpty()如果此集不包含任何元素，则返回true 。Iterator iterator()返回迭代器中这套以升序排序的元素。E last()在这套目前返回的最后一个 （最高） 的元素。E lower(E e)在这一套严格的小于给定的元素，则null返回的最大元素，如果没有这样的元素。E pollFirst()检索和删除第一个 （最低） 元素，或如果此集合为空，则返回null 。E pollLast()检索和删除的最后一个 （最高） 的元素，或如果此集合为空，则返回null 。boolean remove(Object o)从这一组中移除指定的元素，如果它存在。int size()在这套 （其基数） 中返回的元素的数目。NavigableSet subSet(E fromElement, boolean fromInclusive, E toElement, boolean toInclusive)返回此集的部分视图的元素范围从fromElement到toElement.SortedSet subSet(E fromElement, E toElement)返回视图的部分的这一套的元素范围从fromElement，具有包容性，到toElement，独家。SortedSet tailSet(E fromElement)返回其元素是大于或等于fromElement这套的部分视图.NavigableSet tailSet(E fromElement, boolean inclusive)返回其元素是大于 （或等于，如果inclusive是真的） 这套的部分视图f]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[taotao项目搭建 SSM框架的maven项目]]></title>
    <url>%2F2018%2F09%2F25%2Ftaotao%E9%A1%B9%E7%9B%AE%E6%90%AD%E5%BB%BA%20SSM%E6%A1%86%E6%9E%B6%E7%9A%84maven%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[概述：淘淘商城是采用分布式架构部署的一个大型网上商城系统，类似于京东商城。本系统分前台系统和后台系统。前台系统主要负责商城的页面的显示功能，这里采用的面向服务的方式，pc端手机端只负责显示页面，业务逻辑都在服务层实现，客户端调用服务端接口来实现显示功能。 框架这里采用maven来管理整个项目。优势两点：1、maven可以以管理整个项目工程，方便热部署项目，项目发布方便。2、maven管理你jar包具有很大的优势，可以自动下载所需的jar包，只需定义好版本即可，其他maven自动下载。 利用SSM框架来搭建工程：利用框架搭建工程主要分两步：框架所依赖的jar包，框架的配置文件。弄清了这两点就好办了。框架主要分三层：dao层（mybatis）（主要是与数据库打交道）、service层（spring）（主要是负责调用dao层，实现业务逻辑的编写）、controller层（springMVC）（这里主要调用service层，根据jsp页面的内容，将jsp的内容传递到service层，然后讲数据显示到jsp页面）。所以这里的配置文件也就：mybatis的SqlMapConfig.xml （主要是它的插件配置，数据库配置放在dao）。spring将mybatis和springMVC整合起来的application_context_dao.xml（配置数据源，与数据库的连接），application_context_service.xml（将service的文件包引入工程）。application_context_transation.xml（这里将事务独立出来，主要是事务的配置） SpringMVC.xml（主要是前端控制器，试图解析器的配置） 框架搭建完成后，利用mybatis的逆向工程生成各个表的mapper.xml和mapper.java文件、pojo文件。 实现2、具体的功能的实现逻辑 （1）后台系统功能实现 （这里主要讲商品的查询、添加、规格参数、CMS系统的分类、添加） 其实对于功能模块的分析主要有三点： 从哪个数据表获取（主要mapper实现）；页面传递是否有参数，页面的url是什么（controller实现）；返回值是什么（即页面展示的格式是什么样子的，这个根据jsp使用的框架来决定，比如这里的easyUI，可以查询它的api文档，找到其返回值类型）； A、商品的查询逻辑分析：其实对于商品的查询主要就是从数据库中将所有商品查询出来。这简单的查询很简单，可是在页面分页显示出来这就是一个问题了。这里到了mybatis的分页插件pageHelper来实现。 传入参数：Easyui页面默认有page、rows参数传递。 返回值：easyui的格式即datagrid的格式，专门编写一个对应的pojo类放入专门工具类中使用，返回格式即这个pojo。 逻辑：Dao层：Dao层用mybatis的逆向工程 Service调用mapper的查询和分页实现逻辑。 Controller即将参数传递过去，url写好 B、商品添加：商品添加即将商品信息写入数据库，页面传递的内容当点击提交按钮时直接写入数据库，只需补全没有的字段即可。 这里涉及到商品的类目选择、上面的图片上传、商品的描述信息。 类目选择首先得将类目展示出来，这里使用的异步树的格式。查询api发现异步树的返回值的格式。主要思路是：根据parentId来查询类目表，默认从0开始，异步树有个特点，就是每次获取到的id，如果有子节点，会发送url再次请求，如果没有子节点则不发送请求，所以可以都遍历到所有节点。（这个是tree的特点，自动请求） 异步树的特点：从最顶层开始读取，先读顶层节点，如果是闭合状态，发送请求给服务器读取子节点，子节点的状态依赖于父节点，当展开一个封闭的节点时，如果节点没有加载子节点，它将会把节点的id的值作为http请求参数并命名为id，通过url发送到服务器上检索子节点。所以遍历一次后，如果父节点还是父节点（即存在子节点）则检索下面的子节点的内容，将子节点的id作为parentId来检索下面的节点。如果不是父节点了，则打开下面列表。也就是说这些实现都是 异步树自动实现的，我们只需要判断父节点的状态即可，下面的检索根据这个状态进行。 图片上传功能：因为商城的图片非常多，所以我们将这么多的图片保存在图片服务器中，然后将图片在服务器中的具体url写入数据库，供前台调用。前台获取到这个url既可获取到这个图片。这里图片上传到服务器的功能：先生存图片的名称，然后生成图片保存的格式，然后利用ftpUtil将图片上传到服务器，返回一个url链接。 商品规格参数，这里采用的规格参数模板的形式。： 这里有两个表：一个模板表（根据商品的分类建立的模板，根据分类id），一个展示模板表（根据商品的信息写入模板表，根据商品id查询商品信息，然后写入对应订单模板中，然后生成HTML）。 商品的描述：这里采用文本的形式存储的，写入即可。富文本编辑器。 CMS分类：这里的格式也是用了异步树的格式，所以显示方法是一样的。 分类添加：像表中插入数据库即可。 （2）前台功能实现 首页大广告位的实现：这里是从CMS系统中获取广告位的图片，然后展示在页面。但是前台跟后台是不一样的端口，如何从前台访问后台呢，可以使用jsonp的形式。但是我们这里系统是采用面向服务的编程，所以采用rest接口的方式然后功能前台调用，这里用的httpcliet来调用接口。 商品搜索功能的实现： 首先在linux下部署好solr服务器，然后将数据库的表字段导入到solr索引库。然后编写search服务接口，然后供前台调用这个服务接口。 Rest功能： 商品详情页面展示：写三个服务：根据id查询商品的具体信息显示到页面，根据id查询商品的内容表，根据id查询商品的规格参数，即将三个信息展示到页面。然后前台分别调用。 SSO系统：这里涉及到拦截器。 这里是利用了sso的接口文档，即校验接口、注册、登录接口、根据token查询用户接口、安全退出接口。 这个的调用服务层是利用jsonp的形式访问的服务接口，实现跨域访问。客户端全部在jsp页面实现的。 具体流程： 当用户点击注册的时候，跳转到注册页面，即用户信息的保存功能。检验用户名是否存在、手机号和邮箱不能为空。 当用户点击登录按钮的时候，用户输入用户名和密码，检验用户名是否在数据库中存在，然后用户名密码是否正确。这里的密码是用了spring的MD5加密技术。当全部成功后，给用户颁发一个token令牌（利用uuid实现），然后将token存入到redis中（token的key是它生成的号，值是用户的名字），然后设置在redis的过期时间。这相当于用户的session。 然后将token写入cookie中，前台页面利用jsonp调用，根据cookie中的token的值，调用sso的根据token查询用户的服务，查看用户是否有效，如果有效则将用户返回前台页面，前台页面获取用户的用户名显示在首页，表示***已登陆。 这里的cookie是设置了共享域，即全部子系统都可以访问到cookie。 当用户登录其他子系统时，先从从cookie中获取token信息，根据token信息获取用户信息，判断用户信息是否有效，如果有效则放行，如果无效，则利用拦截器拦截跳转到登录页面。用户再次登录的时候刷新redis的时间，重新设置有效期。 拦截器的拦截，在springMVC.xml中设置拦截的名称。 购物车功能： 购物车功能注意到这里商品加入购物车，是将购物车保存在cookie中。这里用到cookieUtil工具来实现这些保存删除功能。在商品详情页面点击“加入购物车”按钮提交一个请求吧商品id传递给Controller，Controller接收id，Controller调用Service根据商品id查询商品基本信息，购物车的商品专门写一个pojo对象，因为商品的很多信息购物车里面用不到。将购物车的商品的pojo，把商品写入cookie中，加入cookie之前先从cookie中把购物车的商品取出来判断当前购物车商品列表中是否有此商品，如果有数量加一，如果没有添加一个商品，数量为1。展示给用户购物车列表。 订单系统：订单系统主要是订单的创建、查询、修改、删除功能。 功能：接收三个参数， 1、对应订单表的pojo。 2、订单明细表对应的商品列表。每个元素是订单明细表对应的pojo 3、物流表对应的pojo]]></content>
      <categories>
        <category>项目实战</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis官方文档]]></title>
    <url>%2F2018%2F09%2F25%2FRedis%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[This README is just a fast quick start document. You can find more detailed documentation at redis.io. What is Redis?Redis is often referred as a data structures server. What this means is that Redis provides access to mutable data structures via a set of commands, which are sent using a server-client model with TCP sockets and a simple protocol. So different processes can query and modify the same data structures in a shared way. Data structures implemented into Redis have a few special properties: Redis cares to store them on disk, even if they are always served and modified into the server memory. This means that Redis is fast, but that is also non-volatile. Implementation of data structures stress on memory efficiency, so data structures inside Redis will likely use less memory compared to the same data structure modeled using an high level programming language. Redis offers a number of features that are natural to find in a database, like replication, tunable levels of durability, cluster, high availability. Another good example is to think of Redis as a more complex version of memcached, where the operations are not just SETs and GETs, but operations to work with complex data types like Lists, Sets, ordered data structures, and so forth. If you want to know more, this is a list of selected starting points: Introduction to Redis data types. http://redis.io/topics/data-types-intro Try Redis directly inside your browser. http://try.redis.io The full list of Redis commands. http://redis.io/commands There is much more inside the Redis official documentation. http://redis.io/documentation Building RedisRedis can be compiled and used on Linux, OSX, OpenBSD, NetBSD, FreeBSD.We support big endian and little endian architectures, and both 32 bitand 64 bit systems. It may compile on Solaris derived systems (for instance SmartOS) but oursupport for this platform is best effort and Redis is not guaranteed towork as well as in Linux, OSX, and *BSD there. It is as simple as: % make You can run a 32 bit Redis binary using: % make 32bit After building Redis, it is a good idea to test it using: % make test Fixing build problems with dependencies or cached build optionsRedis has some dependencies which are included into the deps directory.make does not automatically rebuild dependencies even if something inthe source code of dependencies changes. When you update the source code with git pull or when code inside thedependencies tree is modified in any other way, make sure to use the followingcommand in order to really clean everything and rebuild from scratch: make distclean This will clean: jemalloc, lua, hiredis, linenoise. Also if you force certain build options like 32bit target, no C compileroptimizations (for debugging purposes), and other similar build time options,those options are cached indefinitely until you issue a make distcleancommand. Fixing problems building 32 bit binariesIf after building Redis with a 32 bit target you need to rebuild itwith a 64 bit target, or the other way around, you need to perform amake distclean in the root directory of the Redis distribution. In case of build errors when trying to build a 32 bit binary of Redis, trythe following steps: Install the packages libc6-dev-i386 (also try g++-multilib). Try using the following command line instead of make 32bit:make CFLAGS=&quot;-m32 -march=native&quot; LDFLAGS=&quot;-m32&quot; AllocatorSelecting a non-default memory allocator when building Redis is done by settingthe MALLOC environment variable. Redis is compiled and linked against libcmalloc by default, with the exception of jemalloc being the default on Linuxsystems. This default was picked because jemalloc has proven to have fewerfragmentation problems than libc malloc. To force compiling against libc malloc, use: % make MALLOC=libc To compile against jemalloc on Mac OS X systems, use: % make MALLOC=jemalloc Verbose buildRedis will build with a user friendly colorized output by default.If you want to see a more verbose output use the following: % make V=1 Running RedisTo run Redis with the default configuration just type: % cd src % ./redis-server If you want to provide your redis.conf, you have to run it using an additionalparameter (the path of the configuration file): % cd src % ./redis-server /path/to/redis.conf It is possible to alter the Redis configuration by passing parameters directlyas options using the command line. Examples: % ./redis-server --port 9999 --slaveof 127.0.0.1 6379 % ./redis-server /etc/redis/6379.conf --loglevel debug All the options in redis.conf are also supported as options using the commandline, with exactly the same name. Playing with RedisYou can use redis-cli to play with Redis. Start a redis-server instance,then in another terminal try the following: % cd src % ./redis-cli redis&gt; ping PONG redis&gt; set foo bar OK redis&gt; get foo &quot;bar&quot; redis&gt; incr mycounter (integer) 1 redis&gt; incr mycounter (integer) 2 redis&gt; You can find the list of all the available commands at http://redis.io/commands. Installing RedisIn order to install Redis binaries into /usr/local/bin just use: % make install You can use make PREFIX=/some/other/directory install if you wish to use adifferent destination. Make install will just install binaries in your system, but will not configureinit scripts and configuration files in the appropriate place. This is notneeded if you want just to play a bit with Redis, but if you are installingit the proper way for a production system, we have a script doing thisfor Ubuntu and Debian systems: % cd utils % ./install_server.sh The script will ask you a few questions and will setup everything you needto run Redis properly as a background daemon that will start again onsystem reboots. You’ll be able to stop and start Redis using the script named/etc/init.d/redis_&lt;portnumber&gt;, for instance /etc/init.d/redis_6379. Code contributionsNote: by contributing code to the Redis project in any form, including sendinga pull request via Github, a code fragment or patch via private email orpublic discussion groups, you agree to release your code under the termsof the BSD license that you can find in the COPYING file included in the Redissource distribution. Please see the CONTRIBUTING file in this source distribution for moreinformation. Redis internalsIf you are reading this README you are likely in front of a Github pageor you just untarred the Redis distribution tar ball. In both the casesyou are basically one step away from the source code, so here we explainthe Redis source code layout, what is in each file as a general idea, themost important functions and structures inside the Redis server and so forth.We keep all the discussion at a high level without digging into the detailssince this document would be huge otherwise and our code base changescontinuously, but a general idea should be a good starting point tounderstand more. Moreover most of the code is heavily commented and easyto follow. Source code layoutThe Redis root directory just contains this README, the Makefile whichcalls the real Makefile inside the src directory and an exampleconfiguration for Redis and Sentinel. You can find a few shellscripts that are used in order to execute the Redis, Redis Cluster andRedis Sentinel unit tests, which are implemented inside the testsdirectory. Inside the root are the following important directories: src: contains the Redis implementation, written in C. tests: contains the unit tests, implemented in Tcl. deps: contains libraries Redis uses. Everything needed to compile Redis is inside this directory; your system just needs to provide libc, a POSIX compatible interface and a C compiler. Notably deps contains a copy of jemalloc, which is the default allocator of Redis under Linux. Note that under deps there are also things which started with the Redis project, but for which the main repository is not anitrez/redis. An exception to this rule is deps/geohash-int which is the low level geocoding library used by Redis: it originated from a different project, but at this point it diverged so much that it is developed as a separated entity directly inside the Redis repository. There are a few more directories but they are not very important for our goalshere. We’ll focus mostly on src, where the Redis implementation is contained,exploring what there is inside each file. The order in which files areexposed is the logical one to follow in order to disclose different layersof complexity incrementally. Note: lately Redis was refactored quite a bit. Function names and filenames have been changed, so you may find that this documentation reflects theunstable branch more closely. For instance in Redis 3.0 the server.cand server.h files were named to redis.c and redis.h. However the overallstructure is the same. Keep in mind that all the new developments and pullrequests should be performed against the unstable branch. server.hThe simplest way to understand how a program works is to understand thedata structures it uses. So we’ll start from the main header file ofRedis, which is server.h. All the server configuration and in general all the shared state isdefined in a global structure called server, of type struct redisServer.A few important fields in this structure are: server.db is an array of Redis databases, where data is stored. server.commands is the command table. server.clients is a linked list of clients connected to the server. server.master is a special client, the master, if the instance is a slave. There are tons of other fields. Most fields are commented directly insidethe structure definition. Another important Redis data structure is the one defining a client.In the past it was called redisClient, now just client. The structurehas many fields, here we’ll just show the main ones: struct client { int fd; sds querybuf; int argc; robj **argv; redisDb *db; int flags; list *reply; char buf[PROTO_REPLY_CHUNK_BYTES]; ... many other fields ... } The client structure defines a connected client: The fd field is the client socket file descriptor. argc and argv are populated with the command the client is executing, so that functions implementing a given Redis command can read the arguments. querybuf accumulates the requests from the client, which are parsed by the Redis server according to the Redis protocol and executed by calling the implementations of the commands the client is executing. reply and buf are dynamic and static buffers that accumulate the replies the server sends to the client. These buffers are incrementally written to the socket as soon as the file descriptor is writable. As you can see in the client structure above, arguments in a commandare described as robj structures. The following is the full robjstructure, which defines a Redis object: typedef struct redisObject { unsigned type:4; unsigned encoding:4; unsigned lru:LRU_BITS; /* lru time (relative to server.lruclock) */ int refcount; void *ptr; } robj; Basically this structure can represent all the basic Redis data types likestrings, lists, sets, sorted sets and so forth. The interesting thing is thatit has a type field, so that it is possible to know what type a givenobject has, and a refcount, so that the same object can be referencedin multiple places without allocating it multiple times. Finally the ptrfield points to the actual representation of the object, which might varyeven for the same type, depending on the encoding used. Redis objects are used extensively in the Redis internals, however in orderto avoid the overhead of indirect accesses, recently in many placeswe just use plain dynamic strings not wrapped inside a Redis object. server.cThis is the entry point of the Redis server, where the main() functionis defined. The following are the most important steps in order to startupthe Redis server. initServerConfig() setups the default values of the server structure. initServer() allocates the data structures needed to operate, setup the listening socket, and so forth. aeMain() starts the event loop which listens for new connections. There are two special functions called periodically by the event loop: serverCron() is called periodically (according to server.hz frequency), and performs tasks that must be performed from time to time, like checking for timedout clients. beforeSleep() is called every time the event loop fired, Redis served a few requests, and is returning back into the event loop. Inside server.c you can find code that handles other vital things of the Redis server: call() is used in order to call a given command in the context of a given client. activeExpireCycle() handles eviciton of keys with a time to live set via the EXPIRE command. freeMemoryIfNeeded() is called when a new write command should be performed but Redis is out of memory according to the maxmemory directive. The global variable redisCommandTable defines all the Redis commands, specifying the name of the command, the function implementing the command, the number of arguments required, and other properties of each command. networking.cThis file defines all the I/O functions with clients, masters and slaves(which in Redis are just special clients): createClient() allocates and initializes a new client. the addReply*() family of functions are used by commands implementations in order to append data to the client structure, that will be transmitted to the client as a reply for a given command executed. writeToClient() transmits the data pending in the output buffers to the client and is called by the writable event handler sendReplyToClient(). readQueryFromClient() is the readable event handler and accumulates data from read from the client into the query buffer. processInputBuffer() is the entry point in order to parse the client query buffer according to the Redis protocol. Once commands are ready to be processed, it calls processCommand() which is defined inside server.c in order to actually execute the command. freeClient() deallocates, disconnects and removes a client. aof.c and rdb.cAs you can guess from the names these files implement the RDB and AOFpersistence for Redis. Redis uses a persistence model based on the fork()system call in order to create a thread with the same (shared) memorycontent of the main Redis thread. This secondary thread dumps the contentof the memory on disk. This is used by rdb.c to create the snapshotson disk and by aof.c in order to perform the AOF rewrite when theappend only file gets too big. The implementation inside aof.c has additional functions in order toimplement an API that allows commands to append new commands into the AOFfile as clients execute them. The call() function defined inside server.c is responsible to callthe functions that in turn will write the commands into the AOF. db.cCertain Redis commands operate on specific data types, others are general.Examples of generic commands are DEL and EXPIRE. They operate on keysand not on their values specifically. All those generic commands aredefined inside db.c. Moreover db.c implements an API in order to perform certain operationson the Redis dataset without directly accessing the internal data structures. The most important functions inside db.c which are used in many commandsimplementations are the following: lookupKeyRead() and lookupKeyWrite() are used in order to get a pointer to the value associated to a given key, or NULL if the key does not exist. dbAdd() and its higher level counterpart setKey() create a new key in a Redis database. dbDelete() removes a key and its associated value. emptyDb() removes an entire single database or all the databases defined. The rest of the file implements the generic commands exposed to the client. object.cThe robj structure defining Redis objects was already described. Insideobject.c there are all the functions that operate with Redis objects ata basic level, like functions to allocate new objects, handle the referencecounting and so forth. Notable functions inside this file: incrRefcount() and decrRefCount() are used in order to increment or decrement an object reference count. When it drops to 0 the object is finally freed. createObject() allocates a new object. There are also specialized functions to allocate string objects having a specific content, like createStringObjectFromLongLong() and similar functions. This file also implements the OBJECT command. replication.cThis is one of the most complex files inside Redis, it is recommended toapproach it only after getting a bit familiar with the rest of the code base.In this file there is the implementation of both the master and slave roleof Redis. One of the most important functions inside this file is replicationFeedSlaves() that writes commands to the clients representing slave instances connectedto our master, so that the slaves can get the writes performed by the clients:this way their data set will remain synchronized with the one in the master. This file also implements both the SYNC and PSYNC commands that areused in order to perform the first synchronization between masters andslaves, or to continue the replication after a disconnection. Other C files t_hash.c, t_list.c, t_set.c, t_string.c and t_zset.c contains the implementation of the Redis data types. They implement both an API to access a given data type, and the client commands implementations for these data types. ae.c implements the Redis event loop, it’s a self contained library which is simple to read and understand. sds.c is the Redis string library, check http://github.com/antirez/sds for more information. anet.c is a library to use POSIX networking in a simpler way compared to the raw interface exposed by the kernel. dict.c is an implementation of a non-blocking hash table which rehashes incrementally. scripting.c implements Lua scripting. It is completely self contained from the rest of the Redis implementation and is simple enough to understand if you are familar with the Lua API. cluster.c implements the Redis Cluster. Probably a good read only after being very familiar with the rest of the Redis code base. If you want to read cluster.c make sure to read the Redis Cluster specification. Anatomy of a Redis commandAll the Redis commands are defined in the following way: void foobarCommand(client *c) { printf(&quot;%s&quot;,c-&gt;argv[1]-&gt;ptr); /* Do something with the argument. */ addReply(c,shared.ok); /* Reply something to the client. */ } The command is then referenced inside server.c in the command table: {&quot;foobar&quot;,foobarCommand,2,&quot;rtF&quot;,0,NULL,0,0,0,0,0}, In the above example 2 is the number of arguments the command takes,while &quot;rtF&quot; are the command flags, as documented in the command tabletop comment inside server.c. After the command operates in some way, it returns a reply to the client,usually using addReply() or a similar function defined inside networking.c. There are tons of commands implementations inside th Redis source codethat can serve as examples of actual commands implementations. To writea few toy commands can be a good exercise to familiarize with the code base. There are also many other files not described here, but it is useless tocover everything. We want to just help you with the first steps.Eventually you’ll find your way inside the Redis code base :-) Enjoy!]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[FTP协议的工作原理详解及安装流程]]></title>
    <url>%2F2018%2F09%2F25%2FFTP%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[1. FTP协议什么是FTP呢？FTP 是 TCP/IP 协议组中的协议之一，是英文File Transfer Protocol的缩写。 该协议是Internet文件传送的基础，它由一系列规格说明文档组成，目标是提高文件的共享性，提供非直接使用远程计算机，使存储介质对用户透明和可靠高效地传送数据。简单的说，FTP就是完成两台计算机之间的拷贝，从远程计算机拷贝文件至自己的计算机上，称之为“下载 （download）”文件。若将文件从自己计算机中拷贝至远程计算机上，则称之为“上载（upload）”文件。在TCP/IP协议中，FTP标准命令TCP端口号为21，Port方式数据端口为20。控制链路 ——–TCP 端口 21所有你发往 FTP服务器的命令和服务器反馈的指令都是通过服务器上的 21 端口传送的。数据链路 ——–TCP 端口 20数据链路主要是用来传送数据的，比如客户端上传、下载内容，以及列目录显示的内容等 2. FTP服务器和客户端同大多数Internet服务一样，FTP也是一个客户/服务器系统。用户通过一个客户机程序连接至在远程计算机上运行的服务器程序。依照 FTP 协议提供服务，进行文件传送的计算机就是 FTP 服务器，而连接FTP服务器，遵循FTP协议与服务器传送文件的电脑就是FTP客户端。用户要连上 FTP 服务器，就要用到 FPT 的客户端软件，通常 Windows自带“ftp”命令，这是一个命令行的 FTP 客户程序，另外常用的 FTP 客户程序还有 CuteFTP、Ws_FTP、Flashfxp、LeapFTP、流星雨-猫眼等。 3. FTP用户授权（1）用户授权要连上 FTP 服务器（即“登陆”），必须要有该 FTP 服务器授权的帐号，也就是说你只有在有了一个用户标识和一个口令后才能登陆FTP服务器，享受FTP服务器提供的服务。 （2）FTP地址格式FTP地址如下： ftp://用户名：密码@FTP服务器IP或域名：FTP命令端口/路径/文件名 上面的参数除FTP服务器IP或域名为必要项外，其他都不是必须的。如以下地址都是有效FTP地址： ftp://foolish.6600.org ftp://list:list@foolish.6600.org ftp://list:list@foolish.6600.org:2003 ftp://list:list@foolish.6600.org:2003/soft/list.txt （3）匿名FTP互连网中有很大一部分 FTP 服务器被称为“匿名”（Anonymous）FTP 服务器。这类服务器的目的是向公众提供文件拷贝服务，不要求用户事先在该服务器进行登记注册，也不用取得FTP服务器的授权。Anonymous（匿名文件传输）能够使用户与远程主机建立连接并以匿名身份从远程主机上拷贝文件，而不必是该远程主机的注册用户。用户使用特殊的用户名“anonymous”登陆FTP服务，就可访问远程主机上公开的文件。许多系统要求用户将Emai1地址作为口令，以便更好地对访问进行跟综。匿名FTP一直是Internet上获取信息资源的最主要方式，在Internet成千上万的匿名FTP主机中存储着无以计数的文件，这些文件包含了各种各样的信息，数据和软件。人们只要知道特定信息资源的主机地址，就可以用匿名FTP登录获取所需的信息资料。虽然目前使用WWW环境已取代匿名FTP成为最主要的信息查询方式，但是匿名FTP仍是 Internet上传输分发软件的一种基本方法。如red hat 、autodesk等公司的匿名站点。 4. FTP的传输模式FTP协议的任务是从一台计算机将文件传送到另一台计算机，它与这两台计算机所处的位置、联接的方式、甚至是是否使用相同的操作系统无关。假设两台计算机通过ftp协议对话，并且能访问Internet，你可以用ftp命令来传输文件。每种操作系统使用上有某一些细微差别，但是每种协议基本的命令结构是相同的。 FTP的传输有两种方式：ASCII传输模式和二进制数据传输模式。 1．ASCII传输方式：假定用户正在拷贝的文件包含的简单ASCII码文本，如果在远程机器上运行的不是UNIX，当文件传输时ftp通常会自动地调整文件的内容以便于把文件解释成另外那台计算机存储文本文件的格式。但是常常有这样的情况，用户正在传输的文件包含的不是文本文件，它们可能是程序，数据库，字处理文件或者压缩文件（尽管字处理文件包含的大部分是文本，其中也包含有指示页尺寸，字库等信息的非打印符）。在拷贝任何非文本文件之前，用binary 命令告诉ftp逐字拷贝，不要对这些文件进行处理，这也是下面要讲的二进制传输。 2．二进制传输模式：在二进制传输中，保存文件的位序，以便原始和拷贝的是逐位一一对应的。即使目的地机器上包含位序列的文件是没意义的。例如，macintosh以二进制方式传送可执行文件到Windows系统，在对方系统上，此文件不能执行。如果你在ASCII方式下传输二进制文件，即使不需要也仍会转译。这会使传输稍微变慢 ，也会损坏数据，使文件变得不能用。（在大多数计算机上，ASCII方式一般假设每一字符的第一有效位无意义，因为ASCII字符组合不使用它。如果你传输二进制文件，所有的位都是重要的。）如果你知道这两台机器是同样的，则二进制方式对文本文件和数据文件都是有效的。 5. FTP的工作方式FTP支持两种模式，一种方式叫做Standard (也就是 PORT方式，主动方式)，一种是 Passive (也就是PASV，被动方式)。 Standard模式 FTP的客户端发送 PORT 命令到FTP服务器。Passive模式FTP的客户端发送 PASV命令到 FTP Server。 下面介绍一个这两种方式的工作原理： 主动模式Port模式FTP 客户端首先和FTP服务器的TCP 21端口建立连接，通过这个通道发送命令，客户端需要接收数据的时候在这个通道上发送PORT命令。 PORT命令包含了客户端用什么端口接收数据。在传送数据的时候，服务器端通过自己的TCP 20端口连接至客户端的指定端口发送数据。 FTP server必须和客户端建立一个新的连接用来传送数据。 被动模式Passive模式在建立控制通道的时候和Standard模式类似，但建立连接后发送的不是Port命令，而是Pasv命令。FTP服务器收到Pasv命令后，随机打开一个高端端口（端口号大于1024）并且通知客户端在这个端口上传送数据的请求，客户端连接FTP服务器此端口，然后FTP服务器将通过这个端口进行数据的传送，这个时候FTP server不再需要建立一个新的和客户端之间的连接。 很多防火墙在设置的时候都是不允许接受外部发起的连接的，所以许多位于防火墙后或内网的FTP服务器不支持PASV模式，因为客户端无法穿过防火墙打开FTP服务器的高端端口；而许多内网的客户端不能用PORT模式登陆FTP服务器，因为从服务器的TCP 20无法和内部网络的客户端建立一个新的连接，造成无法工作。 6.FXPFXP说简单点就是一个FTP客户端控制两个FTP服务器，在两个FTP服务器之间传送文件。FXP的全称为File Exchange Protocol――文件交换协议，可以认为FXP本身其实就是FTP的一个子集，因为FXP方式实际上就是利用了FTP服务器的Proxy命令，不过它的前提条件是FTP服务器要支持PASV，且支持FXP方式。FXP传送时，文件并不下载至本地，本地只是发送控制命令，故FXP传送时的速度只与两个FTP服务器之间的网络速度有关，而与本地速度无关。因FXP方式本地只发送命令，故在开始传送后，只要本地不发送停止的命令，就算是本地关机了，FXP仍在传送，直至一个文件传送完成或文件传送出错后，FTP服务器等待本地发送命令时，才会因不能接收到命令而终止FXP传送。 因为上述的原因，FXP传送出错时，本地的用户进程还留在FTP服务器中，并没有退出，如此时再次连接FTP服务器，可能会因用户线程超过允许，FTP服务器提示客户已登陆并拒绝客户端的连接，直至服务器中的傀儡进程因超时或其他原因被FTP服务器杀死后，才能再次连接FTP服务器。 成功FXP有两个必要条件：①两个FTP服务器均支持FXP；②两个FTP服务器均支持PASV方式。但并不是说满足这两个条件的FTP服务器均经本地操作成功FXP，这还与本地与FTP服务器的网络状况有关。故有时会出现同样两个FTP，别人可以FXP，而你不可以的情况。 7. TFTPTFTP(Trivial File Transfer Protocol)小文件传输协议 它是一个网络应用程序，它比FTP简单也比FTP功能少。它在不需要用户权限或目录可见的情况下使用，它使用UDP协议而不是TCP协议。 TFTP是一个传输文件的简单协议，它基于UDP协议而实现，但是我们也不能确定有些TFTP协议是基于其它传输协议完成的。此协议设计的时候是进行小文件传输的，因此它不具备通常的FTP的许多功能，它只能从文件服务器上获得或写入文件，不能列出目录，不进行认证，它传输8位数据。传输中有三种模式：netascii，这是8位的ASCII码形式，另一种是octet，这是8位源数据类型；最后一种mail已经不再支持，它将返回的数据直接返回给用户而不是保存为文件。 任何传输起自一个读取或写入文件的请求，这个请求也是连接请求。如果服务器批准此请求，则服务器打开连接，数据以定长512字节传输。每个数据包包括一块数据，服务器发出下一个数据包以前必须得到客户对上一个数据包的确认。如果一个数据包的大小小于512字节，则表示传输结构。如果数据包在传输过程中丢失，发出方会在超时后重新传输最后一个未被确认的数据包。通信的双方都是数据的发出者与接收者，一方传输数据接收应答，另一方发出应答接收数据。大部分的错误会导致连接中断，错误由一个错误的数据包引起。这个包不会被确认，也不会被重新发送，因此另一方无法接收到。如果错误包丢失，则使用超时机制。错误主要是由下面三种情况引起的：不能满足请求，收到的数据包内容错误，而这种错误不能由延时或重发解释，对需要资源的访问丢失（如硬盘满）。TFTP只在一种情况下不中断连接，这种情况是源端口不正确，在这种情况下，指示错误的包会被发送到源机。这个协议限制很多，这是都是为了实现起来比较方便而进行的。 初始连接时候需要发出WRQ（请求写入远程系统）或RRQ（请求读取远程系统），收到一个确定应答，一个确定可以写出的包或应该读取的第一块数据。通常确认包包括要确认的包的包号，每个数据包都与一个块号相对应，块号从1开始而且是连续的。因此对于写入请求的确定是一个比较特殊的情况，因此它的包的包号是0。如果收到的包是一个错误的包，则这个请求被拒绝。创建连接时，通信双方随机选择一个TID，因此是随机选择的，因此两次选择同一个ID的可能性就很小了。每个包包括两个TID，发送者ID和接收者ID。这些ID用于在UDP通信时选择端口，请求主机选择ID的方法上面已经说过了，在第一次请求的时候它会将请求发到TID 69，也就是服务器的69端口上。应答时，服务器使用一个选择好的TID作为源TID，并用上一个包中的TID作为目的ID进行发送。这两个被选择的ID在随后的通信中会被一直使用 TCP三次握手协议 在TCP/IP协议中，TCP协议提供可靠的连接服务，采用三次握手建立一个连接。第一次握手：建立连接时，客户端发送syn包(syn=j)到服务器，并进入SYN_SEND状态，等待服务器确认；SYN： 同步序列编号(Synchronize Sequence Numbers)第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态；第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=k+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。完成三次握手，客户端与服务器开始传送数据]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[毁掉一个中国年轻人有多容易？]]></title>
    <url>%2F2018%2F09%2F16%2F%E6%AF%81%E6%8E%89%E4%B8%80%E4%B8%AA%E4%B8%AD%E5%9B%BD%E5%B9%B4%E8%BD%BB%E4%BA%BA%E6%9C%89%E5%A4%9A%E5%AE%B9%E6%98%93%2F</url>
    <content type="text"><![CDATA[这是最好的时代，也是最坏的时代–《双城记》 知乎上看到的一篇文章，称得上振聋发聩，如果你有心，希望与君共勉 01 不知道你有没有这样的感受？ 走在街上，感觉自己的耳膜被抖音神曲轮番轰炸：从C哩C哩到123我爱你，从Despacito到确认过眼神； 排队等餐厅叫号，公交车站等公交，90%的人都在低头刷手机，嘴角不时地浮现出蜜汁微笑； 朋友圈和微博上，无数人发出这样的感慨：“抖音有毒，不知不觉我竟然刷了一整天。”有数据统计，抖音85%的用户在24岁以下，基本上都是95后，甚至是00后。 越来越多的年轻人将时间花在刷短视频上，通过手机窥见别人的生活和人生。 然后放下手机，突然觉得周边的一切都索然无味。 《双城记》中，狄更斯说：“这是一个最好的时代，这是一个最坏的时代。” 在这个时代里，摧毁一个中国年轻人，真的很容易。 02 前段时间回老家，正在读高二的表妹看到我的第一句话就是： “姐姐，你有玩抖音吗？我们互相关注一下吧。” 我看着她的韩式空气刘海，棕色美瞳，略显成熟的大红色口红，还有故意折到膝盖以上的校服裙子，突然不知道该说什么。 关注了她的抖音之后，发现她以一天好几条的频率更新着短视频。 我不知道她每天花多久来化妆、练习手指舞和对口型。 我只知道如果她的日常生活都被抖音占据，能用来学习的时间和精力势必寥寥无几。 看过这样一项调查：95后最向往的新兴职业中，主播、网红占据了54%。 然而，这些主播、网红们，向年轻人们传递的都是什么样的价值观呢？ 有美女网红直播撕书，高调地宣称：她们不读书照样开跑车，大学生也得给她们打工； 有17岁的女生整容、泡夜店、炫富、私生活混乱，却凭借着一段摇头晃脑的短视频走红，获得千万点赞； 有00后网红互相攀比早恋早孕，直播晒肚子、晒孩子，还分享一些“相关经验”，抱着孩子就能顺带把钱赚了。这些人的走红让年轻人看到一种成功的捷径，只要红了，就有钱了。 一些人生观、价值观还未成熟的未成年人，通过网红的世界仿佛看到了另一种活法。 既然那么简单就可以赚到快钱和关注，谁还愿意头悬梁、锥刺股地寒窗苦读呢？ 既然拍一条短视频就可以抵上普通白领几个月的工资，谁还愿意勤勤恳恳地工作呢？ 读书太苦了，工作太累了，不如整成网红脸，发几条短视频赚取关注和流量。 最好再傍上一位有钱的金主，从此就能享受纸醉金迷，过上最光鲜亮丽的生活。 不知道有多少人被这样的价值观荼毒，荒废了学业、堕落了青春。 细思极恐。 这个时代，毁掉一个中国年轻人，只需要一种脱轨的价值观就够了。 03 凌晨3点半，忘了关手机的我被一条微信提示声吵醒。 睡眼朦胧地点开一看，是朋友发来的“吃鸡”组队邀请。 明明是工作日，她居然玩游戏玩到了凌晨还不睡觉。 有人说：现代的中国年轻人，习惯于在微信运动里刷存在感，在网络小说中找爱情，在游戏里成就“王者荣耀”。 微博上的娱乐圈八卦新闻，让你沉浸在明星的绯闻琐事之中无法自拔； 短小的公众号、头条文章，控制在2000字左右，保证让你5分钟能读完； 抖音短视频15秒就给你一个刺激，你永远也不知道下一个15秒会刷到什么。 这些利用流量、算法机制推荐的软件，都在利用大数据慢慢掏空你的时间。 这些软件，为什么能如此让人上瘾？ 因为你的每一次点击、每一次滑动，都会有实时的反馈。 这些及时的反馈刺激大脑多次产生多巴胺，并形成依赖，渴望下一个刺激到来，陷入死循环。 这些能提供短期快感的软件，就像不折不扣的精神鸦片。 你麻木地盯着手机屏幕，玩到忘情所以、看到眼睛发酸，却不知自己的深度思考能力正在逐渐被腐蚀。 到最后，除了大量的时间白白被浪费，你一无所得，留下的只会是满满的空虚。 你有没有这样的体验？ 工作日常，明明想要专心完成一项任务，转眼却被手机推送的一条热点新闻吸引了注意力； 回到家中，自己戴着耳机刷抖音、看网剧，伴侣则全身心投入进游戏的世界里，两人虽同处一个屋檐下，一晚上却说不了两句话； 网络段子张口就来，抖音上的梗知道得比谁都多，网红的名字如数家珍，却忘了自己有多久没有好好看过一部经典电影、一本纸质书。你慢慢变成了自己曾经最鄙视的那种人，离记忆里那个朝气蓬勃的少年越来越远。 你的生活变成了简单的两点一线，自己在虚假的满足感中丧失了任何向上的动力。 这个时代，毁掉一个中国年轻人，只需要一个能获得短期快感的app就够了。 04 这个快节奏的时代，那些选择慢下来的“异类”，反而让人觉得可爱。 就像歌手李健，在拍《我是歌手》的时候，被曝出一直用的是老旧的诺基亚键盘手机。 他说：“没有智能手机，受干扰的机会就少了许多。” 他就像生活的旁观者，安静地听音乐、阅读、思考、观察这个世界。 他会强迫自己读一些比较难啃的经典书籍： “童话读起来毫不费力，但人的一生不可能只是读童话，还是要强迫自己读一些看不懂、不好读的书。强迫自己读下来，一定会有收获。” 他心目中的理想生活是让自己置身于另一个空间，去旅行，带着书和一把小琴。 又像作家皮克·耶尔，逃离曼哈顿的摩天大楼，关掉电脑、抛开手机、逃离都市的喧嚣。 他喜欢上了独处和思考，让精神和身体得到彻底的放松，给自己一个留白的空间。 林语堂先生曾经说过：“一个人只拥有此生此世是不够的，他还应该拥有诗意的世界。” 从他们身上，我看到的不是浮躁的价值观、空虚的短期快感，而是一种安静的力量。 多少人嘴里说着：“垃圾游戏，毁我青春。”“抖音有毒，浪费时间。” 然而，毁掉你的，不是抖音，不是游戏，而是不够自律的你自己。 当你从脱轨的价值观、虚拟的快感中抽离，重新审视自己，审视周围。 你会发现：真正能让你获得充实感和满足感的，是那些需要长期投入的事物。 终身成长词典词条《10：时间》中说：你的精力分配，反映了你是什么层次的人。 如果你按照每个月的健身计划认真执行，你会收获更好的身材、更健康的身体； 如果你把刷微博、抖音、玩游戏的时间用来阅读，1年后你的谈吐、写作能力都会发生质的变化； 如果你能在下班后花点时间提升自己的专业技能，3年后也能让自己的睡后收入翻上一倍。 柴静在《看见》里写道：“从不假思索的愚昧里挣脱，这才是活着。” 不要让自己变成一个被浮躁的价值观、短期的快感废掉的年轻人。 你现在每一天短暂的享乐，都在透支着未来。 共勉。 作者：小椰子]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[JSON语法]]></title>
    <url>%2F2018%2F09%2F15%2FJSON%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[十年铸剑 JSON 语法是 JavaScript 语法的子集。JSON 语法规则JSON 语法是 JavaScript 对象表示法语法的子集。 数据在名称/值对中 数据由逗号分隔 花括号保存对象 方括号保存数组 JSON 名称/值对JSON 数据的书写格式是：名称/值对。 名称/值对包括字段名称（在双引号中），后面写一个冒号，然后是值： 1&quot;firstName&quot; : &quot;John&quot; 这很容易理解，等价于这条 JavaScript 语句： 1firstName = &quot;John&quot; JSON 值JSON 值可以是： 数字（整数或浮点数） 字符串（在双引号中） 逻辑值（true 或 false） 数组（在方括号中） 对象（在花括号中） null JSON 对象JSON 对象在花括号中书写： 对象可以包含多个名称/值对： 1&#123; &quot;firstName&quot;:&quot;John&quot; , &quot;lastName&quot;:&quot;Doe&quot; &#125; 这一点也容易理解，与这条 JavaScript 语句等价： 12firstName = &quot;John&quot;lastName = &quot;Doe&quot; JSON 数组JSON 数组在方括号中书写： 数组可包含多个对象： 1234567&#123;&quot;employees&quot;: [&#123; &quot;firstName&quot;:&quot;John&quot; , &quot;lastName&quot;:&quot;Doe&quot; &#125;,&#123; &quot;firstName&quot;:&quot;Anna&quot; , &quot;lastName&quot;:&quot;Smith&quot; &#125;,&#123; &quot;firstName&quot;:&quot;Peter&quot; , &quot;lastName&quot;:&quot;Jones&quot; &#125;]&#125; 在上面的例子中，对象 “employees” 是包含三个对象的数组。每个对象代表一条关于某人（有姓和名）的记录。]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[三种必须掌握的排序算法]]></title>
    <url>%2F2018%2F09%2F15%2F%E4%B8%89%E7%A7%8D%E5%BF%85%E9%A1%BB%E6%8E%8C%E6%8F%A1%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[异乡的孤独 冒泡排序原理：升序排列就是比较两个相邻的元素，将值大的元素交换至右端。较大数再与下个数比较，保持较大者在右，一直循环之后仿佛冒泡一样将较大的数放在了最后一个。第二趟排序最右边数一定是最大数，所以只将前面N-1个数重复以上过程。 举例说明要排序数组：int[] arr={6,3,8,2,9,1}; 第一趟排序： 第一次排序：6和3比较，6大于3，交换位置： 3 6 8 2 9 1 第二次排序：6和8比较，6小于8，不交换位置：3 6 8 2 9 1 第三次排序：8和2比较，8大于2，交换位置： 3 6 2 8 9 1 第四次排序：8和9比较，8小于9，不交换位置：3 6 2 8 9 1 第五次排序：9和1比较：9大于1，交换位置： 3 6 2 8 1 9 第一趟总共进行了5次比较， 排序结果： 3 6 2 8 1 9 第二趟排序： 第一次排序：3和6比较，3小于6，不交换位置：3 6 2 8 1 9 第二次排序：6和2比较，6大于2，交换位置： 3 2 6 8 1 9 第三次排序：6和8比较，6大于8，不交换位置：3 2 6 8 1 9 第四次排序：8和1比较，8大于1，交换位置： 3 2 6 1 8 9 第二趟总共进行了4次比较， 排序结果： 3 2 6 1 8 9 第三趟排序： 第一次排序：3和2比较，3大于2，交换位置： 2 3 6 1 8 9 第二次排序：3和6比较，3小于6，不交换位置：2 3 6 1 8 9 第三次排序：6和1比较，6大于1，交换位置： 2 3 1 6 8 9 第二趟总共进行了3次比较， 排序结果： 2 3 1 6 8 9 第四趟排序： 第一次排序：2和3比较，2小于3，不交换位置：2 3 1 6 8 9 第二次排序：3和1比较，3大于1，交换位置： 2 1 3 6 8 9 第二趟总共进行了2次比较， 排序结果： 2 1 3 6 8 9 第五趟排序： 第一次排序：2和1比较，2大于1，交换位置： 1 2 3 6 8 9 第二趟总共进行了1次比较， 排序结果： 1 2 3 6 8 9 最终结果：1 2 3 6 8 9 NOTE：由此可见N个数要完成排序，要排列N-1趟（最小的数已经在N-1趟时候排在了第一位）。而第i趟比较的次数是N-i次。 控制循环的基本思想：用双重循环语句，外层控制循环多少趟，内层控制每一趟的循环次数，即 时间复杂度1.如果我们的数据正序，只需要走一趟即可完成排序。所需的比较次数C和记录移动次数M均达到最小值，即：Cmin=n-1;Mmin=0;所以，冒泡排序最好的时间复杂度为O(n)。 2.如果很不幸我们的数据是反序的，则需要进行n-1趟排序。每趟排序要进行n-i次比较(1≤i≤n-1)，且每次比较都必须移动记录三次来达到交换记录位置。 在这种情况下，比较和移动次数均达到最大值：冒泡排序的最坏时间复杂度为：O(n2) 。 综上所述：冒泡排序总的平均时间复杂度为：O(n2) 。1234567for(int i=1;i&lt;arr.length;i++)&#123; for(int j=1;j&lt;arr.length-i;j++)&#123; //交换位置&#125; 冒泡排序的优点：每进行一趟排序，就会少比较一次代码1234567891011121314151617181920212223242526272829303132333435363738394041424344package 作业;public class Bubble &#123; public static int[] prod(int n) &#123;//生成一组随机数的方法 int[] b=new int[n]; for(int i=0;i&lt;b.length;i++) &#123; b[i]=(int) (Math.random()*100); System.out.print(b[i]); System.out.print(&apos; &apos;); &#125; return b; &#125; public static void main(String[] args) &#123; System.out.println(&quot;排序前&quot;); int[] a=prod(5); int temp; for (int i = 0; i &lt; a.length-1; i++) &#123;//外层循环N-1次 for (int j = 0; j &lt; a.length-(i+1); j++) &#123;//这里想了很久才明白，i+1才是趟数 if (a[j]&gt;a[j+1]) &#123;//这里只需要改变这个大小与号就可以控制升序or降序 temp=a[j]; a[j]=a[j+1]; a[j+1]=temp; &#125; &#125; &#125; System.out.println(); System.out.println(&quot;排完后&quot;); for (int i = 0; i &lt; a.length; i++) &#123; System.out.print(a[i]); System.out.print(&quot; &quot;); &#125; &#125;&#125; 选择排序原理在要排序的一组数中，选出最小的一个数与第一个位置的数交换；然后在剩下的数当中再找最小的与第二个位置的数交换，如此循环到倒数第二个数和最后一个数比较为止。 举例数组 int[] arr={5,2,8,4,9,1}; 第一趟排序： 原始数据：5 2 8 4 9 1 最小数据1，把1放在首位，也就是1和5互换位置， 排序结果：1 2 8 4 9 5 第二趟排序： 第1以外的数据{2 8 4 9 5}进行比较，2最小， 排序结果：1 2 8 4 9 5 第三趟排序： 除1、2以外的数据{8 4 9 5}进行比较，4最小，8和4交换 排序结果：1 2 4 8 9 5 第四趟排序： 除第1、2、4以外的其他数据{8 9 5}进行比较，5最小，8和5交换 排序结果：1 2 4 5 9 8 第五趟排序： 除第1、2、4、5以外的其他数据{9 8}进行比较，8最小，8和9交换 排序结果：1 2 4 5 8 9 NOTE：依旧是熟悉的N-1趟排序，排序的算法关键是掌握循环的次数。每一趟排序都是获得最小数的方法：for循环进行比较，定义一个第三个变量temp，首先前两个数比较，把较小的数放在temp中，然后用temp再去跟剩下的数据比较，如果出现比temp小的数据，就用它代替temp中原有的数据。 代码：123456789101112131415161718192021222324252627public class Selection &#123; public static void main(String[] args) &#123; int[] a=Bubble.prod(10);//随机产生10个数 for (int i = 0; i &lt; a.length-1; i++) &#123; int k=i; for (int j = k+1; j &lt; a.length; j++) &#123; if (a[j]&lt;a[k]) &#123; k=j; //每一次内循环的任务就是寻找最小数的下标 &#125; &#125; if (i!=k)//如果i=k说明最小的数就是此时与后面比较的数a[i]。 &#123;//外循环的任务就是将最小数与当前数组外循环的的数进行调换 int temp = a[i]; a[i]=a[k]; a[k]=temp; &#125; &#125; Bubble.print(a); &#125;&#125; 插入排序原理排序过程的某一中间时刻，R被划分成两个子区间R[1．．i-1]（已排好序的有序区）和R[i．．n]（当前未排序的部分，可称无序区）。插入排序的基本操作是将当前无序区的第1个记录R[i]插人到有序区R[1．．i-1]中适当的位置上，使R[1．．i]变为新的有序区。因为这种方法每次使有序区增加1个记录，通常称增量法。插入排序与打扑克时整理手上的牌非常类似。摸来的第1张牌无须整理，此后每次从桌上的牌(无序区)中摸最上面的1张并插入左手的牌(有序区)中正确的位置上。为了找到这个正确的位置，须自左向右(或自右向左)将摸来的牌与左手中已有的牌逐一比较。 思路算法进行的过程中会把数组分为一部分有序数组，后面的是无序数组，找到无序数组的第一个数只需要和有序数组的最后一个数比较，无序大则break，小则继续倒序比较。关键是掌握数组前移的方法。 代码123456789101112131415161718192021222324252627public class Insertion &#123; public static void main(String[] args) &#123; int[] a=Bubble.prod(6); for (int i = 1; i &lt; a.length; i++) &#123;//第一个数a[0]不做不比较 int key=a[i];//做比较和插入的数 int j =i-1; for (; j &gt;=0; j--) &#123;//倒序比较，无序数组取出的第一个数key比前面有序数组最后一个a[j]（最大的数）大，就不需要与前面比较了 if (a[j]&lt;key) &#123; break; &#125; else &#123; a[j+1]=a[j];//假如待插入数字不比最大的一个数字大，就依次跟前面的数字比较，同时把比较过的数字位置依次右移 &#125; &#125; a[j + 1] = key; //最后找到合适的位置插入数组 &#125; Bubble.print(a); &#125; &#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[编译原理 LL1分析法]]></title>
    <url>%2F2018%2F09%2F03%2F%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%20LL1%E5%88%86%E6%9E%90%E6%B3%95%2F</url>
    <content type="text"><![CDATA[从简入奢易，从奢入俭难 求First集，Follow集，Select集First集合： First集合顾名思义就是求一个文法符号串所可能推导出的符号串的第一个终结符的集合。 First（X）就是求X所有推导出的符号串的第一个符号的集合。 求First集合可分如下几种情况: 12345678910111、单个符号的First集合：单个终结符的First集合就是它自己。2、单个非终结符的First集合：A--&gt;a… 产生式右部以终结符开头，根据定义，这种情况下显然可以看出a属于First(A)。A--&gt;B… 产生式右部以非终结符开头，根据定义，既然可以把A替换成B……，也可以看出First（B）属于First（A）。这是一个递归的推导。3、多个符号形成的符号串的First结合：符号串ABC…，并且A不能推导出空串ε，显然根据定义First（ABC…）=First（A） 符号串ABC…，并且A可能推导出空串ε，当A不是空串的时候，显然First（A）属于First（ABC…），但当A是空串的时候，ABC…就成了BC…，此时根据B是否能推出空串来决定是否将First（B）加入First （ABC…）。这是一个递归的推导，综上所述，符号串中的第一个不能推出空串的符 号前面所有符号的First集合减去空串ε都属于First（ABC…），第一个不能推出空串的 符号的First集合也属于First（ABC…）。也就是假设A、B都可以推出空串，C不能推 出空串，First（ABC…）=First（A）-ε∪First（B）-ε∪First（C）。 注意：First集合中的符号一定是终结符，终结符也包括空串ε。 Follow集合： Follow集合也是顾名思义的，就是文法符号后面可能跟随的终结符的集合（不包括空 串ε）。 Follow(X)就是求X后面可能跟随的符号集合。 求Follow集合可分如下三种种情况: 终结符的Follow集合没有定义，只有非终结符才会有Follow集合。 1A–&gt;…Ua… 要求的Follow集合的非终结符后跟终结符 根据定义，显然a属于Follow（U）。这种情况下，Follow（U）和A没有任何关系，产生式左边是什么无所谓。1A–&gt;…UP… 要求的Follow集合的非终结符后跟非终结符 根据定义，显然P的第一个符号属于Follow（U），也就是First（P）属于Follow（U）。12A–&gt;…UP并且ε属于First（P）要求的Follow集合的非终结符后跟非结尾的终结符，并且结尾非终结符的First集合包含空串。 这是上一种情况的一种特例，除了要按上一种情况处理，First（P）属于Follow（U）以外还要进行分析；因为当P推导为空串时，空串不能出现在Follow集合中，所以U后面跟随的应该是P后面的东西，可P已经是结束的符号，此时U后面显然就是A后面跟随的东西了。所以在这种情况下Follow（A）也属于Follow（U）。123A–&gt;…U 要求的Follow集合的非终结符在产生式结尾 这时候又要递归推导，U是A的结尾，所以U后面跟随的东西也就是A后面跟随的东西。所以Follow（A）属于Follow（U） Select集合： Select集合就是产生式左部的可能的推导结果的起始符号。 Select（A–&gt;B）就是求这个产生式中A可能推导出起始符号集合（不包含空串ε）。 求Select集合可分如下几种情况: 1A–&gt;X （X为任意文法符号串，不限于非终结符或单个符号），并且X不能推导出空串 ε 根据定义，显然A推出的符号串起始就是X的起始，也就是First（X）. Select（A–&gt;X）= First（X） 1A–&gt;X （X为任意文法符号串，不限于非终结符或单个符号），并且X能推导出空串ε 根据定义，显然First（X）属于Select（A–&gt;X），此外，当X推导为空串时，显然A也推导为空串，那么此时推导出的符号串就会是A后面的符的推导结果。也就是Follow（A）,所以，此时Follow（A）也属于Select（A–&gt;X）。 Select（A–&gt;X）= First（X）U Follow（A）注意：Select集合中不包括空串ε，但有可能会包含#(句子括号)。 构造预测分析表 根据Select集预测某个开始符号遇到某个终结符将使用的文法 具体格式如下： // 终结符 非终结符 文法表达式]]></content>
      <categories>
        <category>编译原理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Oracle后台进程详解]]></title>
    <url>%2F2018%2F09%2F03%2FOracle%E5%90%8E%E5%8F%B0%E8%BF%9B%E7%A8%8B%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[♪ 流浪–卢焱 后台进程 后台进程负责保证数据库的稳定工作，每当数据库启动时，这些后台进程会自动启动，并且持续整 个实例的生命周期，每个进程负责一个独特的任务，表2-4 是一些最重要的后台进程。 进 程 缩 写 描 述 Database Writer DBWn 负责把脏数据写回磁盘 Log Writer LGWR 负责把日志数据写到联机日志文件 Checkpoint CKPT 负责检查点操作 Process Monitor PMON 负责维护用户进程 System Monitor SMON 负责实例恢复 Archiver ARCn 负责归档操作，生成归档日志 Manageability Monitor MMON 和AW R有关 Manageability Monitor Light MMNL 和AW R有关 Memory Manager MMAN 和自动SGA管理有关 Job Queue Coordination Process CJQO 定时任务进程 Recover Writer RVWR 和Flashback Database 功能有关 Change Tracking Writer CTWR 跟踪数据块变化，支持快速增量备份 1．DBWnOracle 对于数据的修改都是在内存中进行的，Oracle不会直接修改磁盘上的数据，因此Oracle在修改数据之前必须把数据从磁盘读入到SGA(系统全局区)。这个模式就遇到两个问题：首先，如何确保SGA中有足够的空间来装载这些数据？其次，修改后的数据终将写回到磁盘上，这又是如何完成的？我们就带着这两个问题来了解DBWn 进程的功能。 DBWn （Database Writer）进程的显式作用是负责把 SGA中被修改的数据同步到磁盘文件中。每当SGA 缓存中的空闲空间变得过小时，DBWR进程就通过把脏数据写到磁盘来释放空间。DBWn 进程使用的是LRU（Least Recently Used ）算法工作的，也就是根据数据从最后一次被使用以来的 时间决定释放那些数据，越久没有用到的数据越先被清除。因此 DBWn 的隐式的作用是保证 Buffer Cache 中空闲数据块的数量，避免 Server Process 从磁盘把数据读入内存时没有空间可用。 DBWn 的写时机包括： 检查点，即数据库的检查点动作会触发 DBWn 进程工作；如果一个 Sever Process 在寻找可空闲数据块时， 超过了一定阈值仍然没能找到空闲块，就 会触发 DBWn 进程工作；每 3 秒自动唤醒一次。对于一个大型数据库或者修改非常频繁的系统而言，仅靠一个DBWn 进程为所有数据文件的写 操作提供服务，可能会力不从心。因此，Oracle 允许同时运行多个 DBWn 进程，以分担繁重的写负 载。这就是 DBWn 中n 的来历。数据库中最多可以使用 20 个DBWn 进程（n 从0~9 ，a~i）。数据库 初始化参数DB_WRITER_PROCESSES 就是用来定义DBWn 进程数量。如果没有定义这个参数， Oracle 缺省时按照 CPU 的数量来决定需要的进程个数。每8 个CPU 分配一个进程。 Oracle 推荐在增加 DBWn 进程数量之前，要先考虑使用异步 IO，有可能异步 IO就能够解决问 题，不需要增加进程数量。 2．LGWR （Log Writer）LGWR 进程的作用是吧LogBuffer中的日志内容写到联机日志文件中，从而释放Log用户Buffer空间。数据库的所有修改操作（增、删、改）都会生成日志，这些日志最初先保存在Redo LogBuffer中，然后在某个时刻由LGWR进程写入到磁盘的联机日志文件中。 触发LGWR 写操作的原因有几种： 用户提交，即用户发出 Commit 指令时会触发 LGWR 写操作；每三秒钟定时唤醒；如果使用的 Log Buffer 超过了配置的 1/3 时，即 1/3 满会触发 LGWR 的写操作；Log Buffer 中的日志数量超过 1MB 时，即 1MB 限制也会触发 LGWR 的写操作；由 DBWR 进程触发（1）提前写。 Oracle 使用的是提前写（Write-Ahead）机制，即和一个数据块相关联的的 Redo记录必须先于 数据块本身被记录到磁盘中。这就意味着，当DBWn 进程试图把一个脏数据块写到磁盘上之前， DBWn 进程会先确定和这个数据块相关联的所有Redo记录都已经被写到联机日志文件中了，如果 没有满足这个前提条件，那么 DBWn 进程就会通知 LGWR 进程，等待 LGWR 进程把相关日志都写 完后，DBWn 进程再把数据块内容写到磁盘文件中。 （2）快速提交。 每当用户发出Commit命令时，Oracle 只是会把Redo Log Buffer 中的记录写到日志文件中，同 时会在日志中写入一条代表事务已经提交的记录（Commit Record）。但是这个事务所修改到的数据 块并不会被写到数据文件中。或者说Oracle 对Commit操作成功的定义是这样的：只要这个事务的 Redo Record被写到日志文件中，这个事务就算是 Commit成功了，至于事务修改的数据是否记录到 数据文件没有任何关系。这也就是Oracle 的快速提交（Fast Commit）机制。 提前写（Write Ahead）和快速提交（Fast Commit）是 Oracle 两个很重要的运行机制，这两个机 制保证了事务提交不必等待数据写到磁盘，而之所以采用这种机制，也是平衡性能和可用性的结果。 对于一个繁忙的OLTP 系统来说，同时会有大量的事务发生，因此同时会有大量的Commit请 求，这时LGWR 进程就可以把许多的 Commit请求批量的写入日志文件，而不是针对每个Commit 请求立即处理，这种机制也叫做Group Commit。 3．CKPT（Checkpoint）所谓检查点，代表着数据库的一致性状态。在检查点时刻，数据文件的内容和SGA 中的内容 完全一致，也就是说在 SGA 中进行的所有数据修改都被写回到数据文件上，而数据库的一致性状态 也正是从这个角度来描述的。 注意：检查点所代表的数据一致和事务隔离级别所说的读一致性不是一个概念，后者是从数据完整性角度 来说的。而检查点的数据一致仅指内存和磁盘的数据一样，是从恢复的角度来说的，二者一定不能 混淆。虽然在检查点时刻，系统中会有很多未提交事务，修改后的脏数据最终可能被提交，永久生 效，也有可能回滚，还原成修改前的样子，但这不是检查点所关心的。检查点只关心恢复操作是否 可以从这一时刻开始。 在发生检查点机制时，会同时有 DBWn 、LGWR 、CKPT 三组进程的活动。首先，DBWR进程 要把脏数据写入的磁盘数据文件中，当然这个操作也会触发 LGWR 的工作。而 CKPT 进程只负责更 新控制文件中的检查点记录，它的任务量并不像 DBWn 进程和 LGWR 进程那么繁重. 4．PMON（Process Monitor）这个后台进程用来监控用户进程的。用户进程可能由各种原因导致异常终止，比如网络故障、用户机器断电等。这时用户进程对应着的服务进程可能还占用着系统资源，如果这些资源不及时释 放，就会影响正常用户的工作。 PMON 进程就负责在发现用户进程异常中止后的清理工作，以确保释放占用的资源。比如，一个用户进程可以在异常中止之前正在处理事务，使用了若干锁，突然用户计算机断电了，这些锁没 有被正常释放，而且这些锁永远不会有机会被正常释放，其他用户可能就要永久等待这些锁。这时 就需要PMON 进程强行进行清理工作，释放这些被占用的资源，以保证其他用户不会因为这些异常 中止进程的干扰。PMON 进程定期被唤醒，==其他进程也会在需要时主动唤醒PMON== 进程。 5．SMON（System Monitor）如果遭遇数据库异常关闭，SGA中还没有来得及写到磁盘的信息就丢失了，数据库再次启动时，就先要进行恢复工作，这种恢复叫做实例恢复（Instance Recovery ）。SMON 进程负责实例恢复，实例恢复分成3 个阶段。 前滚（Roll Forward）：这一阶段是读取联机日志，找到最后一次检查点之后的日志内容， 并重做这些日志，把数据库恢复到上次实例关闭时的状态，这时系统包含着提交和未提交的 事务。打开数据库：为了减少用户等待时间，Oracle 选择尽可能早地打开数据库，打开数据库以 后，再继续进行恢复工作。现在用户就可以使用数据库。回滚（Roll Back） ：SMON 进程回滚未提交的事务，Server Process 也可以进行部分回滚工作。除了实例恢复，SMON 进程还负责部分空间管理工作，包括： 如果使用字典管理表空间（DMT） ，SMON 进程需要合并空闲 Extents，以避免磁盘碎片， 这个功能叫做 Coalesce，这个任务每 3 秒执行一次；SMON 进程负责清理临时段，以释放空间；SMON 进程也是定期被唤醒或者被其他进程主动唤醒。 6．ARCn（Archiver）归档（Archiver）进程负责归档模式的数据库的归档操作。我们知道每个数据库都必须要创建 至少两组联机日志，这些日志是循环使用的，也就是一组日志写满后，LGWR 就切换到另一组日志 继续写入，周而复始。因此稍早产生日志终将被新的日志覆盖掉，这是非归档模式。而归档模式比 非归档模式多出的处理就是，在发生日志切换时，ARCn 进程被唤醒，把之前写满的日志做一个文 件拷贝，这个拷贝被保存到一个特殊的目录下——归档目录，这个拷贝就叫做归档日志。每个联机 日志能够被覆盖的前提条件也相应地多了一个，除了要完成检查点，还必须完成归档操作。 归档模式就是确保数据库所有操作日志都被保留下来，这样能够最大程度的保证数据库的可恢 复性。 ARCn 进程就是完成这个拷贝动作，和DBWn 进程一样，ARCn 进程可以有多个，最多是 10 个（n 取值范围为 0~9 ）。数据库的初始化参数 LOG_ARCHIVE_MAX_PROCESSES 就是定义数据库 启动时运行的ARCn 的个数。]]></content>
      <categories>
        <category>oracle</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[昆山实习路程规划]]></title>
    <url>%2F2018%2F09%2F03%2F%E6%98%86%E5%B1%B1%E5%AE%9E%E4%B9%A0%E8%B7%AF%E7%A8%8B%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[我们这个年代的孩子 mmp 第一次坐飞机怎么还还是特么一个人出发地武宿飞机场 T1航站楼（西方向） 提前一个小时到飞机场，航空公司规定航班起飞前30分钟停止办理登机手续 办登机牌手续。通过显示屏航班找柜台，把身份证，机票交给工作人员，在这里托运行李，20公斤以下免费，禁止违禁物品 过安检，将机票的机票的旅客联、登机牌、身份证交给安检员 候机。 登机口对应候机厅 登机 找机上位置。登机牌上标明有你的位置，如：5D、11C什么的，数字代表第几排，每排的座位是按A、B、C、D、E、F。。排的，飞机上的座位号标在放行李的舱壁（座位上方）。找到你的位置坐下，扣上安全带，起飞前关掉手机。 到达。飞机到达目的站后，如果你托运有行李，记得去取行李，在往出口的通过上会有取行李的地方。 中转站上海上海浦东机场 T2航站楼下了飞机如果在跑道上就随人群坐摆渡车到航站楼。联系酒店，接送服务找不到就问人到酒店的路线 北方英豪商务宾馆912 早上8点到9点出发坐地铁2号线 预计10点左右到达浦东机场→虹桥火车站 上海浦东机场到虹桥火车，共59.3公里。 地铁 地铁2号线东延伸段 → 地铁2号线 ,票价9元，大约需要100分钟。浦东机场出站厅后,会有很明显的标识指引,跟着走就是了。机场的大厅和地铁站的大厅是连在一起的从上海浦东国际机场站上车后，乘坐开往广兰路 方向的2号线到达广兰路站 下车，然后换乘地铁2号线 （徐泾东方向）虹桥火车站 下车 （南口出）出站旁边就是 虹桥火车站预计十二点到达虹桥火车站车票信息上海虹桥- 昆山南G1928 9月12日（周三） 12:55发车 预计20分钟到达昆山南 终点站 昆山市 打车 50元 或者坐公交半小时或1个半小时到达杰普软件基地]]></content>
      <categories>
        <category>旅行</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PLSQL中的三种参数模式IN、OUT、IN OUT]]></title>
    <url>%2F2018%2F09%2F03%2FPLSQL%E4%B8%AD%E7%9A%84%E4%B8%89%E7%A7%8D%E5%8F%82%E6%95%B0%E6%A8%A1%E5%BC%8FIN%E3%80%81OUT%E3%80%81IN%20OUT%2F</url>
    <content type="text"><![CDATA[我发现在别人心里我好像并不是我想的那么重要 1、IN模式IN模式是参数的默认模式，这种模式就是在程序运行的时候已经具有值，在程序体中值不会改变。 错误例子： 12345678910create or replace procedure in_proc ( p_a in number , -- 形参， 这里的值是调用处传递的实参 p_b in number )asbegin p_a := 10 ; //错误 --实参被传递进来以后，在这个程序体中值就不可能被改变了 p_b := 20 ; //错误 DBMS_OUTPUT.PUT_LINE(p_a) ; DBMS_OUTPUT.PUT_LINE(p_b) ;end ; 错误日志123456LINE/COL ERROR-------- -------------------------------------------6/5 PL/SQL: Statement ignored6/5 PLS-00363: 表达式 &apos;P_A&apos; 不能用作赋值目标7/5 PL/SQL: Statement ignored7/5 PLS-00363: 表达式 &apos;P_B&apos; 不能用作赋值目标 因为值传递到程序体中值就不会改变了 2、OUT模式out模式定义的参数只能在过程体内部赋值，表示该参数可以将某个值传递到存储过程的调用处。 错误例子： 12345678create or replace procedure out_proc ( p_a out number , --使用OUT模式 p_b out number ) as begin DBMS_OUTPUT.PUT_LINE(&apos;p_a : &apos; || p_a) ; --输出参数值 DBMS_OUTPUT.PUT_LINE(&apos;p_b : &apos; || p_b) ;end ; 目前out_proc过程体内并没有对参数进行赋值，编写一个PLSQL块，进行验证该过程。 12345678declare v_a number ; --定义变量 v_b number ;begin v_a := 10 ; --为变量赋值 v_b := 20 ; out_proc(v_a , v_b) ; --调用out_proc过程end ; 可以发现此时根本没有把参数传递的值打印出来，这样就可以验证使用OUT模式不可以传值的问题。 程序修改： 12345678910create or replace procedure out_proc ( p_a out number , --使用OUT模式 p_b out number ) as begin DBMS_OUTPUT.PUT_LINE(&apos;p_a : &apos; || p_a) ; -- OUT模式修饰的参数是不会接收从外部过程调用处传递进来的值 DBMS_OUTPUT.PUT_LINE(&apos;p_b : &apos; || p_b) ; p_a := 100 ; -- 在过程体内为参数赋值 p_b := 200 ;end ; 编写PLSQL块验证： 12345678910declarev_a number ; --定义变量v_b number ;beginv_a := 10 ;v_b := 20 ;out_proc(v_a , v_b) ; --调用out_proc过程DBMS_OUTPUT.PUT_LINE(v_a) ;DBMS_OUTPUT.PUT_LINE(v_b) ;end ; 这次值被成功输出了。这就验证了前面提出的问题（out模式定义的参数只能在过程体内部赋值，表示该参数可以将某个值传递到存储过程的调用处）。 简单来说就是OUT不可以接收从该过程的调用处传递进来的值，只能在过程体内部对参数进行赋值，而后才能把过程体内部的值传递到该过程的被调用处。 3、IN OUT模式IN OUT 通俗来说就表示既可以向过程体外传递参数也可以从过程体内传出数值 。 例子：12345678910create or replace procedure inout_proc ( p_a in out number , -- 定义形参 p_b in out number )as begin DBMS_OUTPUT.PUT_LINE(&apos;传递到过程体内的 p_a : &apos; || p_a ) ; --打印输出过程调用出传递进来的实参 DBMS_OUTPUT.PUT_LINE(&apos;传递到过程体内的 p_b : &apos; || p_b ) ; p_a := 100 ; -- 在过程体内为参数赋值 p_b := 200 ;end ; 编写PLSQL块验该过程 12345678910declare v_a number ; -- 定义变量 v_b number ;begin v_a := 10 ; --为变量赋值 v_b := 20 ; inout_proc(v_a , v_b) ; --调用inout_proc 传递实参进去 DBMS_OUTPUT.PUT_LINE(&apos;传递到过程体内的 v_a : &apos; || v_a ) ; -- 输出在过程体内被修改的值 DBMS_OUTPUT.PUT_LINE(&apos;传递到过程体内的 v_b : &apos; || v_b ) ;end ; 执行结果：12341 传递到过程体内的 v_a : 102 传递到过程体内的 v_b : 203 传递到过程体内的 v_a : 1004 传递到过程体内的 v_b : 200 IN OUT简单来说就是过程调用处传递的实参，在过程体内会被接收到。并且在过程体内为形参赋的值也会被传递到过程调用处。]]></content>
      <categories>
        <category>oracle</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[编译原理LR0分析法]]></title>
    <url>%2F2018%2F09%2F03%2F%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86LR0%E5%88%86%E6%9E%90%E6%B3%95%2F</url>
    <content type="text"><![CDATA[唯离散者，方查其荣辱 一、LR分析的基本原理1、LR分析的基本思想LR方法的基本思想就是，在规范归约的过程中，一方面要记住已移进和归约出的整个字符串，也就是说要记住历史；一方面能够根据所用的产生式的推测未来可能碰到的输入符号，也就是说能够对未来进行展望。这样，当一串貌似句柄的字符串出现在分析栈的顶部时，我们希望能够根据历史和展望以及现实的输入符号这三部分的材料，决定出现在栈顶的这一串符号是否就是我们要找的句柄。 2、LR分析器的构成采用下推自动机这种数据模型。包括以下几个部分： 1.输入带 2.分析栈：包括状态栈和文法符号栈两部分。(s0,#)为分析开始前预先放在栈里的初始状态和句子括号。 3.LR 分析表：包括动作表和状态转移表两张表。 3、LR分析表是LR分析器的核心部分一张LR分析表包括两部分：动作表(ACTION)和状态转换表(GOTO)。它们都是二维数组。ACTION[s,a]规定了当状态s面临输入符号a时应采取什么动作(移进、归约、接受和报错)，而GOTO[s,X]规定了当状态s面对文法符号X(终结符或非终结符)时的下一状态是什么。 显然， GOTO[s,X]定义了一个以文法符号为字母表的DFA。 不同的 LR 分析法构造LR分析表的方法都不同，由此产生了不同的LR分析法。 4、LR分析算法123456789101112131415161718192021置ip指向输入串w的第一个符号 令Si为栈顶状态 a是ip指向的符号（当前输入符号） BEGIN(重复开始) IFACTION[Si,a]=SjTHEN BEGIN PUSH j,a (进栈) ip前进(指向下一输入符号) END ELSEIFACTION[Si,a]=rj(若第j条产生式为A→β) THEN BEGIN pop|β| 项 若当前栈顶状态为Sk pushGOTO[Sk,A] 和A(进栈) END ELSEIFACTION[Si,a]=acc THEN return (成功） ELSE error END. (重复结束) 二、LR（0）分析器1、可归前缀与规范句型的活前缀文法G[S]：(1) S → aAcBe[1](2) A → b[2](3) A → Ab[3](4) B → d[4] S → ÞaAcBe[1] → ÞaAcd[4]e[1] → ÞaAb[3]cd[4]e[1] → Þab[2]b[3]cd[4]e[1] 每次归约句型的前部分依次为：ab[2]aAb[3]aAcd[4]aAcBe[1] 规范句型的这种前部分符号串称为可归前缀 我们把形成可归前缀之前包括可归前缀在内的所有规范句型的前缀都称为活前缀 （活前缀就是可归前缀的前缀）如下： e,a,ab e ,a,aA,aAb e ,a,aA,aAc,aAcd e ,a,aA,aAc,aAcB,aAcBe 三、LR分析（一）LR分析构造识别活前缀的有穷自动机项目（item）：在每个产生式的右部适当位置添加一个圆点构成项目。 根据圆点所在的位置和圆点后是终结符还是非终结符把项目分为以下几种： 移进项目，形如 A→a•ab 待约项目，形如 A→a•Bb 归约项目，形如 A→a• 接受项目，形如S’ →S• 根据圆点所在的位置和圆点后是终结符还是非终结符把项目分为以下几种： 移进项目，形如 A →a . ab 待约项目，形如 A→a . Bb 归约项目，形如 A→a . 接受项目，形如 S’→S. 把文法的所有产生式的项目都引出，每个项目都为NFA的一个状态。其中 文法的第一个产生式的第一个项目为文法的初态 文法的接受项目为文法的句子识别态 文法的每一个产生式的归约项目为文法的句柄识别态 构造步骤： 项目圆点的左部表示分析过程的某个时刻用该产生式归约时句柄已识别的部分，圆点右部表示待识别的部分。 构造识别活前缀的NFA：1、把文法的所有产生式的项目都引出，每个项目都为NFA的一个状态2、确定初态、句柄识别态、句子识别态3、确定状态之间的转换关系 若项目i为 X → X1X2…Xi-1• Xi…Xn 项目j为 X → X1X2…Xi-1 Xi •Xi+1…Xn 则从状态i到状态j连一条标记为Xi的箭弧 若i为X→g•Ad，k为A→•b，则从状态i画标 记为 e的箭弧到状态k （二）将非确定的有限自动机转换成确定的有穷自动机方法一：（采用子集构造法） 方法二：通过构造文法G的LR（0）的项目集规范族来直接构造识别活前缀的DFA LR(0)项目集规范族的构造 构成识别一个文法活前缀的DFA项目集（状态）的全体称为这个文法的LR(0)项目集规范族 （1）通过闭包函数(CLOSURE)来求DFA一个状态的项目集，找出所有的等价的项目。 如果I是文法G’的一个项目集，定义和构造I的闭包CLOSURE(I)如下：a)I的项目都在CLOSURE(I)中b)若A→a• Bb属于CLOSURE(I)，则每一形如B→• g的项目也属于CLOSURE(I)c)重复b)直到CLOSURE(I)不再扩大 （2）定义转换函数如下：GOTO（I，X）=CLOSURE（J）其中：I为包含某一项目集的状态，X为一文法符号 J={任何形如A→aX •b的项目|A→a•X b属于I} 圆点不在产生式右部最左边的项目称为核，唯一的例外是S’ → • S。因此用GOTO（I，X）转换函数得到的J为转向后状态所含项目集的核 使用闭包函数（CLOSURE）和转向函数(GOTO(I,X))构造文法G’的LR(0)的项目集规范族，步骤如下： a)置项目S’→ •S为初态集的核，然后对核求闭包CLOSURE（{S’→ •S}）得到初态的项目集b)对初态集或其它所构造的项目集应用转换函数GOTO(I，X)=CLOSURE(J)求出新状态J的项目集c)重复b)直到不出现新的项目集为止 例题已知文法 12S-&gt;a|^|(T) T-&gt;T,S|S 构造它的 LR(0) 分析表。 解：加入非终结符 S’ ，方法的增广文法为： 123456S&apos;-&gt;S S-&gt;a S-&gt;^ S-&gt;(T) T -&gt;T,S T -&gt;S 下面构造它的 LR(0) 项目集规范族为：从上表可看出,不存在移进归约冲突以及归约归约冲突，该文法是 LR(0) 文法。 从而有下面的 LR(0) 分析表]]></content>
      <categories>
        <category>编译原理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[2018 天津]]></title>
    <url>%2F2018%2F08%2F26%2F2018%20%E5%A4%A9%E6%B4%A5%2C%E9%9A%8F%E7%AC%94%2F</url>
    <content type="text"><![CDATA[另外，我想说，异乡的告别真痛苦带着欢声笑语我们上路，在离开时的无言里我们各奔东西 我还记得你和我说的，如果旅行不是自己规划的是没有灵魂的。可是对我而言，如果旅行的方向没有你那也毫无意义。 天津之眼摩天轮 1- 天津的美丽地标，拍摄夜景、乘坐观光都十分浪漫 这次旅行揭开了我好多的第一次，印象最深的还是摩天轮，我可能是轻微恐高，坐在这个缓缓向上的大机器里，竟然有了恐惧的心情，摩天轮还未到中点，我甚至不敢抬头看还会爬多高，也不敢看地下，因为会觉得自己就要掉下去。还有在车厢里悄悄拍下你，希望能在我将来天天里能想起你的笑脸 ## 意大利风情区1- 古老典雅的红顶意式建筑群，漫步其中，仿佛置身欧洲小镇。 之前幻想过到了这里会不会就是梦中的佛罗伦萨，仿佛，仿佛了些什么啊哈哈你是我最想看到的风景 古文化街1-天津老字号店铺和手工艺品集中地，逛街购物、品尝美食的好去处。 每个城市都会有这么个地方，古色古香的商业化地方 五大道1- 众多民国风云人物的寓居之处，在栋栋洋房之间看旧日津门缩影。 一个安静的街区，欧式的建筑也会让人产生一种欧式缓慢节奏的感觉 晚上第一次吃了小龙虾，印象并不好，只是因为我们差点因为它吵了一架 瓷房子1- 精美的中国古代瓷器密密麻麻贴满墙壁，奢华和创意程度令人惊叹！ 门票太贵了，远远看了一眼这个不明意义的建筑 世纪钟广场1- 天津地标，大钟庞大而精密，是很多游客合影留念的必到之处。 下了火车就看到了，很惊艳，也很惊讶，遗憾没有合影啊 西开教堂1- 天津主教堂，参观繁复精美的建筑和雕塑，还可以参加弥撒活动。 也是第一次去教堂吧，庄严的气氛一遍遍冲刷着心里，平时玩世不恭的我也变得虔诚起来，里面不光游客，真正的天主教徒，印象最深的是偶然听到一个老奶奶纯正的天津口音，“咱看不见他（耶稣），他都看着咱呐” 有一个信仰支持着如何做人做事，真好晚上查了六级成绩，过了，我觉得这必然得谢谢那个耶稣老人家]]></content>
      <categories>
        <category>旅行</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[2018 天津]]></title>
    <url>%2F2018%2F08%2F18%2F2018%20%E5%A4%A9%E6%B4%A5%2F</url>
    <content type="text"><![CDATA[后来多少人想起了他们会在那样的地方告别，也忘记了告别的时候要再用力一点，多一句话说不定就是最后一句，多看一眼也说不定就是最后一眼吧。2018 相聚有时，后会无期 天津之眼摩天轮 1- 天津的美丽地标，拍摄夜景、乘坐观光都十分浪漫 门票 70元 景点介绍“天津之眼是一座横跨在海河上的摩天轮，就像是桥上的一只眼睛，这里也是天津最著名的的地标之一，每到夜晚华灯初上时，天津之眼的彩灯柔美，无数游客会来到这里，拍摄全景或是乘坐观光，享受别样的浪漫。 游玩天津之眼一般有两种方式，乘坐或是远观拍照。乘坐摩天轮70元每人，如果想要独享，还可以花400块包一个包厢（限坐5人或以下）。摩天轮运营一圈大约是30分钟，座舱内有空调，可以缓慢舒适的观赏周围开阔的景色，尤其夜晚天黑后华灯初上，十分漂亮。 如果要拍摄摩天轮，最佳的位置是在摩天轮南侧的金刚桥上，站在桥上，三岔河口（海河、南运河、北运河交汇处）就在眼前，柔美的天津之眼展开在眼前，周围是海河两岸的美丽建筑，随便一按就是漂亮的标志照片。 特别提示摩天轮目前每天上午9:30开始运营，下午到票售罄时即结束，每到节假日时摩天轮旁都会排起大长队，常常五六点钟票就售完了，所以若有条件还请避开节假日。 ## 意大利风情区1- 古老典雅的红顶意式建筑群，漫步其中，仿佛置身欧洲小镇。 景点介绍意大利风情区位于天津市中心，在这里有200余栋地中海风格的典雅建筑。漫步其中，就好像行走在浪漫的欧洲小镇，众多的名人故居、影视剧取景地也为游人的旅程增色不少。 意大利风情区就在海河的旁边，从海河边（北安桥）走过来，首先看到是高高的有尖顶的钟楼，再往前，看到精致的镂空铜马车，标志着意大利风情区到了。沿街随意逛逛，看看红顶意式建筑群，欧式雕塑，踱步到马可波罗广场。马可波罗广场是景区的标志性建筑之一，中央柯林斯式的石柱上站着手持橄榄枝的和平女神。往西走，是威尼斯广场的“飞狮许愿池”，它远没有《罗马假日》电影里真正的罗马许愿池的气魄和鼎盛人气，可与整个意大利风情区营造的气氛融合，也依稀有电影的感觉了。的确有众多影视剧来这里取景，比如《建国大业》、《金粉世家》等，游人可以在这里找到剧中熟悉的场景，同时，也吸引了很多拍婚纱照的爱侣。 除此之外，景区拥有众多名人故居。梁启超故居，大名鼎鼎的“饮冰室”就在这里；民国大总统、大军阀曹锟故居现在是渤海商品交易所；袁世凯故居、冯国璋旧宅现已改为饭店；还有曹禺故居、张廷谔旧宅等。参观一下介绍天津历史和未来城市规划的天津市规划展览馆也不错，记得带好身份证领取免费门票。 到了夜晚，意式建筑亮了灯，西餐厅、咖啡店里的烛光、灯光摇曳，酒吧变得热闹，意大利风情区的景色和氛围更加迷人。去布置得颇具特色，堆满啤酒罐和啤酒桶的巴伐利亚啤酒坊来杯啤酒；或者去酒吧中比较出名的13CLUB坐坐，摇滚乐是它的特色，唐朝、纸娃娃等摇滚乐队都来这里演出过，具体演出场次和门票可关注网站：http://site.douban.com/tj13club/room/559651/ 意大利风情区有不少店铺，出售精致的工艺品、小玩意儿，不过价钱略贵，建议看看就好。 古文化街1-天津老字号店铺和手工艺品集中地，逛街购物、品尝美食的好去处。 景点介绍古文化街位于天津市南开区，以天后宫为中心，南起水阁大街，北到通北路。这里是天津最著名的老字号和手工艺品店铺集中地。可以找到杨柳青年画、泥人张、魏记风筝等众多的手工艺品，还能品尝到经典的天津美食。 古文化街目前有上百家店堂，大多是天津老字号店铺，充满浓郁的民间特色。这里有出售景泰蓝、苏绣、漆器等的综合性店铺乔香阁；有出售土特产的果仁张、皮糖张、崩豆张；最负盛名的还是民间工艺品店铺，拥有神态逼真的彩绘泥塑的“泥人张”，使用木板印绘年画的杨柳青年画，制作形态各异的风筝的“风筝魏”等，都是游客到古文化街必须去逛一逛的店铺。逛街的同时还可以享受天津特色美食，狗不理包子，煎饼果子，天津大麻花等，绝对满足吃货的胃口。店铺早上8:30左右开张，晚上17:30左右打烊，可以注意一下逛街的时间。 除了逛街、吃美食，古文化街还有不少名胜古迹，可以好好逛逛看看。天后宫位于古文化街中心，也是古文化街古迹的核心，祭祀保佑出海远航平安的天后娘娘，已有600余年历史。现在是天津民俗博物馆的所在地，馆内介绍了天津城历史、民俗，陈列着明代天津城砖、清代漕运模型、清代水机等文物。戏楼又称“津门老戏楼”，可以看相声和变戏法表演。大狮子胡同是近代思想家、教育家严复故居所在地，原房屋已不在，现在旧址上建天演广场，铸有严复铜像。另外还有通庆里、玉皇阁等等，各有特色。 每年的农历3月23日是天后娘娘的生日，届时古文化街会举行皇会（最初叫“娘娘会”，因乾隆下江南时曾游此会于是得名“皇会”），天后宫前广场、宫南、宫北一带都能看到表演，有龙灯舞、狮子舞、少林会、高跷、法鼓、旱船、地秧歌、武术以及京戏、评剧、梆子等，是整个天津最热闹的庙会之一。 五大道1- 众多民国风云人物的寓居之处，在栋栋洋房之间看旧日津门缩影。 -景点介绍五大道位于天津和平区，以区域内五个主要的道路命名，实际有二十多条街道。这里曾经是英租界，在民国时期，清朝遗老、北洋政府里很多官员名流都曾在这里寓居，一栋栋优美典雅的洋房仿佛在诉说着津门曾经的风云故事。 -五大道总述目前来到五大道游览，主要就是观看街道上2000多所花园式的欧式建筑，其中名人故居就有三百多处，张学良、顾维钧、吉鸿昌、爱新觉罗载振等众多清末民初的名流都在这里留下了名字。这里的建筑整体是欧式，但形式多样各有特色。街区优雅浪漫，不少影视剧组来此取景，拍婚纱照的也爱把五大道的小洋房当背景。不过大多数的洋房目前都铁门紧闭，并不能进入。 -游玩方式初到五大道，如果摸不清东南西北，可以先到长沙路101号的民园广场，看看曾经的欧式体育馆，这里也相当于是五大道的集散中心。广场附近的游客中心里，可以拿一份地图（也有付费购买的更清晰版），上面标注了五大道很多故居、著名建筑的所在地，根据地图参观游玩即可。另外，在这里也可以选择乘坐马车和骑自行车，马车每人80元，自行车大约每小时10元左右，都是游玩五大道的经典方式。 -参观重点五大道内，很多的点都很值得参观，整个下来大约要大半天时间，其中有几处建筑是参观的重点。疙瘩楼在河北路，墙上一粒一粒烧过火的砖形成的疙瘩已经十分特别，而且还是一座瓷片贴满的洋房；马场道117号的天津外国语学院是电视剧《金粉世家》的取景地；清朝庆亲王载振的公馆建筑中西合璧，在重庆道；蔡成勋故居是五大道唯一的中式建筑，在这里显得十分特别，位于大理道；同样在大理道的睦南公园每年春天都有鲜花开放，给游人带来惊喜。另外，在这些建筑中，很多都提供餐饮或者下午茶服务，虽然价格较贵，但是想想在民国名流的家中用餐，格调还是蛮高的。 瓷房子1- 精美的中国古代瓷器密密麻麻贴满墙壁，奢华和创意程度令人惊叹！ 景点介绍“瓷房子是一座动用了无数私藏古瓷器、汉白玉石雕、水晶、玛瑙、古董装饰而成的法式建筑。房子的墙上密密麻麻贴满了精美的中国古代瓷器，庭院和楼内堆满了古董，铺天盖地的瓷器古董常让初到瓷房子的游客眼花缭乱。 瓷房子的围墙由数百个民国和晚清时期的古瓷瓶垒砌串联而成，名平安墙。房顶用古瓷片拼成的巨龙盘旋出“China”的图案，巨龙后是碎瓷片拼出的2008年奥运主体育场鸟巢。注意看房子外围右侧，有一竖排的瓷猫从顶层延伸到一层墙角，瓷猫周边镶嵌满水晶、玛瑙，如此兴师动众装饰的却是一根下水管道，令人赞叹。 整幢楼共有五层，地下室不对外开放，一到四层供游客参观。每一层楼内都摆放着许多雕刻细腻的古代木制家具，红色墙壁上用瓷片贴出古今中外的名人字画。一层中央放着一只宋代大瓷缸。二楼和三楼都有阳台可以观景，一定要抬头看阳台的天花板，天花板是由一个个整只的古代瓷器盘子贴出来的，越往中间的盘子越价值不菲。由于每一层中央都是镂空的，从四楼可以一直看到一楼中央的大瓷缸。 面朝瓷房子，左手边有一间同样覆盖满精美瓷器的小房间是厕所，看一看就好，为了在水晶、玛瑙与瓷器堆中上一回脱俗、唯美的厕所，厕所门前经常排长队。 瓷房子的右手边就是出口了，别直接走出去了，出口所在的小房间有“镇馆之宝”。在瓷房子庭院中所见古董石像有些没有头部，头都在出口的耳房这，其中最大的一颗佛头就是“镇馆之宝”了，佛眉心间有个原来是放红宝石用的大凹槽。出口的这间房间不允许照相。 若光看这幢瓷房子还不过瘾，在天津五大道有一幢疙瘩楼（河北路283号），和瓷房子有异曲同工之妙，离得也不远，可以过去看看。 世纪钟广场1- 天津地标，大钟庞大而精密，是很多游客合影留念的必到之处。 景点介绍世纪钟广场位于海河北岸，天津火车站旁，广场上有一座巨大的机械钟，是天津的地标建筑，很多到天津游玩的游客都会来这里拍照留念。 世纪钟高达40米左右，大部分由金属制成，在世纪钟旁边就能看到内部的钟表骨架，众多的零件咬合在一起，共同支撑着前面表盘的分秒不差，做工的精密让人赞叹。世纪钟整个呈黑色，上面有代表12星座的浮雕等装饰，每天晚上世纪钟广场会亮起暖黄灯光，结合钟表本身的复古感觉很有质感。世纪钟广场周围则是海河两边的繁华街区，所以到这里拍摄夜景也是很多游客的选择。 西开教堂1- 天津主教堂，参观繁复精美的建筑和雕塑，还可以参加弥撒活动。 景点介绍西开教堂位于繁华的滨江道商业街的最南端，始建于1917年，是天主教天津教区的主教堂。教堂建筑风格庄重大气，教堂内的雕塑也都繁复精美，另外弥撒和天主教节日的活动对外开放，可以参与其中，感受浓厚的宗教氛围。 外部参观教堂外部用红黄相间花砖砌成，三座呈品字形排列、高耸入云的塔楼上浮盖着绿色铜片，经过岁月的冲刷，斑驳的绿色在阳光的照耀下反而闪烁出具有历史感的光彩，塔楼顶上各有一个青铜十字架。 内部建筑走进教堂，映入眼帘的首先是湖蓝、白色、淡黄构成的内部主色调，给人一种清新的感觉，只在恰到好处的位置上雕刻着各种花纹，14根立柱从门口排列到祭台，气度不凡。教堂四周列着一座座精美的教徒铜像，墙壁上则挂着一幅幅记述耶稣受难故事的油画，教堂内还有圣母、耶稣、天使等的彩色塑像。另外，一扇扇彩绘玻璃窗也很迷人。在教堂的一侧你会发现一个木质小房间，顶上有小小的十字架，那是供神甫接待信徒忏悔告解用的“告解亭”。 宗教活动西开教堂的弥撒活动对外开放，非教徒同样可以参加，不过弥撒时间不可以在教堂里跑来跑去到处参观，静静地坐在后排，不能大声喧哗、不要拍照，去感受繁华都市中内心的那一份宁静就好。另外也有很多天主教节日的活动，也和弥撒一样对外开放。具体弥撒和天主教节日活动时间可见官网：http://www.tj-church.org/About/misa/]]></content>
      <categories>
        <category>旅行</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[词法分析-正规式、NFA和DFA之间的转化：]]></title>
    <url>%2F2018%2F08%2F17%2F%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90-%E6%AD%A3%E8%A7%84%E5%BC%8F%E3%80%81NFA%E5%92%8CDFA%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BD%AC%E5%8C%96%EF%BC%9A%2F</url>
    <content type="text"><![CDATA[坚持 正规式与NFAg关系对照图注意优先级关系，闭包运算*最高，连接运算.次之，或运算最低 考题构造正则式1a*b|7C(ab)*b 对应的DFA。ε 1)先画出对应的NFA12345678910graph LRX--&gt;|ε|11--&gt;|a|11--&gt;|ε|2X--&gt;|ε|33--&gt;|a|55--&gt;|b|33--&gt;|ε|42--&gt;|b|Y4--&gt;|b|Y 2)确定化DFA这个表是从NFA到DFA的时候必须要用到的。第一列第一行I的意思是从NFA的起始节点经过任意个ε所能到达的结点集合。X|Ia|Ib—|—| —{X,1,2,3,4} |{1,2,5} | {Y}{1,2,5}|{1,2} | {3,4,Y}{Y}|- |-{1,2}|{1,2} |{Y}{3,4,Y} |{5} |{Y}{5}|- |{3,4}{3,4}|{5} |{Y} X Ia Ib A B C B D E C - - D D C E F C F - G G F C 1注：加粗为终止状态 CE NFA确定化的时候，包含NFA初态的那个DFA状态就是确定后的DFA的初态 DFA的终态就是所有包含了NFA终态的DFA的状态123456789101112graph LRA--&gt;|a|BA--&gt;|b|CB--&gt;|a|DB--&gt;|b|ED--&gt;|a|DD--&gt;|b|CE--&gt;|a|FE--&gt;|b|CF--&gt;|b|GG--&gt;|a|FG--&gt;|b|C 3)最小化DFA 首先按照非终止和终止状态，将状态分为K1｛A,B,D,F,G｝，K2｛C,E｝ 考察K1 用a输出K1-a-&gt;K1 用b输出 A-b-&gt;K2 B-b-&gt;K2 D-b-&gt;K2 F-b-&gt;K1 G-b-&gt;K2 所以K1分为{A，B，D，G}，{F}在{A，B，D，G}中 因为G-a-&gt;F所以分为{A,B,D}{G}同理可以分为{A}{B}{D} 考察K2 因为C没有ab输出 所以直接分开{C} {E}]]></content>
      <categories>
        <category>编译原理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[DFA最小化--分割法]]></title>
    <url>%2F2018%2F08%2F17%2FDFA%E6%9C%80%E5%B0%8F%E5%8C%96--%E5%88%86%E5%89%B2%E6%B3%95%2F</url>
    <content type="text"><![CDATA[千里之行始于足下 FA的最小化就是寻求最小状态DFA 最小状态DFA的含义: 1.没有多余状态(死状态)除多余状态 什么是多余状态？从这个状态没有通路到达终态；S1从开始状态出发，任何输入串也不能到达的那个状态。S2 如何消除多余状态？1删除！ ## 2. 没有两个状态是互相等价（不可区别）两个状态s和t等价的条件：兼容性（一致性）条件——同是终态或同是非终态传播性（蔓延性）条件——对于所有输入符号，状态s和状态t必须转换到等价的状态里。 DFA的最小化—例子，第一步都是固定的。分成终态和非终态 １．将Ｍ的状态分为两个子集一个由终态k1=｛Ｃ，Ｄ，Ｅ，Ｆ｝组成，一个由非终态k2=｛Ｓ，Ａ，Ｂ｝组成， ２．考察｛Ｓ，Ａ，Ｂ｝是否可分． 因为Ａ经过a到达C属于k1.而S经过a到达A属于k2.B经过a到达A属于k2，所以K2继续划分为{S，B},{A}, ３．考察｛Ｓ，Ｂ｝是否可再分： B经过b到达D属于k1.S经过b到达B属于k2，所以S，B可以划分。划分为{S},{B} ４．考察｛Ｃ，Ｄ，Ｅ，Ｆ｝是否可再分： 因为Ｃ，Ｄ，Ｅ，Ｆ经过a和b到达的状态都属于｛Ｃ，Ｄ，Ｅ，Ｆ｝=k1所以相同，所以不可再分： ５．｛Ｃ，Ｄ，Ｅ，Ｆ｝以｛Ｄ｝来代替则，因为CDEF相同，你也可以用C来代替。无所谓的最小化的ＤＦＡ如图，：]]></content>
      <categories>
        <category>编译原理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[编译原理中，形式语言里怎么区分文法类型]]></title>
    <url>%2F2018%2F08%2F17%2F%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E4%B8%AD%EF%BC%8C%E5%BD%A2%E5%BC%8F%E8%AF%AD%E8%A8%80%E9%87%8C%E6%80%8E%E4%B9%88%E5%8C%BA%E5%88%86%E6%96%87%E6%B3%95%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[四种文法的判断非常简单，说到到，四种文法就是规定产生式的左和右边的字符的组成规则不同而已，其它的不能理解就不要去想了，你只要知道判断的时候就是以产生式的左边和右边符合的规则进行判断。下面解释一下如何根据产生式左边和右边的特征来进行判断。 首先，应该明确，四种文法，从0型到3型，其规则和约定越来越多，限制条件也越来越多，所以，我们判断时可以从最复杂的3型进行判断，依次向下判断，如果不符合3型的，那再看是不是2型的，不是2型的，再看是不是1型的，当然，对于作题作的熟的朋友，不用这么复杂，可以一眼直接看出来。先来看看教科书的解释 3型文法遵循什么规范呢？ 第一点：左边必须只有一个字符，且必须是非终结符； 第二点：其右边最多只能有两个字符，且当有两个字符时必须有一个为终结符而另一个为非终结符。当右边只有一个字符时，此字符必须为终结符。 第三点：对于3型文法中的所有产生式，其右边有两个字符的产生式，这些产生式右边两个字符中终结符和非终结符的相对位置一定要固定，也就是说如果一个产生式右边的两个字符的排列是：终结符＋非终结符，那么所有产生式右边只要有两个字符的，都必须前面是终结符而后面是非终结符。反之亦然，要么，就全是：非终结符＋终结符。 再看2型文法如何判断：第一点：与3型文法的第一点相同，即：左边必须有且仅有一个非终结符。第二点：2型文法所有产生式的右边可以含有若干个终结符和非终结符（只要是有限的就行，没有个数限制）。 依2型文法的判断规则，你的三个文法都属于2型文法，即：上下文无关文法。 再看1型文法如何判断：第一点：1型文法所有产生式左边可以含有一个、两个或两个以上的字符，但其中必须至少有一个非终结符。第二点：与2型文法第二点相同。 依1型文法判断规则，显然，你的文法也是属于1型的。 最后是0型文法，这个就不用看了，只要你能描述出来，都属于这个类型，即0型。]]></content>
      <categories>
        <category>编译原理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[编译原理：短语、直接短语、句柄、素短语]]></title>
    <url>%2F2018%2F08%2F16%2F%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%EF%BC%9A%E7%9F%AD%E8%AF%AD%E3%80%81%E7%9B%B4%E6%8E%A5%E7%9F%AD%E8%AF%AD%E3%80%81%E5%8F%A5%E6%9F%84%E3%80%81%E7%B4%A0%E7%9F%AD%E8%AF%AD%2F</url>
    <content type="text"><![CDATA[概念12如果Ｓ-&gt;* αＡβ and A-&gt;+γ，则称γ是句型αγβ的相对于变量A的短语 如果Ｓ-&gt;* αＡβ and A-&gt;γ，则称γ是句型αγβ的相对于变量A的直接（简单）短语 最左直接短语叫做句柄 其实最简单的判断方法直接画出语法树了。 文法S-&gt;(L)|aS|aL-&gt;L,S|S分析(S,(a)) 1.先画出语法树 2.判断短语1一个句型的语法树中任一子树叶节点所组成的符号串都是该句型的短语。 很明显的，最下面的a是S的叶子节点、最左边的S是L的叶子节点。其他的叶子节点从左往右分别是(,,,(,),)在树的第四层的(,L,)都是子树S的孩子，因为短语都是叶子节点，所以这边的短语有(a)在树的第三层的L,,,S都是子树L的孩子，因为短语都是叶子节点，所以这边的短语有S,(a)在树的第二层的(,L,)都是根节点S的孩子，因为短语都是叶子节点，所以这边的短语有(S,(a)) 所以短语有a (a) S,(a) (S,(a)) S 3.判断直接（简单）短语1当子树不包含其他更小的子树时，该子树叶节点所组成的字符串就是该句型的直接短语 短语包含直接短语，我们可以直接在短语中判断。这里只有第五层的S和第三层的L不包含其他更下的子树，所以有a和S是直接短语。其中(a)的父节点S包含L，S,(a)的父节点L包含L和S， (S,(a))的父节点S包含L 4.判断句柄1句柄是最左边的直接短语 因为S处于最左边，所以S是直接短语 5.判断素短语1素短语是一个短语，它至少含有一个终结符，而且除他之外不含有其他素短语 。 短语包含素短语，我们可以直接在短语中判断。因为S可以推导出其他字符，(a);S,(a);(S,(a))都包含其他素短语a，所以符合条件的只有a。]]></content>
      <categories>
        <category>编译原理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[oracle复习重点第一章]]></title>
    <url>%2F2018%2F08%2F13%2Foracle%E5%A4%8D%E4%B9%A0%E9%87%8D%E7%82%B9%E7%AC%AC%E4%B8%80%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[第一章1、基本概念（表空间、模式等）、默认的表空间、表空间与数据文件之间的关系，表空间与段、区和数据块之间的关系；逻辑存储结构包括数据块、区、段、表空间和模式对象。 数据块、区、段和表空间 数据块（database block） ：数据块是数据库读/写数据的最小储存单元，数据块的大小通常设置为os块大小的整数倍。常见大小为2k或者4k。 区（extent） ：由一组连续的数据块所组成的逻辑单位。 段（segment） ：由一个或多个不连续的区的集合，Oracle数据库包括数据段、索引段、临时段、回滚段等。 表空间（Tablespace）：由若干个段组成，它是最大的逻辑存储单元，Oracle数据库被划分为一个或多个称为表空间的逻辑结构。关系一个数据库从逻辑上说是由一个或多个表空间所组成，一个表空间由若干段组成，一个段是由若干区所组成，一个区是由一组连续的数据块组成，而一个数据块对应硬盘上的一个或多个物理块。 1234567891011graph TDA[数据库]--&gt;B(表空间)A[数据库]--&gt;C(表空间)A[数据库]--&gt;D(表空间)C[表空间]--&gt;E(段)C[表空间]--&gt;f(段)C[表空间]--&gt;g(段)E[段]--&gt;H(区)E[段]--&gt;I(区)H[区]--&gt;J(一连串的数据快)J[一连串的数据块]--&gt;K(对应硬盘上一个或多个物理块) Oracle数据库被划分为一个或多个称为表空间的逻辑结构，系统默认创建的表空间包括： （1）EXAMPLE表空间是示例表空间 （2）SYSTEM表空间是系统表空间 （3）SYSAUX表空间是辅助系统表空间 （4）TEMP表空间是临时表空间 （5）UNDOTBSI表空间是重做表空间。 （6）USERS表空间是用户表空间 Oracle的模式对象包括表、视图、序列、同义词、索引等 21个对象。用户使用的一系列的模式对象的集合称为用户的方案。表是数据库中存放用户数据的对象。它包含一组列描述当前实体的属性，每个列都有一个名字和若干个属性。 2、oracle的外部结构：数据文件、日志文件和控制文件；(掌握功能)1234graph TDA[物理存储结构哦]--&gt;B(数据文件)A[物理存储结构哦]--&gt;c(控制文件)A[物理存储结构哦]--&gt;d(日志文件) 物理存储结构是从物理存储的角度分析数据库的组成，也就是系统创建和使用的操作系统物理文件。 数据文件数据文件用于保存数据库中的全部数据。如表、数据和索引。数据文件一般以*.dbf命名。数据库、表空间和数据文件之间的关系如图所示：一个Oracle数据库是由一个或多个表空间构成的， Oracle数据库的每个表空间由一个或多个数据文件构成，这些文件由Oracle所在的操作系统管理 重做日志文件重做日志文件（Redo Log Files）用于记录数据库所做任何变更。这些变更被记录在联机重做日志文件（Online Redo Log File）中。当数据库中的数据遭到破坏时，可以用这些日志来恢复数据库。通常以*.log命名。重做日志文件记录对数据库的所有修改信息，用于故障恢复 重做日志文件写入过程 控制文件每一个Oracle数据库，都有相应的控制文件，它们是较小的二进制文件。用于记录数据库的物理结构。通常以*.ctl命名。它们包括： （1）Oracle数据库名称与建立时间； （2）数据文件与重置日志文件名称及其所在位置； （3）日志记录序列码（Log Sequence Number）。控制文件是记录数据库物理结构的二进制文件。二者的关系数据库实例 数据库实例是Oracle为了完成用户服务而启动的一系列的程序。 它包含系统全局区（SGA）和后台进程两部分。 1234graph LRa[oracle实例]--&gt;|分配|b(系统全局区SGA)a[oracle实例]--&gt;|启动|c(后台进程) 系统全局区1234graph TDa[SGA的内存结构]--&gt;b(数据高速缓冲区)a[SGA的内存结构]--&gt;c(共享池)a[SGA的内存结构]--&gt;d(重做速缓冲区) SGA是系统为实例分配的一组共享内存缓冲区，用于存放数据库系统信息。多个进程可以同时对SGA中的数据进行访问和相互通信。 数据高速缓冲区数据高速缓冲区存放着数据库最近使用过的数据块。当用户访问相同的数据时，可以直接在数据缓冲区中提取，而不必再到数据文件中读取。 获取和修改数据的时候大大地提高了性能 通过LRU算法管理可用空间共享池共享池相当于程序高速缓冲区。用来储存最近执行过的SQL语句和最近使用过的数据定义。它由库缓冲区和数据字典缓冲区组成。共享池使得用户可以共享已经编译解析过的程序代码，从而降低了重复执行相同代码的开销，提高数据库的性能。123graph TDa[共享缓冲区]--&gt;b[库缓冲区]a[共享缓冲区]--&gt;d[数据字典] 重做日志缓冲区对数据库进行修改的任何事务在记录到重做日志之前都必须首先放到重做日志缓冲区中。重做日志缓冲区是专为此开辟的一块内存区域，重做日志缓存中的内容将被LGWR后台进程随时写入重做日志文件。 记录实例做出的修改 是循环缓冲区后台进程数据库的物理结构和内存结构之间的关系是由后台进程来维持的。 进程名 功能 日志写进程LGWR 将重做日志记录写到联机日志文件 数据库写进程DBWR 将修改过的数据库写回到数据文件 系统监控进程SMON 对有故障的实例进行恢复 进程监控进程PMON 清理异常终止的进程所占用的资源 检查点进程CKPT 定期检查数据库 归档进程ARCH 将已写满的联机日志文件复制到归档日志文件 Oracle的体系结构示意图 其他概念—进程结构 用户进程 : 当用户要求连接到 Oracle 服务器时启动的一种进程。 服务器进程 : 直接和 Oracle 服务器交互的一段程序。它响应用户要 求，向服务器发起呼叫并返回结果给用户。 后台进程 : 用于维持数据库的物理结构和存储结构间的关系附加进程其他概念—程序全局区程序全局区（PGA）：是用户进程私有的内存区域，不能共享。PGA在用户进程连接到数据库后，在创建会话时被自动分配，当一个用户会话结束，PGA被释放。]]></content>
      <categories>
        <category>oracle</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[oracle复习重点第三章]]></title>
    <url>%2F2018%2F08%2F13%2Foralce%E5%A4%8D%E4%B9%A0%E9%87%8D%E7%82%B9%E7%AC%AC%E4%BA%8C%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[第三章 创建表的SQL命令（创建、修改和删除）； 数据操作的SQL命令：插入数据、修改数据、删除数据；大题 选择的话是细则创建表 12345678910CREATE TABLE XSB( 学号 char(6) NOT NULL PRIMARY KEY, 姓名 char(8) NOT NULL, 性别 char(2) DEFAULT &apos;男&apos; NOT NULL, 出生时间 date NOT NULL, 专业 char(12) NULL, 总学分 number(2) NULL, 备注 varchar2(200) NULL); SQL简介 数据定义语言（DDL）。DDL用于对数据库以及数据库中各种对象的结构进行创建、删除、修改等。其中数据库对象主要包括表、视图、索引、同义词、序列等。DDL包括的主要语句及功能如表所示 语 句 功 能 CREATE 创建数据库或数据库对象 ALTER 对数据库或数据库对象进行修改 DROP 删除数据库或数据库对象 数据操纵语言（DML）。DML用于操纵存储在数据库对象中的数据。包括查找、插入、修改和删除等操作。DML包括的主要语句及功能如表所示： 语 句 功 能 SELECT 从表或视图中检索数据 INSERT 将数据插入到表或视图中 UPDATE 修改表或视图中的数据 DELETE 从表或视图中删除数据 数据控制语言（DCL）。DCL用于安全管理，确定哪些用户可以查看或修改数据库中的数据。DCL包括的主要语句及功能如表所示： 语 句 功 能 GRANT 授予权限 REVOKE 收回权限 DENY 收回权限，并禁止从其他角色继承权限 事务控制语言（TCL）。事务是一个或多个SQL语句序列的组合。事务控制语言TCL用于维护交易过程中数据的一致性。TCL包括的主要语句及功能如表所示： 语 句 功 能 COMMIT 用于提交事务，对数据库做永久性修改 ROLLBACK 用于事务出错时回滚数据 SAVEPOINT 标记事务中的某个点以便将来可以回滚 修改表ADD子句：用于向表中增加一个新列，新列的定义和创建表时定义列的格式一样，一次可添加多个列，中间用逗号隔开。 1234在表XS_JSJ中增加两列：奖学金等级、等级说明。ALTER TABLE XS_JSJ ADD (奖学金等级 number(1), 等级说明 varchar2(40) DEFAULT &apos;奖金1000元&apos;); 123为XS_JSJ表添加主键。ALTER TABLE XS_JSJ ADD (CONSTRAINT &quot;PK_JSJ&quot; PRIMARY KEY(学号) ); MODIFY子句：用于修改表中某列的属性（数据类型、默认值等）。在修改数据类型时需要注意，如果表中该列所存数据的类型与将要修改的列类型冲突，则会发生错误。 123在XS_JSJ表中修改“等级说明”列的默认值。ALTER TABLE XS_JSJ MODIFY (等级说明 DEFAULT &apos;奖金800元&apos; ); DROP子句：该子句用于从表中删除指定的字段或约束，语法格式为：1234567DROP &#123; COLUMN &lt;列名&gt; ∣PRIMARY [KEY] ∣UNIQUE (&lt;列名&gt;,…n) ∣CONSTRAINT &lt;约束名&gt; ∣[ CASCADE ]&#125; 12345在表XS_JSJ中删除“奖学金等级”和“等级说明”列。ALTER TABLE XS_JSJ DROP COLUMN 奖学金等级;ALTER TABLE XS_JSJ DROP COLUMN 等级说明; 删除表语法格式：DROP TABLE [&lt;用户方案名&gt;.] &lt;表名&gt;例如要删除表XS_JSJ，使用如下语句： 1DROP TABLE XS_JSJ; 数据的操作命令INSERT语句：向指定的表中加入一行，由VALUES指定各列的值。 12INSERT INTO &lt;表名&gt;[(&lt;列名1&gt;,&lt;列名2&gt;,…n)] VALUES(&lt;列值1&gt;,&lt;列值2&gt;,…n) 插入的数据应与字段的数据类型相同。 数据的大小应在列的规定范围内，例如：不能将一个长度为80的字符串加入到长度为40的列中。 在values中列出的数据位置必须与被加入的列的排列位置相对应。 字符和日期型数据应包含在单引号中。 插入空值，不指定或insert into table value(null) 向XSCJ数据库的表XSB中插入如下的一行： 151114 周何骏 计算机 男 1998-09-25 90可以使用如下的SQL语句：I1234NSERT INTO XSB(学号, 姓名, 性别, 出生时间, 专业, 总学分) VALUES(&apos;151114&apos;, &apos;周何骏&apos;, &apos;男&apos;,TO_DATE(&apos;19980925&apos;,&apos;YYYYMMDD&apos;), &apos;计算机&apos;, 90);或者：INSERT INTO XSB VALUES(&apos;151114&apos;, &apos;周何骏&apos;, &apos;男&apos;, &apos;1998-09-25&apos;, &apos;计算机&apos;, 90, NULL); 然后再运行COMMIT命令（用于提交修改过的数据，以保证数据保存到数据库中）COMMIT; 使用 update语句修改表中数据 123UPDATE &lt;表名&gt; SET &lt;列名&gt;=&#123;&lt;新值&gt;|&lt;表达式&gt;&#125; [,…n] [WHERE &lt;条件表达式&gt;] UPDATE语法可以用新值更新原有表行中的各列。 SET子句指示要修改哪些列和要给予哪些值。 WHERE子句指定应更新哪些行。如没有WHERE子句，则更新所有的行。 将XSCJ数据库的XSB表中学号为“151114”的学生备注列值置为“辅修计算机专业”，使用如下SQL语句： 123UPDATE XSB SET 备注=&apos;辅修计算机专业&apos; WHERE 学号=&apos;151114&apos;; 将a表中的所有学生的ZXF（总学分）都增加5。 12UPDATE a SET ZXF = ZXF + 5;]]></content>
      <categories>
        <category>oracle</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[oracle复习重点第四章]]></title>
    <url>%2F2018%2F08%2F13%2Foracle%E5%A4%8D%E4%B9%A0%E9%87%8D%E7%82%B9%E7%AC%AC%E5%9B%9B%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[你带着你的好过一辈子吧 第四章 SELECT语句（包括SELECT、FROM等子句）； 连接查询（包括内连接和外连接，外连接又分为左外连接、右外连接和完全外连接）； 子查询； 分组函数，group by子句，having子句，排序 视图创建，注意一些选项：froce、with read only和with check option 可更新视图的概念 了解替换变量：&amp;，&amp;&amp; 选择和投影的区别选择：单目运算，其运算对象是一个表。该运算按给定的条件，从表中选出满足条件的行形成一个新表作为运算结果。投影：单目运算，该运算从表中选出指定的列组成一个新表。 连接 连接：把两个表中的行按着给定的条件（=、&gt;、&lt;、&gt;=、&lt;=、!=）拼接而形成的新表。 等值连接：如果连接两个表的条件是要求某些列值相等，则称该连接为等值连接。（属性名可以不同，但是要求列值相同） 自然连接：两个关系具有相同属性时(属性名和列值都相同)，进行的等值连接，并且去掉重复的属性. 等值连接与自然连接的区别： 1. 等值连接中不要求列名相同，只要列值相同即可。而自然连接要求列名和列值都要相同，才能进行自然连接。 2. 等值连接不去除重复列，而自然连接要求去掉重复列，也可以说，自然连接是去掉重复列的等值连接。 查询SQL查询语句的步骤： 编译：服务器进程在共享池中搜索是否有相同的SQL语句；检查SQL语句的语法；处理之后，或返回错误，或将SQL语句和执行计划装入共享的SQL区 执行：SQL语句获取执行所需的所有资源和信息，服务器进程执行SQL语句 提取数据：服务器进程选择所需的数据行，并在需要时进行排序，最后将结果返回给用户进程 SQL的SELECT语句可以实现对表的选择、投影及连接操作，其功能十分强大。SELECT语句比较复杂，其主要的子句语法格式如下： 123456SELECT &lt;列&gt; /*指定要选择的列及其限定*/ FROM &lt;表或视图&gt; /*FROM子句，指定表或视图*/ [ WHERE &lt;条件表达式&gt; ] /*WHERE子句，指定查询条件*/ [ GROUP BY &lt;分组表达式&gt; ] /*GROUP BY子句，指定分组表达式*/ [ HAVING &lt;分组条件表达式&gt; ] /*HAVING子句，指定分组统计条件*/ [ ORDER BY &lt;排序表达式&gt; [ ASC | DESC ]] /*ORDER子句，指定排序表达式和顺序*/ 修改查询结果中的列标题可以在列名之后使用AS子句指定一个列别名来替代查询结果的列标题名。【例】 查询XSB表中计算机专业同学的学号、姓名和总学分，结果中各列的标题分别指定为num、name和score。 1234567SELECT 学号 AS num, 姓名 AS name, 总学分 AS score FROM XSB WHERE 专业= &apos;计算机&apos;;也可以省略AS关键字，写成：SELECT 学号 num, 姓名 name, 总学分 score FROM XSB WHERE 专业=&apos;计算机&apos;; 消除结果集中的重复行可以使用DISTINCT关键字消除结果集中的重复行，其格式是： 1SELECT [ ALL | DISTINCT ] &lt;列名&gt; [ , &lt;列名&gt;…] 关键字DISTINCT的含义是对结果集中的重复行只选择一个，保证行的唯一性。【例】 对XSCJ数据库的XSB表只选择专业和总学分，消除结果集中的重复行。 12SELECT DISTINCT 专业 AS 专业,总学分 AS 总学分 FROM XSB; 选择行选择行是选择列的特例。WHERE子句中查询条件的基本格式为： 1234WHERE &lt;条件表达式&gt;::= &#123; [ NOT ] &lt;判定运算&gt; | (&lt;条件表达式&gt; ) &#125;其中，&lt;判定运算&gt;的结果为TRUE、FALSE或UNKNOWN，经常用到的格式为：&lt;判定运算&gt;::= 1234567&#123; &lt;表达式1&gt; &#123; = | &lt; | &lt;= | &gt; | &gt;= | &lt;&gt; | != &#125; &lt;表达式2&gt; /*比较运算*/ | &lt;字符串表达式1&gt; [ NOT ] LIKE &lt;字符串表达式2&gt; /*字符串模式匹配*/ | &lt;表达式&gt; [ NOT ] BETWEEN &lt;表达式1&gt; AND &lt;表达式2&gt; /*指定范围*/ | &lt;表达式&gt; IS [ NOT ] NULL /*是否空值判断*/ | &lt;表达式&gt; [ NOT ] IN ( &lt;子查询&gt; | &lt;表达式&gt; [,…n] ) /*IN子句*/ | EXIST ( &lt;子查询&gt; ) /*EXIST子查询*/&#125; 1．表达式比较比较运算的格式为： 1&lt;表达式1&gt; &#123; = | &lt; | &lt;= | &gt; | &gt;= | &lt;&gt; | != &#125; &lt;表达式2&gt; 当两个表达式值均不为空值（NULL）时，比较运算返回逻辑值TRUE（真）或FALSE（假）；而当两个表达式值中有一个为空值或都为空值时，比较运算将返回UNKNOWN。 【例】 比较运算符的应用。① 查询CP表中库存量在500以上的产品情况。 123SELECT * FROM CP WHERE 库存量&gt;500; 2．模式匹配LIKE谓词用于指出一个字符串是否与指定的字符串相匹配，其运算对象可以是char、varchar2和date类型的数据，返回逻辑值TRUE或FALSE。LIKE谓词表达式的格式为： 1&lt;字符串表达式1&gt; [ NOT ] LIKE &lt;字符串表达式2&gt; 在使用LIKE时，可以使用两个通配符：“%”和“”。若使用带“%”通配符的LIKE进行字符串比较，模式字符串中的所有字符都有意义，包括起始或尾随空格； 而“”在模糊条件中表示一个字符。 【例】 查询CP表（表4.11）中产品名含有“冰箱”的产品情况。 123SELECT * FROM CP WHERE 产品名称 LIKE &apos;%冰箱%&apos;; 1234【例】 查询XSB表中姓“王”且单名的学生情况。SELECT * FROM XSB WHERE 姓名 LIKE &apos;王_&apos;; 3．范围比较用于范围比较的关键字有两个：BETWEEN和IN。当要查询的条件是某个值的范围时，可以使用BETWEEN关键字。BETWEEN关键字指出查询范围，格式为： 1&lt;表达式&gt; [ NOT ] BETWEEN &lt;表达式1&gt; AND &lt;表达式2&gt; 当不使用NOT时，若表达式的值在表达式1与表达式2之间（包括这两个值），则返回TRUE，否则返回FALSE；使用NOT时，返回值刚好相反。 【例】 指定查询的范围。① 查询CP表中价格在2000元与4000元之间的产品情况。123SELECT * FROM CP WHERE 价格 BETWEEN 2000 AND 4000; ② 查询XSB表中不在1996年出生的学生情况。1234SELECT * FROM XSB WHERE 出生时间 NOT BETWEEN TO_DATE(&apos;19960101&apos;, &apos;YYYYMMDD&apos;) AND TO_DATE(&apos;19961231&apos;, &apos;YYYYMMDD&apos;); 使用IN关键字可以指定一个值表，值表中列出所有可能的值，当表达式与值表中的任意一个匹配时，即返回TRUE，否则返回FALSE。其格式为： 1&lt;表达式&gt; IN ( &lt;表达式&gt; [,…n]) 【例】 查询CP表中库存量为“200”“300”和“500”的产品情况。 123SELECT * FROM CP WHERE 库存量=200 OR 库存量=300 OR 库存量=500; 该语句与下列语句等价： 123SELECT * FROM CP WHERE 库存量 IN (200,300,500); 4．空值比较当需要判定一个表达式的值是否为空值时，使用IS NULL关键字，格式为： 1&lt;表达式&gt; IS [ NOT ] NULL 当不使用NOT时，若表达式的值为空值，返回TRUE，否则返回FALSE；当使用NOT时，结果刚好相反。【例】 查询XSB表中拥有备注信息的学生情况。123SELECT * FROM XSB WHERE 备注 IS NOT NULL; 5．子查询 在查询是基于未知的值时应使用子查询。子查询是指嵌入在其它sql语句中的select语句,也叫嵌套查询。 非相关子查询是独立于外部查询的子查询，子查询总共执行一次，执行完毕后将值传递给外部查询。 相关子查询是指子查询引用了外部查询中表的信息，这就意味着子查询要依赖于外部查询，不能独立地调用它。由于相关子查询的执行依赖于外部查询的数据，故外部查询执行一行，子查询就执行一次。 子查询通常与谓词IN、EXIST及比较运算符结合使用。 （1）IN子查询。IN子查询用于进行一个给定值是否在子查询结果集中的判断，格式为： 1&lt;表达式&gt; [ NOT ] IN ( &lt;子查询&gt;) 当表达式与子查询的结果表中的某个值相等时，IN谓词返回TRUE，否则返回FALSE；若使用了NOT，则返回的值刚好相反。 1例：select * from A where id in (select id from B); in()只执行一次，它查出B表中的所有id字段并缓存起来。之后，检查A表的id是否与B表中的id相等，如果相等则将A表的记录加入结果集中，直到遍历完A表的所有记录。 【例】 在XSCJ数据库中查找选修了课程号为102的学生的情况： 1234SELECT * FROM XSB WHERE 学号 IN ( SELECT 学号 FROM CJB WHERE 课程号 = &apos;102&apos; ); 在执行包含子查询的SELECT语句时，系统先执行子查询，产生一个结果表，再执行查询。 123456789101112【例】 查找未选修离散数学的学生的情况。SELECT 学号, 姓名, 专业, 总学分 FROM XSB WHERE 学号 NOT IN ( SELECT 学号 FROM CJB WHERE 课程号 IN ( SELECT 课程号 FROM KCB WHERE 课程名 = &apos;离散数学&apos; ) ); （2）比较子查询。这种子查询可以认为是IN子查询的扩展，它使表达式的值与子查询的结果进行比较运算，格式为： 1&lt;表达式&gt; &#123; &lt; | &lt;= | = | &gt; | &gt;= | != | &lt;&gt; &#125; &#123; ALL | SOME | ANY &#125; ( &lt;子查询&gt; ) 其中，ALL、SOME和ANY关键字说明对比较运算的限制。ALL指定表达式要与子查询结果集中的每个值都进行比较，当表达式与每个值都满足比较的关系时，才返回TRUE，否则返回FALSE；SOME或ANY表示表达式只要与子查询结果集中的某个值满足比较的关系时，就返回TRUE，否则返回FALSE。 【例】 查找比所有计算机系学生年龄都大的学生。 1234567SELECT * FROM XSB WHERE 出生时间 &lt;ALL ( SELECT 出生时间 FROM XSB WHERE 专业= &apos;计算机&apos; ); 【例】 查找课程号206的成绩不低于课程号101的最低成绩的学生的学号、姓名。 1234567891011SELECT 学号，姓名 FROM XSB WHERE 学号 IN ( SELECT 学号 FROM CJB WHERE 课程号 = &apos;206&apos; AND 成绩 &gt;= ANY ( SELECT 成绩 FROM CJB WHERE 课程号 = &apos;101&apos; ) ); （3）EXISTS子查询。EXISTS谓词用于测试子查询的结果是否为空表，若子查询的结果集不为空，则EXISTS返回TRUE，否则返回FALSE。EXISTS还可与NOT结合使用，即NOT EXISTS，其返回值与EXIST刚好相反。格式为：[ NOT ] EXISTS ( &lt;子查询&gt; )例：1select * from A where exists (select * from B where A.id=B.id); exists()会执行A.length次，它并不缓存exists()结果集，因为exists()结果集的内容并不重要，重要的是其内查询语句的结果集空或者非空，空则返回false，非空则返回true。 【例】 查找选修206号课程的学生姓名。 1234567SELECT 姓名 FROM XSB WHERE EXISTS ( SELECT * FROM CJB WHERE 学号=XSB.学号 AND 课程号= &apos;206&apos; ); 总结：exists通常用在相关子查询中（执行依赖于外部查询的数据，外部查询执行一行，子查询就执行一次），而in子句通常用在非相关子查询中，先执行子查询，将子查询的结果用于外查询；如果查询的两个表大小相当，那么用in和exists的效率差别不大，如果子表数据量大时，exists效率优于in， 因为in是在内存里遍历比较，而exists只需要查询数据库。 连接 在SQL中，包括符合SQL标准连接谓词的和使用关键字JION的两种连接方式 1．连接谓词可以在SELECT语句的WHERE子句中使用比较运算符给出连接条件对表进行连接，将这种表示形式称为连接谓词。 【例】 查找XSCJ数据库每个学生及其选修的课程情况。 123SELECT XSB.* ,CJB.* FROM XSB , CJB WHERE XSB.学号=CJB.学号; 结果表将包含XSB表和CJB表的所有行和列。 【例】 查找选修了206课程且成绩在80分以上的学生姓名及成绩。 123SELECT 姓名, 成绩 FROM XSB , CJB WHERE XSB.学号 = CJB.学号 AND 课程号 = &apos;206 &apos; AND 成绩 &gt;= 80; 2．以JOIN关键字指定的连接Oracle的PL/SQL语言扩展了以JOIN关键字指定连接的表示方式，增强了表的连接运算能力。连接表的格式为： 1234&lt;表名&gt; &lt;连接类型&gt; &lt;表名&gt; ON &lt;条件表达式&gt;其中，&lt;连接类型&gt;的格式为：&lt;连接类型&gt;::= [ INNER | &#123; LEFT | RIGHT | FULL &#125; [ OUTER ] CROSS JOIN 其中，INNER表示内连接，OUTER表示外连接，CROSS JOIN表示交叉连接; 使用 ON 子句指定连接条件，这个连接条件是与其它条件分开的，ON 子句使语句具有更高的可读性。 ■ 内连接：根据指定的查询条件进行连接查询，只有满足条件的数据才会出现在结果集中。其实质就是利用 where 子句对两张表形成的笛卡尔积进行筛选。 ■ 外连接：在内连接的基础上，将某个表中不符合条件的记录加入结果集中。一个表最多只能和一个表进行外连接。根据连接结果集中所包含不符合连接条件的记录来源的不同，外连接分为三类：左外连接 、右外连接和完全外连接。 ■ 交叉连接：交叉连接实际上是将两个表进行笛卡儿积运算。 （1）内连接。按照ON所指定的连接条件合并两个表，返回满足条件的行。 【例】 查看XSCJ数据库每个学生及其选修的课程情况。123SELECT * FROM XSB INNER JOIN CJB ON XSB.学号 = CJB.学号; 结果表将包含XSB表和CJB表的所有字段（不去除重复学号字段）。 【例】 查找选修了206课程且成绩在80分以上的学生姓名及成绩。123SELECT 姓名, 成绩 FROM XSB JOIN CJB ON XSB.学号 = CJB.学号 WHERE 课程号 = &apos;206&apos; AND 成绩&gt;=80; 【例】查找选修课程成绩在90分以上的学生学号、姓名、课程名及成绩。 12345SELECT XSB.学号 , 姓名 , 课程名 , 成绩 FROM XSB JOIN CJB JOIN KCB ON CJB.课程号 = KCB.课程号 ON XSB.学号 = CJB.学号 WHERE 成绩&gt;=90; 【例】 查找不同课程但成绩相同的学生的学号、课程号和成绩。 123SELECT a.学号,a.课程号,b.课程号,a.成绩 FROM CJB a JOIN CJB b ON a.成绩=b.成绩 AND a.学号=b.学号 AND a.课程号!=b.课程号; （2）外连接。外连接的结果表不但包含满足连接条件的行，还包括相应表中的所有行。外连接包括以下三种。 左外连接（LEFT OUTER JOIN）：结果表中除了包括满足连接条件的行外，还包括左表的所有行； 右外连接（RIGHT OUTER JOIN）：结果表中除了包括满足连接条件的行外，还包括右表的所有行； 完全外连接（FULL OUTER JOIN）：结果表中除了包括满足连接条件的行外，还包括两个表的所有行。 【例】 查找所有学生情况及他们选修的课程号，若学生未选修任何课，也要包括其情况。 12SELECT XSB.* , 课程号 FROM XSB LEFT OUTER JOIN CJB ON XSB.学号 = CJB.学号; 若有学生未选任何课程，则结果表中相应行的课程号字段值为NULL。【例】 查找被选修了的课程的选修情况和所有开设的课程名。 12SELECT CJB.* , 课程名 FROM CJB RIGHT JOIN KCB ON CJB.课程号= KCB.课程号; 若某课程未被选修，则结果表中相应行的学号、课程号和成绩字段值均为NULL。 （3）交叉连接。交叉连接实际上是将两个表进行笛卡儿积运算，结果表是由第1个表的每一行与第2个表的每一行拼接后形成的表，因此其行数等于两表行数之积。【例】 列出学生所有可能的选课情况。 12SELECT 学号, 姓名, 课程号, 课程名 FROM XSB CROSS JOIN KCB; 汇总1．分组函数分组函数作用于一组数据，并返回一个值。分组函数中SUM和AVG只应用于数值型的列，MAX、MIN和COUNT可以应用于字符、数值和日期类型的列。组函数忽略列的空值。 在分组函数中可使用DISTINCT或ALL关键字。ALL表示对所有值进行运算。DISTINCT 表示去除重复值。默认为ALL。 （1）SUM和AVG函数。这两个函数分别用于求表达式中所有值项的总和与平均值，语法格式为：SUM / AVG ( [ ALL | DISTINCT ] &lt;表达式&gt; )其中，表达式还可以是常量、列、函数。SUM和AVG函数只能对数值型数据进行计算。【例4.36】 求选修101课程的学生的平均成绩。 123SELECT AVG(成绩) AS 课程101平均成绩 FROM CJB WHERE 课程号=‘101’; （2）MAX和MIN函数。MAX和MIN函数分别用于求表达式中所有值项的最大值与最小值，语法格式为：MAX / MIN ( [ ALL | DISTINCT ] &lt;表达式&gt; )其中，表达式的数据类型可以是数字、字符和时间日期类型。【例4.37】 求选修101课程的学生的最高分和最低分。 123SELECT MAX(成绩) AS 课程101的最高分, MIN(成绩) AS 课程101的最低分 FROM CJB WHERE 课程号=‘101’; （3）COUNT函数。COUNT函数用于统计组中满足条件的行数或总行数，格式为：COUNT ( { [ ALL | DISTINCT ] &lt;表达式&gt; } | )选择时将统计总行数。【例4.38】 学生数统计。① 求学生的总人数。 123SELECT COUNT(*) AS 学生总数 FROM XSB;COUNT(*)不需要任何参数。 ③ 统计离散数学课程成绩在85分以上的人数。 1234567SELECT COUNT(成绩) AS 离散数学85分以上的人数 FROM CJB WHERE 成绩&gt;=85 AND 课程号= ( SELECT 课程号 FROM KCB WHERE 课程名= &apos;离散数学&apos; ); 2．GROUP BY子句GROUP BY子句用于对表或视图中的数据按字段分组，语法格式为：GROUP BY [ ALL ] &lt;分组表达式&gt; [,…n]分组表达式通常包含字段名。指定ALL将显示所有组。使用GROUP BY子句后，SELECT子句中的列表中只能包含在GROUP BY中指出的列或在分组函数中指定的列。【例4.39】 将XSB表中各专业输出。 123SELECT 专业 FROM XSB GROUP BY 专业; 【例4.41】 求被选修的各门课程的平均成绩和选修该课程的人数。 123SELECT 课程号, AVG(成绩) AS 平均成绩,COUNT(学号) AS 选修人数 FROM CJB GROUP BY 课程号; 3．HAVING子句使用 HAVING 子句进行过滤分组:(1)行已经被分组。(2)使用了组函数。(3)满足HAVING 子句中条件的分组将被显示。【例4.42】 查找XSCJ数据库中平均成绩在85分以上的学生的学号和平均成绩。 1234SELECT 学号, AVG(成绩) AS 平均成绩 FROM CJB GROUP BY 学号 HAVING AVG(成绩)&gt;=85; 【例4.43】 查找选修课程超过两门且成绩都在80分以上的学生的学号。 12345SELECT 学号 FROM CJB WHERE 成绩&gt;=80 GROUP BY 学号 HAVING COUNT(*) &gt; 2; 【例4.44】 查找通信工程专业平均成绩在85分以上的学生的学号和平均成绩。 123456789SELECT 学号,AVG(成绩) AS 平均成绩 FROM CJB WHERE 学号 IN ( SELECT 学号 FROM XSB WHERE 专业= &apos;通信工程&apos; ) GROUP BY 学号 HAVING AVG(成绩) &gt; =85; 排序 在ORDER BY 子句在SELECT语句的结尾，可进行排序 1[ ORDER BY &#123; &lt;排序表达式&gt; [ ASC | DESC ] &#125; [ ,…n ] 系统默认值为ASC，升序 DESC为降序。 合并在实际应用中，为了合并多个select语句的结果，可以使用集合操作符号 union 。使用UNION子句可以将两个或多个SELECT查询的结果合并成一个结果集，其语法格式为： 12&lt;SELECT查询语句1&gt;UNION [ ALL] &lt;SELECT查询语句2&gt;]]></content>
      <categories>
        <category>oracle</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[代码高亮展示]]></title>
    <url>%2F2018%2F08%2F12%2F%E4%BB%A3%E7%A0%81%E9%AB%98%E4%BA%AE%E5%B1%95%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[这是一行普通的字 这是高亮部分 12345678910111213这是代码 $(&apos;pre code&apos;).each(function(i, block) &#123; //hljs.highlightBlock(block); var lines = $(this).text().split(&apos;\n&apos;).length - 1; var $numbering = $(&apos;&lt;ul/&gt;&apos;).addClass(&apos;pre-numbering&apos;); $(this) .addClass(&apos;has-numbering&apos;) .parent() .append($numbering); for(i=1;i&lt;=lines;i++)&#123; $numbering.append($(&apos;&lt;li/&gt;&apos;).text(i)); &#125; &#125;);]]></content>
  </entry>
  <entry>
    <title><![CDATA[pic test]]></title>
    <url>%2F2018%2F08%2F12%2Fpic-test%2F</url>
    <content type="text"><![CDATA[插个图片吧]]></content>
  </entry>
  <entry>
    <title><![CDATA[如何利用优秀的hexo+github建立一个属于自己博客]]></title>
    <url>%2F2018%2F08%2F12%2F%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E4%BC%98%E7%A7%80%E7%9A%84hexo-github%E5%BB%BA%E7%AB%8B%E4%B8%80%E4%B8%AA%E5%B1%9E%E4%BA%8E%E8%87%AA%E5%B7%B1%E5%8D%9A%E5%AE%A2(1)%2F</url>
    <content type="text"><![CDATA[内事不决问百度，外事不决问谷歌 1.环境搭建1.1下载git 地址link git是个啥？ 根据网上介绍git是一个最优秀的版本控制软件没有之一。 顾名思义，版本控制系统是任何能让你了解到一个文件的历史，以及它的发展过程的系统。 git在这里有啥子用呢？ 接下来大部分操作都会用到git命令服务窗口 包括安装hexo以及hexo的各种插件，将本地关联到github服务器，让hexo生成页面等等。 1.2下载node.js hexo是一款基于Node.js的静态博客框架，因此安装之前必须先安装Node.js 地址一路安装下去没什么好说的。 1.3安装hexo !]]></content>
      <categories>
        <category>hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F08%2F12%2Fhello-world%2F</url>
    <content type="text"><![CDATA[耗时三天十几个小时，踩过过无数个坑，博客终于千呼万唤出来了。今天太累了，明天会把基本的步骤写出来，做为供自己反思（zhuangbi）和他人学习。 万里长征的第一步，开始 加油!！！]]></content>
  </entry>
  <entry>
    <title><![CDATA[php categorie test]]></title>
    <url>%2F2018%2F08%2F12%2Fphp%20%E5%88%86%E7%B1%BB%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[test]]></content>
      <categories>
        <category>php</category>
      </categories>
  </entry>
</search>
